{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in initial packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import oscn\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#Uncomment on initial run -- #nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn-crfsuite\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Docket Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpDocket(docNum):\n",
    "    splitNum = docNum.split('-')\n",
    "    #print(splitNum)\n",
    "    docType = splitNum[0]\n",
    "    year = splitNum[1]\n",
    "    county ='Tulsa'\n",
    "    docNum = splitNum[2]\n",
    "    #print(\"Split: \", docType, ' ', year, ' ', docNum)\n",
    "    case=oscn.request.Case(type=docType, year=year,county=county,number=docNum)\n",
    "    return case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling out Judge, defendant lawyer & state rep from given text\n",
    "\n",
    "Commented out all of the print functions, so the execution of the code below isn't so lengthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchTagPatterns(string, pattern):\n",
    "    match_list = []\n",
    "    #print(\"Pattern is \",pattern)\n",
    "    pattern = re.sub(r'[^\\w\\s]','',pattern)\n",
    "    pattern = pattern.strip()\n",
    "    #print(\"Stripped Pattern: \",pattern)\n",
    "    seqMatch = SequenceMatcher(None, string, pattern, autojunk=False)\n",
    "    match = seqMatch.find_longest_match(0, len(string), 0, len(pattern))\n",
    "    if (match.size == len(pattern)):\n",
    "        start = match.a\n",
    "        end = match.a + match.size\n",
    "        match_tup = (start, end)\n",
    "        string = string.replace(pattern, \"X\" * len(pattern), 1)\n",
    "        match_list.append(match_tup)\n",
    "        \n",
    "    return match_list, string\n",
    "\n",
    "def mark_sentence(s, match_list):\n",
    "    word_dict = {}\n",
    "    for word in s.split():\n",
    "        word_dict[word] = 'O'\n",
    "        \n",
    "    for start, end, e_type in match_list:\n",
    "        temp_str = s[start:end]\n",
    "        tmp_list = temp_str.split()\n",
    "        if len(tmp_list) > 1:\n",
    "            word_dict[tmp_list[0]] = 'B-' + e_type\n",
    "            for w in tmp_list[1:]:\n",
    "                word_dict[w] = 'I-' + e_type\n",
    "        else:\n",
    "            word_dict[temp_str] = 'B-' + e_type\n",
    "    return word_dict\n",
    "\n",
    "def clean(text):\n",
    "    soup = BeautifulSoup(text)\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    return text\n",
    "\n",
    "def create_data(df):\n",
    "    match_list = []\n",
    "    for text, annotation in zip(df.text, df.annotation):\n",
    "        #print(\"Text : \", text)\n",
    "        #print(\"annotation : \", annotation)\n",
    "        text = clean(text)\n",
    "        #print(\"text cleaned\")\n",
    "        text_ = text \n",
    "        #print(text_)\n",
    "\n",
    "        for i in annotation:\n",
    "            a, text_ = matchTagPatterns(text, i[0])\n",
    "            #print('a:',a)\n",
    "            #print('i:',i)\n",
    "            if a:\n",
    "                match_list.append((a[0][0], a[0][1], i[1]))\n",
    "    d = mark_sentence(text, match_list)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating tuples and tagging out the keywords we want to identify\n",
    "\n",
    "This sets up the data into easier to use pairs of `(word, tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTuples(i, value, column):\n",
    "    values = value.split('\\n')\n",
    "    tuples = []\n",
    "    for val in values:\n",
    "        tuples.append(tuple((val,column)))\n",
    "    #print(\"found tuples \",tuples,\" for \", value)\n",
    "    return tuples\n",
    "#Tuple reference\n",
    "#https://stackoverflow.com/questions/31175223/append-a-tuple-to-a-list-whats-the-difference-between-two-ways/31175264\n",
    "def getValues(i,column):\n",
    "    value = training[column][i]\n",
    "    tuples = []\n",
    "    #print(\"Values \", value, \" found \", pd.isnull(value), \" is null for column \",column)\n",
    "    if not(pd.isnull(value)):\n",
    "        if ('\\n' in value):\n",
    "            tuples = createTuples(i, value, column)\n",
    "        else:\n",
    "            tuples.append(tuple([value,column]))\n",
    "    #print(\"tuple created \", tuples)\n",
    "    return tuples\n",
    "def zipTuples(lst):\n",
    "    lst_tuple = [x for x in zip(*[iter(lst)]*2)]\n",
    "    #print(lst_tuple)\n",
    "    return lst_tuple\n",
    "def getAnnotations(i, columns):\n",
    "    annotations = []\n",
    "    for column in columns:\n",
    "        tuples = getValues(i,column)\n",
    "        #print(\"tuples created =\", tuples, \" tuples\")\n",
    "        annotations = np.append(annotations,[[tuples]]) \n",
    "        #print(\"annotations created =\", annotations, \" annotations\")\n",
    "    return zipTuples(annotations)\n",
    "        \n",
    "def getTags(case,i):\n",
    "    #print(\"This is the \",i,\"th case\")\n",
    "    columns = ['Judge','Defendant lawyer','State Rep']\n",
    "    annotations = getAnnotations(i, columns)\n",
    "    tags = [[case.text, annotations]]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features, Tokens, and Label Lists\n",
    "\n",
    "Features used by the CRF Model, but not the eventual LSTM Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    #postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        #postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        #postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagsToSent(tags):\n",
    "    sentList = []\n",
    "    for i in range(len(tags)):\n",
    "        #https://www.kite.com/python/answers/how-to-convert-a-dictionary-into-a-list-of-tuples-in-python\n",
    "        #print(tags[i].items())\n",
    "        dictItems = tags[i].items()\n",
    "        sentList.append(list(dictItems))\n",
    "    return sentList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Dockets through Tagger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling in the Training Data\n",
    "\n",
    "* If you've got the pickled file `taggedNERSet`  and want to see setup for NN, then you can skip to the Word Mapping section\n",
    "* If you've got the pickled files `X`,`y`,`X_val`,`y_val`, you can skip to the Bidirectional LSTM section where the Neural Network modelling starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Docket Number</th>\n",
       "      <th>Conviction</th>\n",
       "      <th>NER Training Paragraph</th>\n",
       "      <th>Judge</th>\n",
       "      <th>Defendant lawyer</th>\n",
       "      <th>State Rep</th>\n",
       "      <th>Sentencing</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF-2012-5905</td>\n",
       "      <td>Y</td>\n",
       "      <td>JUDGE DAWN MOODY: DEFENDANT PRESENT NOT IN CUS...</td>\n",
       "      <td>DAWN MOODY</td>\n",
       "      <td>SHEILA NAIFEH</td>\n",
       "      <td>JULIANNE BURTON</td>\n",
       "      <td>TWO (2) YEARS</td>\n",
       "      <td>https://www.oscn.net/dockets/GetCaseInformatio...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF-2012-5896</td>\n",
       "      <td>Y</td>\n",
       "      <td>JUDGE JAMES CAPUTO: DEFENDANT PRESENT REPRESEN...</td>\n",
       "      <td>JAMES CAPUTO</td>\n",
       "      <td>DARRELL BOLTON</td>\n",
       "      <td>KALI STRAIN</td>\n",
       "      <td>TWO (2) YEARS DEPARTMENT OF CORRECTIONS</td>\n",
       "      <td>https://www.oscn.net/dockets/GetCaseInformatio...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CF-2012-5886</td>\n",
       "      <td>Y</td>\n",
       "      <td>JUDGE JAMES CAPUTO: DEFENDANT PRESENT IN CUSTO...</td>\n",
       "      <td>JAMES CAPUTO</td>\n",
       "      <td>ADAM HASELGREN</td>\n",
       "      <td>KALI STRAIN</td>\n",
       "      <td>THREE (3) YEARS IN DEPARTMENT OF CORRECTIONS</td>\n",
       "      <td>https://www.oscn.net/dockets/GetCaseInformatio...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CF-2012-5591</td>\n",
       "      <td>N</td>\n",
       "      <td>JUDGE CLIFFORD SMITH: DEFENDANT PRESENT IN CUS...</td>\n",
       "      <td>CLIFFORD SMITH</td>\n",
       "      <td>CLAY IJAMS</td>\n",
       "      <td>SEAN HILL</td>\n",
       "      <td>STATE DISMISSES</td>\n",
       "      <td>https://www.oscn.net/dockets/GetCaseInformatio...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CF-2012-5914</td>\n",
       "      <td>Y</td>\n",
       "      <td>\\nJUDGE STEPHEN CLARK: DEFENDANT PRESENT NOT I...</td>\n",
       "      <td>STEPHEN CLARK</td>\n",
       "      <td>CARLOS WILLIAMS</td>\n",
       "      <td>ERIC LOGGIN</td>\n",
       "      <td>FIVE (5) YEAR DEFERRED SENTENCE\\nFIVE (5) YEAR...</td>\n",
       "      <td>https://www.oscn.net/dockets/GetCaseInformatio...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Docket Number Conviction                             NER Training Paragraph  \\\n",
       "0  CF-2012-5905          Y  JUDGE DAWN MOODY: DEFENDANT PRESENT NOT IN CUS...   \n",
       "1  CF-2012-5896          Y  JUDGE JAMES CAPUTO: DEFENDANT PRESENT REPRESEN...   \n",
       "2  CF-2012-5886          Y  JUDGE JAMES CAPUTO: DEFENDANT PRESENT IN CUSTO...   \n",
       "3  CF-2012-5591          N  JUDGE CLIFFORD SMITH: DEFENDANT PRESENT IN CUS...   \n",
       "4  CF-2012-5914          Y  \\nJUDGE STEPHEN CLARK: DEFENDANT PRESENT NOT I...   \n",
       "\n",
       "            Judge Defendant lawyer        State Rep  \\\n",
       "0      DAWN MOODY    SHEILA NAIFEH  JULIANNE BURTON   \n",
       "1    JAMES CAPUTO   DARRELL BOLTON      KALI STRAIN   \n",
       "2    JAMES CAPUTO   ADAM HASELGREN      KALI STRAIN   \n",
       "3  CLIFFORD SMITH       CLAY IJAMS        SEAN HILL   \n",
       "4   STEPHEN CLARK  CARLOS WILLIAMS      ERIC LOGGIN   \n",
       "\n",
       "                                          Sentencing  \\\n",
       "0                                      TWO (2) YEARS   \n",
       "1            TWO (2) YEARS DEPARTMENT OF CORRECTIONS   \n",
       "2       THREE (3) YEARS IN DEPARTMENT OF CORRECTIONS   \n",
       "3                                    STATE DISMISSES   \n",
       "4  FIVE (5) YEAR DEFERRED SENTENCE\\nFIVE (5) YEAR...   \n",
       "\n",
       "                                                Link  Year  \n",
       "0  https://www.oscn.net/dockets/GetCaseInformatio...  2012  \n",
       "1  https://www.oscn.net/dockets/GetCaseInformatio...  2012  \n",
       "2  https://www.oscn.net/dockets/GetCaseInformatio...  2012  \n",
       "3  https://www.oscn.net/dockets/GetCaseInformatio...  2012  \n",
       "4  https://www.oscn.net/dockets/GetCaseInformatio...  2012  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in data\n",
    "training = pd.read_csv('../../Data/judge_training_labels.csv')\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviewing the one record to validate\n",
    "#training.iloc[[n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of usage of the `lookUpDocket` function using the first row's Docket Number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse out the Docket number using the above function\n",
    "#testNum = training['Docket Number'][0]\n",
    "#case = lookUpDocket(testNum) #training['Docket Number'][0]\n",
    "#case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of usage of the `word_tokenize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return a tokenized copy of text\n",
    "#tokenizedCase = word_tokenize(case.text)\n",
    "#tokenizedCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling out the Judge, Defendant Lawyer & State Rep from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTags =[]\n",
    "for i in training.index:\n",
    "    case = lookUpDocket(training['Docket Number'][i])\n",
    "    data = pd.DataFrame(getTags(case,i), columns=['text', 'annotation'])\n",
    "    taggedSet = create_data(data)\n",
    "    allTags.append(taggedSet)\n",
    "#allTags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting a dictionary into a list of tuples\n",
    "\n",
    "`tagsToSent` takes the given tagged dictionary for each document and turns them into a list form. This `sentList` is now a list of lists that represent a single OSCN document's text: \n",
    "\n",
    "`[document1,document2...]`\n",
    "\n",
    "Sentences are the normal way documents are broken up and tagged. We are treating each OSCN document as a 'sentence' to keep documents together and for ease of assigning the entities to a case number. Each of these documents are made up of tagged word lists in tuple form:\n",
    "\n",
    "`[('OSCN','O'),...,('JANE', 'B-State Rep'), ('DOE', 'I-State Rep'),...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentList = tagsToSent(allTags)\n",
    "#sentList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pickle tagged data for later runs without invoking the OSCN scraper\n",
    "file_name = f'taggedNERSet'\n",
    "f = open(file_name, 'wb')\n",
    "pickle.dump(sentList, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pickled data from above tagging\n",
    "file_name = f'taggedNERSet'\n",
    "sentList2 = pickle.load(open(file_name, 'rb'))\n",
    "#testing load to new list to ensure we actually saved and reloaded\n",
    "#sentList2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running against a CRF Model\n",
    "\n",
    "Just for mechanics sake seeing if we've gotten the data into a state that it can be manipulated by a model (that's why test and train are the same set) Run the above cell that loads processed training data into sentList2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [sent2features(s) for s in sentList2]\n",
    "y = [sent2labels(s) for s in sentList2]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['B-Judge',\n",
    " 'B-State Rep',\n",
    " 'I-State Rep',\n",
    " 'B-Defendant lawyer',\n",
    " 'I-Defendant lawyer',\n",
    " 'I-Judge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A91237E3A0>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001A91237E640>},\n",
       "                   random_state=123, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%%time\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        random_state = 123)\n",
    "rs.fit(X_train, y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.08306892029976798, 'c2': 0.059459058557582024}\n",
      "best CV score: 0.9926190440948653\n",
      "model size: 0.20M\n",
      "Dark blue => 0.9917, dark red => 0.9926\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# standard metric outputs\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\n",
    "\n",
    "# extracting parameters from the grid search for plotting\n",
    "_x = [s['c1'] for s in rs.cv_results_['params']]\n",
    "_y = [s['c2'] for s in rs.cv_results_['params']]\n",
    "_c = rs.cv_results_['mean_test_score'].tolist()\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 8)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C1')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
    "    min(_c), max(_c)\n",
    "))\n",
    "\n",
    "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
    "\n",
    "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c1': 0.08306892029976798, 'c2': 0.059459058557582024}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs.best_params_list(my_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying optimal hyperparamters to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.08306892029976798,\n",
       "    c2=0.059459058557582024, keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1= 0.08306892029976798,\n",
    "    c2=0.059459058557582024,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-Judge',\n",
       " 'I-Judge',\n",
       " 'B-Defendant lawyer',\n",
       " 'I-Defendant lawyer',\n",
       " 'B-State Rep',\n",
       " 'I-State Rep']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5365921748370869"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "B-Defendant lawyer      0.783     0.439     0.562        41\n",
      "I-Defendant lawyer      0.759     0.500     0.603        44\n",
      "           B-Judge      0.789     0.395     0.526        38\n",
      "           I-Judge      0.727     0.372     0.492        43\n",
      "       B-State Rep      0.762     0.390     0.516        41\n",
      "       I-State Rep      0.762     0.390     0.516        41\n",
      "\n",
      "         micro avg      0.763     0.415     0.538       248\n",
      "         macro avg      0.764     0.414     0.536       248\n",
      "      weighted avg      0.763     0.415     0.537       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mapping\n",
    "\n",
    "Load in the previous run pickle data which includes the 3 key columns to train the model on in the right format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pickled data from above tagging\n",
    "file_name = f'taggedNERSet'\n",
    "sentList2 = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sentList2[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentList\n",
    "X_train = [sent2tokens(s) for s in sentList2]\n",
    "y_train = [sent2labels(s) for s in sentList2]\n",
    "\n",
    "#test is same as train just for functionality testing\n",
    "X_test = [sent2tokens(s) for s in sentList2]\n",
    "y_test = [sent2labels(s) for s in sentList2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('OSCN', 'O')\n",
      "('Case', 'O')\n",
      "('Details', 'O')\n",
      "('Skip', 'O')\n",
      "('to', 'O')\n",
      "('Main', 'O')\n",
      "('Content', 'O')\n",
      "('Accessibility', 'O')\n",
      "('Statement', 'O')\n",
      "('Help', 'O')\n",
      "('Contact', 'O')\n",
      "('Us', 'O')\n",
      "('epayments', 'O')\n",
      "('Careers', 'O')\n",
      "('toggle', 'O')\n",
      "('navigation', 'O')\n",
      "('Home', 'O')\n",
      "('Courts', 'O')\n",
      "('Decisions', 'O')\n",
      "('Programs', 'O')\n",
      "('News', 'O')\n",
      "('Legal', 'O')\n",
      "('Research', 'O')\n",
      "('Court', 'O')\n",
      "('Records', 'O')\n",
      "('Quick', 'O')\n",
      "('Links', 'O')\n",
      "('The', 'O')\n",
      "('information', 'O')\n",
      "('on', 'O')\n",
      "('this', 'O')\n",
      "('page', 'O')\n",
      "('is', 'O')\n",
      "('NOT', 'O')\n",
      "('an', 'O')\n",
      "('official', 'O')\n",
      "('record', 'O')\n",
      "('Do', 'O')\n",
      "('not', 'O')\n",
      "('rely', 'O')\n",
      "('the', 'O')\n",
      "('correctness', 'O')\n",
      "('or', 'O')\n",
      "('completeness', 'O')\n",
      "('of', 'O')\n",
      "('Verify', 'O')\n",
      "('all', 'O')\n",
      "('with', 'O')\n",
      "('keeper', 'O')\n",
      "('contained', 'O')\n",
      "('in', 'O')\n",
      "('report', 'O')\n",
      "('provided', 'O')\n",
      "('compliance', 'O')\n",
      "('Oklahoma', 'O')\n",
      "('Open', 'O')\n",
      "('Act', 'O')\n",
      "('51', 'O')\n",
      "('OS', 'O')\n",
      "('24A1', 'O')\n",
      "('Use', 'O')\n",
      "('governed', 'O')\n",
      "('by', 'O')\n",
      "('act', 'O')\n",
      "('as', 'O')\n",
      "('well', 'O')\n",
      "('other', 'O')\n",
      "('applicable', 'O')\n",
      "('state', 'O')\n",
      "('and', 'O')\n",
      "('federal', 'O')\n",
      "('laws', 'O')\n",
      "('In', 'O')\n",
      "('District', 'O')\n",
      "('for', 'O')\n",
      "('Tulsa', 'O')\n",
      "('County', 'O')\n",
      "('STATE', 'O')\n",
      "('OF', 'O')\n",
      "('OKLAHOMA', 'O')\n",
      "('Plaintiff', 'O')\n",
      "('v', 'O')\n",
      "('EDWARD', 'O')\n",
      "('MONTAGUS', 'O')\n",
      "('GRAMMER', 'O')\n",
      "('Defendant', 'O')\n",
      "('No', 'O')\n",
      "('CF20125896', 'O')\n",
      "('Criminal', 'O')\n",
      "('Felony', 'O')\n",
      "('Filed', 'O')\n",
      "('12312012Closed', 'O')\n",
      "('09092013Judge', 'O')\n",
      "('CF', 'O')\n",
      "('Docket', 'O')\n",
      "('E', 'O')\n",
      "('Parties', 'O')\n",
      "('Broken', 'O')\n",
      "('Arrow', 'O')\n",
      "('Police', 'O')\n",
      "('Department', 'O')\n",
      "('ARRESTING', 'O')\n",
      "('AGENCYGRAMMER', 'O')\n",
      "('DefendantSTATE', 'O')\n",
      "('Attorneys', 'O')\n",
      "('Attorney', 'O')\n",
      "('Represented', 'O')\n",
      "('BOLTON', 'I-Defendant lawyer')\n",
      "('DARRELL', 'B-Defendant lawyer')\n",
      "('L', 'O')\n",
      "('Bar', 'O')\n",
      "('9341408', 'O')\n",
      "('S', 'O')\n",
      "('DENVER', 'O')\n",
      "('AVETULSA', 'O')\n",
      "('OK', 'O')\n",
      "('74119', 'O')\n",
      "('Events', 'O')\n",
      "('Event', 'O')\n",
      "('Party', 'O')\n",
      "('Reporter', 'O')\n",
      "('Friday', 'O')\n",
      "('February', 'O')\n",
      "('22', 'O')\n",
      "('2013', 'O')\n",
      "('at', 'O')\n",
      "('900', 'O')\n",
      "('AM', 'O')\n",
      "('ARRAIGNMENT', 'O')\n",
      "('Arraignment', 'O')\n",
      "('March', 'O')\n",
      "('LAST', 'O')\n",
      "('PASS', 'O')\n",
      "('Monday', 'O')\n",
      "('April', 'O')\n",
      "('15', 'O')\n",
      "('PRELIMINARY', 'O')\n",
      "('HEARING', 'O')\n",
      "('ISSUE', 'O')\n",
      "('PRIVATE', 'O')\n",
      "('ATTORNEY', 'O')\n",
      "('Preliminary', 'O')\n",
      "('Hearing', 'O')\n",
      "('May', 'O')\n",
      "('6', 'O')\n",
      "('13', 'O')\n",
      "('DISTRICT', 'O')\n",
      "('COURT', 'O')\n",
      "('June', 'O')\n",
      "('10', 'O')\n",
      "('17', 'O')\n",
      "('July', 'O')\n",
      "('September', 'O')\n",
      "('9', 'O')\n",
      "('FINDING', 'O')\n",
      "('AND', 'O')\n",
      "('SENTENCING', 'O')\n",
      "('Tuesday', 'O')\n",
      "('24', 'O')\n",
      "('2015', 'O')\n",
      "('000', 'O')\n",
      "('COST', 'O')\n",
      "('ADMINISTRATION', 'O')\n",
      "('REVIEW', 'O')\n",
      "('Cost', 'O')\n",
      "('Admin', 'O')\n",
      "('Judge', 'O')\n",
      "('General', 'O')\n",
      "('Counts', 'O')\n",
      "('appear', 'O')\n",
      "('only', 'O')\n",
      "('under', 'O')\n",
      "('counts', 'O')\n",
      "('which', 'O')\n",
      "('they', 'O')\n",
      "('were', 'O')\n",
      "('charged', 'O')\n",
      "('For', 'O')\n",
      "('complete', 'O')\n",
      "('sentence', 'O')\n",
      "('see', 'O')\n",
      "('court', 'O')\n",
      "('minute', 'O')\n",
      "('docket', 'O')\n",
      "('Count', 'O')\n",
      "('1', 'O')\n",
      "('ABDGR', 'O')\n",
      "('ASSAULT', 'O')\n",
      "('WITH', 'O')\n",
      "('A', 'O')\n",
      "('DANGEROUS', 'O')\n",
      "('WEAPON', 'O')\n",
      "('violation', 'O')\n",
      "('21', 'O')\n",
      "('645Date', 'O')\n",
      "('Offense', 'O')\n",
      "('12252012', 'O')\n",
      "('Name', 'O')\n",
      "('Disposition', 'O')\n",
      "('Information', 'O')\n",
      "('Disposed', 'O')\n",
      "('CONVICTION', 'O')\n",
      "('09092013', 'O')\n",
      "('Guilty', 'O')\n",
      "('Plea', 'O')\n",
      "('WEAPONABDGR', 'O')\n",
      "('Violation', 'O')\n",
      "('645', 'O')\n",
      "('Date', 'O')\n",
      "('Code', 'O')\n",
      "('Description', 'O')\n",
      "('Amount', 'O')\n",
      "('12312012', 'O')\n",
      "('TEXT', 'O')\n",
      "('CRIMINAL', 'O')\n",
      "('FELONY', 'O')\n",
      "('INITIAL', 'O')\n",
      "('FILING', 'O')\n",
      "('Document', 'O')\n",
      "('Available', 'O')\n",
      "('Clerks', 'O')\n",
      "('Office', 'O')\n",
      "('INFORMATION', 'O')\n",
      "('DEFENDANT', 'O')\n",
      "('WAS', 'O')\n",
      "('CHARGED', 'O')\n",
      "('COUNT', 'O')\n",
      "('IN', 'O')\n",
      "('VIOLATION', 'O')\n",
      "('OCIS', 'O')\n",
      "('HAS', 'O')\n",
      "('AUTOMATICALLY', 'O')\n",
      "('ASSIGNED', 'O')\n",
      "('JUDGE', 'O')\n",
      "('DOCKET', 'O')\n",
      "('TO', 'O')\n",
      "('THIS', 'O')\n",
      "('CASE', 'O')\n",
      "('01042013', 'O')\n",
      "('RETRL', 'O')\n",
      "('RETURN', 'O')\n",
      "('RELEASE', 'O')\n",
      "('1020442088', 'O')\n",
      "('TIFF', 'O')\n",
      "('PDF', 'O')\n",
      "('01112013', 'O')\n",
      "('AFPCA', 'O')\n",
      "('AFFIDAVIT', 'O')\n",
      "('PROBABLE', 'O')\n",
      "('CAUSE', 'O')\n",
      "('TRACIS', 'O')\n",
      "('ARRESTED', 'O')\n",
      "('01172013', 'O')\n",
      "('CTFREE', 'O')\n",
      "('HOGSHEAD', 'O')\n",
      "('CHARLES', 'O')\n",
      "('PRESENT', 'O')\n",
      "('CUSTODY', 'O')\n",
      "('REPRESENTED', 'O')\n",
      "('BY', 'O')\n",
      "('COUNSEL', 'O')\n",
      "('PASSED', 'O')\n",
      "('2152013', 'O')\n",
      "('9AM', 'O')\n",
      "('ROOM', 'O')\n",
      "('173', 'O')\n",
      "('RECOGNIZED', 'O')\n",
      "('BACK', 'O')\n",
      "('BOND', 'O')\n",
      "('REMAIN', 'O')\n",
      "('02132013', 'O')\n",
      "('ENTERS', 'O')\n",
      "('STRIKE', 'O')\n",
      "('21513', 'O')\n",
      "('DATE', 'O')\n",
      "('RESET', 'O')\n",
      "('22213', 'O')\n",
      "('AT', 'O')\n",
      "('02222013', 'O')\n",
      "('CTPASS', 'O')\n",
      "('3222013', 'O')\n",
      "('03052013', 'O')\n",
      "('BOTRF', 'O')\n",
      "('FROM', 'O')\n",
      "('NF20127956', 'O')\n",
      "('DATED', 'O')\n",
      "('12282012', 'O')\n",
      "('BEEN', 'O')\n",
      "('TRANSFERRED', 'O')\n",
      "('THE', 'O')\n",
      "('ON', 'O')\n",
      "('IS', 'O')\n",
      "('AS', 'O')\n",
      "('FOLLOWS', 'O')\n",
      "('PROFESSIONAL', 'O')\n",
      "('FOR', 'O')\n",
      "('PROFESSIONALDAMPFAGUILAR', 'O')\n",
      "('ROBERTA', 'O')\n",
      "('NUMBER', 'O')\n",
      "('AMOUNT', 'O')\n",
      "('1000000', 'O')\n",
      "('POSTED', 'O')\n",
      "('1020977474', 'O')\n",
      "('1000', 'O')\n",
      "('BOJ', 'O')\n",
      "('JAIL', 'O')\n",
      "('FUND', 'O')\n",
      "('FEE', 'O')\n",
      "('2500', 'O')\n",
      "('CCADMIN25', 'O')\n",
      "('CLERK', 'O')\n",
      "('ADMINISTRATIVE', 'O')\n",
      "('25', 'O')\n",
      "('COLLECTIONS', 'O')\n",
      "('250', 'O')\n",
      "('03222013', 'O')\n",
      "('HELD', 'O')\n",
      "('WAIVES', 'O')\n",
      "('READING', 'O')\n",
      "('FURTHER', 'O')\n",
      "('TIME', 'O')\n",
      "('PLEAD', 'O')\n",
      "('PLEA', 'O')\n",
      "('GUILTY', 'O')\n",
      "('SET', 'O')\n",
      "('4152013', 'O')\n",
      "('158', 'O')\n",
      "('REMAINS', 'O')\n",
      "('03262013', 'O')\n",
      "('DAINS', 'O')\n",
      "('INSPECTION', 'O')\n",
      "('NOTIFICATION', 'O')\n",
      "('1021111574', 'O')\n",
      "('04152013', 'O')\n",
      "('DAVID', 'O')\n",
      "('YOULL', 'O')\n",
      "('MATT', 'O')\n",
      "('KEHOE', 'O')\n",
      "('STATES', 'O')\n",
      "('MOTION', 'O')\n",
      "('STATUS', 'O')\n",
      "('VICTIM', 'O')\n",
      "('ANDOR', 'O')\n",
      "('BE', 'O')\n",
      "('5613', 'O')\n",
      "('347', 'O')\n",
      "('RECOGNZIED', 'O')\n",
      "('05062013', 'O')\n",
      "('WAIPH', 'O')\n",
      "('WAIVER', 'O')\n",
      "('BIND', 'O')\n",
      "('OVER', 'O')\n",
      "('ORDER', 'O')\n",
      "('1021648999', 'O')\n",
      "('05072013', 'O')\n",
      "('CTPRLW', 'O')\n",
      "('STEPHEN', 'O')\n",
      "('CLARK', 'O')\n",
      "('TOM', 'O')\n",
      "('SAWYER', 'O')\n",
      "('REPORTER', 'O')\n",
      "('WAIVED', 'O')\n",
      "('CALLED', 'O')\n",
      "('HEREBY', 'O')\n",
      "('BINDS', 'O')\n",
      "('5132013', 'O')\n",
      "('900AM', 'O')\n",
      "('413', 'O')\n",
      "('BEFORE', 'O')\n",
      "('JAMES', 'B-Judge')\n",
      "('CAPUTO', 'I-Judge')\n",
      "('05132013', 'O')\n",
      "('KALI', 'B-State Rep')\n",
      "('STRAIN', 'I-State Rep')\n",
      "('6102013', 'O')\n",
      "('REQUEST', 'O')\n",
      "('06102013', 'O')\n",
      "('6172013', 'O')\n",
      "('06172013', 'O')\n",
      "('CAUTO', 'O')\n",
      "('7152013', 'O')\n",
      "('AGREEMENT', 'O')\n",
      "('07152013', 'O')\n",
      "('CTPLESEN', 'O')\n",
      "('BARBARA', 'O')\n",
      "('TIFFEE', 'O')\n",
      "('SWORN', 'O')\n",
      "('OPEN', 'O')\n",
      "('ADVISED', 'O')\n",
      "('RECOMMENDATION', 'O')\n",
      "('JURY', 'O')\n",
      "('TRIAL', 'O')\n",
      "('NONJURY', 'O')\n",
      "('ACCEPTS', 'O')\n",
      "('WITHHOLDS', 'O')\n",
      "('GUILT', 'O')\n",
      "('PRESENTENCING', 'O')\n",
      "('INVESTIGATION', 'O')\n",
      "('REPORT', 'O')\n",
      "('REQUESTED', 'O')\n",
      "('992013', 'O')\n",
      "('EXONERATED', 'O')\n",
      "('SIGNED', 'O')\n",
      "('PERSONAL', 'O')\n",
      "('RECOGNIZANCE', 'O')\n",
      "('07172013', 'O')\n",
      "('PR', 'O')\n",
      "('1022286442', 'O')\n",
      "('07192013', 'O')\n",
      "('WFPDA', 'O')\n",
      "('WITNESS', 'O')\n",
      "('FEES', 'O')\n",
      "('PAID', 'O')\n",
      "('62713', 'O')\n",
      "('1021945175', 'O')\n",
      "('2700', 'O')\n",
      "('07242013', 'O')\n",
      "('71613', 'O')\n",
      "('1022407548', 'O')\n",
      "('CONVICTED', 'O')\n",
      "('TINA', 'O')\n",
      "('ROSE', 'O')\n",
      "('PRESENTENCE', 'O')\n",
      "('RECEIVED', 'O')\n",
      "('COPIOES', 'O')\n",
      "('FURNISHED', 'O')\n",
      "('HAVING', 'O')\n",
      "('PREVIOUSLY', 'O')\n",
      "('ENTERED', 'O')\n",
      "('SAID', 'O')\n",
      "('FINDS', 'O')\n",
      "('SENTENCED', 'O')\n",
      "('TWO', 'O')\n",
      "('2', 'O')\n",
      "('YEARS', 'O')\n",
      "('DEPARTMENT', 'O')\n",
      "('CORRECTIONS', 'O')\n",
      "('FINED', 'O')\n",
      "('50000COSTS', 'O')\n",
      "('25000', 'O')\n",
      "('COMPENSATION', 'O')\n",
      "('ASSESSMENT', 'O')\n",
      "('SUBJECT', 'O')\n",
      "('NINE', 'O')\n",
      "('MONTHS', 'O')\n",
      "('ONE', 'O')\n",
      "('YEAR', 'O')\n",
      "('POST', 'O')\n",
      "('SUPERVISION', 'O')\n",
      "('APPEAL', 'O')\n",
      "('RIGHTS', 'O')\n",
      "('JUDGMENT', 'O')\n",
      "('SENTENCE', 'O')\n",
      "('ISSUED', 'O')\n",
      "('RULE', 'O')\n",
      "('8', 'O')\n",
      "('COSTF', 'O')\n",
      "('COSTS', 'O')\n",
      "('10300', 'O')\n",
      "('DACPAF', 'O')\n",
      "('DA', 'O')\n",
      "('COUNCIL', 'O')\n",
      "('PROSECUTION', 'O')\n",
      "('OCISR', 'O')\n",
      "('SYSTEM', 'O')\n",
      "('REVOLVING', 'O')\n",
      "('SSFCHS', 'O')\n",
      "('SHERIFFS', 'O')\n",
      "('SERVICE', 'O')\n",
      "('HOUSE', 'O')\n",
      "('SECURITY', 'O')\n",
      "('MELRF', 'O')\n",
      "('MEDICAL', 'O')\n",
      "('EXPENSE', 'O')\n",
      "('LIABILITY', 'O')\n",
      "('CLEET', 'O')\n",
      "('PENALTY', 'O')\n",
      "('PFE7', 'O')\n",
      "('LAW', 'O')\n",
      "('LIBRARY', 'O')\n",
      "('600', 'O')\n",
      "('FOREN', 'O')\n",
      "('FORENSIC', 'O')\n",
      "('SCIENCE', 'O')\n",
      "('IMPROVEMENT', 'O')\n",
      "('500', 'O')\n",
      "('SSF', 'O')\n",
      "('ARRESTS', 'O')\n",
      "('AFIS', 'O')\n",
      "('CHAB', 'O')\n",
      "('STATUTORY', 'O')\n",
      "('300', 'O')\n",
      "('AGVSU', 'O')\n",
      "('GENERAL', 'O')\n",
      "('SERVICES', 'O')\n",
      "('UNIT', 'O')\n",
      "('VCA', 'O')\n",
      "('VICTIMS', 'O')\n",
      "('AC12', 'O')\n",
      "('FINE', 'O')\n",
      "('FINES', 'O')\n",
      "('PAYABLE', 'O')\n",
      "('COUNTY', 'O')\n",
      "('50000', 'O')\n",
      "('CCADMIN', 'O')\n",
      "('700', 'O')\n",
      "('BDXON', 'O')\n",
      "('ENTRY', 'O')\n",
      "('DETAILED', 'O')\n",
      "('SERIAL', 'O')\n",
      "('84711452', 'O')\n",
      "('ABOVE', 'O')\n",
      "('CHANGED', 'O')\n",
      "('READ', 'O')\n",
      "('86107725', 'O')\n",
      "('09102013', 'O')\n",
      "('PSIR', 'O')\n",
      "('1022803290', 'O')\n",
      "('09162013', 'O')\n",
      "('JS', 'O')\n",
      "('1022935581', 'O')\n",
      "('09172013', 'O')\n",
      "('PGSF', 'O')\n",
      "('SUMMARY', 'O')\n",
      "('FACTS', 'O')\n",
      "('1022950308', 'O')\n",
      "('09182013', 'O')\n",
      "('CNOTE', 'O')\n",
      "('DOC', 'O')\n",
      "('GIVEN', 'O')\n",
      "('WEEKS', 'O')\n",
      "('AFTER', 'O')\n",
      "('RELEASED', 'O')\n",
      "('MAKE', 'O')\n",
      "('PAYMENT', 'O')\n",
      "('PLAN', 'O')\n",
      "('09192013', 'O')\n",
      "('RULE8', 'O')\n",
      "('1022448503', 'O')\n",
      "('10042013', 'O')\n",
      "('RETCP', 'O')\n",
      "('COMMITMENT', 'O')\n",
      "('PUNISHMENT', 'O')\n",
      "('1023043525', 'O')\n",
      "('10112013', 'O')\n",
      "('RETJS', 'O')\n",
      "('1023174592', 'O')\n",
      "('5000', 'O')\n",
      "('08202014', 'O')\n",
      "('CTPPA', 'O')\n",
      "('OR', 'O')\n",
      "('101914', 'O')\n",
      "('DUE', 'O')\n",
      "('19TH', 'O')\n",
      "('DAY', 'O')\n",
      "('EACH', 'O')\n",
      "('MONTH', 'O')\n",
      "('CONTINUING', 'O')\n",
      "('UNTIL', 'O')\n",
      "('CASES', 'O')\n",
      "('FULL', 'O')\n",
      "('YOUR', 'O')\n",
      "('32415', 'O')\n",
      "('AUTHORIZATION', 'O')\n",
      "('81814', 'O')\n",
      "('ALSO', 'O')\n",
      "('SEE', 'O')\n",
      "('CM13925CF13862CF125896', 'O')\n",
      "('1026740097', 'O')\n",
      "('10182016', 'O')\n",
      "('CTRS', 'O')\n",
      "('CLAIM', 'O')\n",
      "('INTERCEPT', 'O')\n",
      "('TAX', 'O')\n",
      "('REFUND', 'O')\n",
      "('10102017', 'O')\n",
      "('10092019', 'O')\n",
      "('10052020', 'O')\n",
      "('oscn', 'O')\n",
      "('EMAIL', 'O')\n",
      "('webmasteroscnnet', 'O')\n",
      "('Judicial', 'O')\n",
      "('Center', 'O')\n",
      "('2100', 'O')\n",
      "('N', 'O')\n",
      "('Lincoln', 'O')\n",
      "('Blvd', 'O')\n",
      "('City', 'O')\n",
      "('73105', 'O')\n",
      "('courts', 'O')\n",
      "('Supreme', 'O')\n",
      "('Appeals', 'O')\n",
      "('Civil', 'O')\n",
      "('decisions', 'O')\n",
      "('New', 'O')\n",
      "('programs', 'O')\n",
      "('Sovereignty', 'O')\n",
      "('Symposium', 'O')\n",
      "('Alternative', 'O')\n",
      "('Dispute', 'O')\n",
      "('Resolution', 'O')\n",
      "('Early', 'O')\n",
      "('Settlement', 'O')\n",
      "('Mediation', 'O')\n",
      "('Childrens', 'O')\n",
      "('Improvement', 'O')\n",
      "('Program', 'O')\n",
      "('CIP', 'O')\n",
      "('Nominating', 'O')\n",
      "('Commission', 'O')\n",
      "('Certified', 'O')\n",
      "('Courtroom', 'O')\n",
      "('Interpreters', 'O')\n",
      "('Shorthand', 'O')\n",
      "('Reporters', 'O')\n",
      "('ADA', 'O')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(X_train[1],y_train[1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def trainingSetToWordMap(X_train):\n",
    "    words = []\n",
    "    for entry in X_train:\n",
    "        for word in entry:\n",
    "            words.append(word)\n",
    "    #Unique words counted in the dockets, then mapping the words to a number (which will then be used in the NN)\n",
    "    wc = Counter(words)\n",
    "    print(len(wc))\n",
    "    word_map = {}\n",
    "    for i,(k,v) in enumerate(wc.most_common()):\n",
    "        word_map[k] = i+2 #starting sequence after unknowns\n",
    "    word_map['<pad>']=0 #padding values\n",
    "    word_map['<unk>']=1 #unknown values\n",
    "    return word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15841\n"
     ]
    }
   ],
   "source": [
    "word_map= trainingSetToWordMap(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OSCN': 2,\n",
       " 'Case': 3,\n",
       " 'Details': 4,\n",
       " 'Skip': 5,\n",
       " 'to': 6,\n",
       " 'Main': 7,\n",
       " 'Content': 8,\n",
       " 'Accessibility': 9,\n",
       " 'Statement': 10,\n",
       " 'Help': 11,\n",
       " 'Contact': 12,\n",
       " 'Us': 13,\n",
       " 'epayments': 14,\n",
       " 'Careers': 15,\n",
       " 'toggle': 16,\n",
       " 'navigation': 17,\n",
       " 'Home': 18,\n",
       " 'Courts': 19,\n",
       " 'Decisions': 20,\n",
       " 'Programs': 21,\n",
       " 'News': 22,\n",
       " 'Legal': 23,\n",
       " 'Research': 24,\n",
       " 'Court': 25,\n",
       " 'Records': 26,\n",
       " 'Quick': 27,\n",
       " 'Links': 28,\n",
       " 'The': 29,\n",
       " 'information': 30,\n",
       " 'on': 31,\n",
       " 'this': 32,\n",
       " 'page': 33,\n",
       " 'is': 34,\n",
       " 'NOT': 35,\n",
       " 'an': 36,\n",
       " 'official': 37,\n",
       " 'record': 38,\n",
       " 'Do': 39,\n",
       " 'not': 40,\n",
       " 'rely': 41,\n",
       " 'the': 42,\n",
       " 'correctness': 43,\n",
       " 'or': 44,\n",
       " 'completeness': 45,\n",
       " 'of': 46,\n",
       " 'Verify': 47,\n",
       " 'all': 48,\n",
       " 'with': 49,\n",
       " 'keeper': 50,\n",
       " 'contained': 51,\n",
       " 'in': 52,\n",
       " 'report': 53,\n",
       " 'provided': 54,\n",
       " 'compliance': 55,\n",
       " 'Oklahoma': 56,\n",
       " 'Open': 57,\n",
       " 'Act': 58,\n",
       " '51': 59,\n",
       " 'OS': 60,\n",
       " '24A1': 61,\n",
       " 'Use': 62,\n",
       " 'governed': 63,\n",
       " 'by': 64,\n",
       " 'act': 65,\n",
       " 'as': 66,\n",
       " 'well': 67,\n",
       " 'other': 68,\n",
       " 'applicable': 69,\n",
       " 'state': 70,\n",
       " 'and': 71,\n",
       " 'federal': 72,\n",
       " 'laws': 73,\n",
       " 'In': 74,\n",
       " 'District': 75,\n",
       " 'for': 76,\n",
       " 'Tulsa': 77,\n",
       " 'County': 78,\n",
       " 'No': 79,\n",
       " 'Criminal': 80,\n",
       " 'Felony': 81,\n",
       " 'Filed': 82,\n",
       " 'Docket': 83,\n",
       " 'Parties': 84,\n",
       " 'Attorneys': 85,\n",
       " 'Events': 86,\n",
       " 'Counts': 87,\n",
       " 'appear': 88,\n",
       " 'only': 89,\n",
       " 'under': 90,\n",
       " 'counts': 91,\n",
       " 'which': 92,\n",
       " 'they': 93,\n",
       " 'were': 94,\n",
       " 'charged': 95,\n",
       " 'For': 96,\n",
       " 'complete': 97,\n",
       " 'sentence': 98,\n",
       " 'see': 99,\n",
       " 'court': 100,\n",
       " 'minute': 101,\n",
       " 'docket': 102,\n",
       " 'oscn': 103,\n",
       " 'EMAIL': 104,\n",
       " 'webmasteroscnnet': 105,\n",
       " 'Judicial': 106,\n",
       " 'Center': 107,\n",
       " '2100': 108,\n",
       " 'N': 109,\n",
       " 'Lincoln': 110,\n",
       " 'Blvd': 111,\n",
       " 'City': 112,\n",
       " 'OK': 113,\n",
       " '73105': 114,\n",
       " 'courts': 115,\n",
       " 'Supreme': 116,\n",
       " 'Appeals': 117,\n",
       " 'Civil': 118,\n",
       " 'decisions': 119,\n",
       " 'New': 120,\n",
       " 'programs': 121,\n",
       " 'Sovereignty': 122,\n",
       " 'Symposium': 123,\n",
       " 'Alternative': 124,\n",
       " 'Dispute': 125,\n",
       " 'Resolution': 126,\n",
       " 'Early': 127,\n",
       " 'Settlement': 128,\n",
       " 'Mediation': 129,\n",
       " 'Childrens': 130,\n",
       " 'Improvement': 131,\n",
       " 'Program': 132,\n",
       " 'CIP': 133,\n",
       " 'Nominating': 134,\n",
       " 'Commission': 135,\n",
       " 'Certified': 136,\n",
       " 'Courtroom': 137,\n",
       " 'Interpreters': 138,\n",
       " 'Shorthand': 139,\n",
       " 'Reporters': 140,\n",
       " 'ADA': 141,\n",
       " 'STATE': 142,\n",
       " 'OF': 143,\n",
       " 'OKLAHOMA': 144,\n",
       " 'v': 145,\n",
       " 'CF': 146,\n",
       " 'ARRESTING': 147,\n",
       " 'Event': 148,\n",
       " 'Party': 149,\n",
       " 'Reporter': 150,\n",
       " 'at': 151,\n",
       " 'PRELIMINARY': 152,\n",
       " 'HEARING': 153,\n",
       " 'Count': 154,\n",
       " '1': 155,\n",
       " 'violation': 156,\n",
       " 'Offense': 157,\n",
       " 'Name': 158,\n",
       " 'Disposition': 159,\n",
       " 'Information': 160,\n",
       " 'Disposed': 161,\n",
       " 'Violation': 162,\n",
       " 'TO': 163,\n",
       " 'Date': 164,\n",
       " 'Code': 165,\n",
       " 'Description': 166,\n",
       " 'Amount': 167,\n",
       " 'TEXT': 168,\n",
       " 'CRIMINAL': 169,\n",
       " 'FELONY': 170,\n",
       " 'INITIAL': 171,\n",
       " 'FILING': 172,\n",
       " 'Document': 173,\n",
       " 'Available': 174,\n",
       " 'INFORMATION': 175,\n",
       " 'DEFENDANT': 176,\n",
       " 'WAS': 177,\n",
       " 'CHARGED': 178,\n",
       " 'WITH': 179,\n",
       " 'COUNT': 180,\n",
       " 'IN': 181,\n",
       " 'VIOLATION': 182,\n",
       " 'OCIS': 183,\n",
       " 'HAS': 184,\n",
       " 'AUTOMATICALLY': 185,\n",
       " 'ASSIGNED': 186,\n",
       " 'JUDGE': 187,\n",
       " 'THIS': 188,\n",
       " 'CASE': 189,\n",
       " 'PRESENT': 190,\n",
       " 'CUSTODY': 191,\n",
       " 'AND': 192,\n",
       " 'REPRESENTED': 193,\n",
       " 'BY': 194,\n",
       " 'THE': 195,\n",
       " 'A': 196,\n",
       " 'PLEA': 197,\n",
       " 'GUILTY': 198,\n",
       " 'FOR': 199,\n",
       " 'ROOM': 200,\n",
       " 'BOND': 201,\n",
       " 'Attorney': 202,\n",
       " 'Represented': 203,\n",
       " 'ARRAIGNMENT': 204,\n",
       " 'Clerks': 205,\n",
       " 'Office': 206,\n",
       " 'WAIVES': 207,\n",
       " 'TIME': 208,\n",
       " 'ENTERS': 209,\n",
       " 'SET': 210,\n",
       " 'ATTORNEY': 211,\n",
       " 'AM': 212,\n",
       " 'ISSUE': 213,\n",
       " 'HELD': 214,\n",
       " 'AFFIDAVIT': 215,\n",
       " 'DISTRICT': 216,\n",
       " 'COURT': 217,\n",
       " 'READING': 218,\n",
       " 'FURTHER': 219,\n",
       " 'PLEAD': 220,\n",
       " 'ISSUED': 221,\n",
       " 'ON': 222,\n",
       " 'RETURN': 223,\n",
       " 'Department': 224,\n",
       " 'Preliminary': 225,\n",
       " 'Hearing': 226,\n",
       " 'FINDING': 227,\n",
       " 'ORDER': 228,\n",
       " '900': 229,\n",
       " 'COST': 230,\n",
       " '2500': 231,\n",
       " 'DOCKET': 232,\n",
       " 'CAUSE': 233,\n",
       " 'FUND': 234,\n",
       " 'Plaintiff': 235,\n",
       " 'PROBABLE': 236,\n",
       " 'OCISR': 237,\n",
       " 'SYSTEM': 238,\n",
       " 'REVOLVING': 239,\n",
       " 'Defendant': 240,\n",
       " 'AMOUNT': 241,\n",
       " 'RELEASE': 242,\n",
       " '5000': 243,\n",
       " 'IS': 244,\n",
       " 'FEE': 245,\n",
       " '1000': 246,\n",
       " 'PROSECUTION': 247,\n",
       " 'ADMINISTRATIVE': 248,\n",
       " 'CLERK': 249,\n",
       " 'COUNTY': 250,\n",
       " '8': 251,\n",
       " 'COSTS': 252,\n",
       " 'VICTIM': 253,\n",
       " 'COLLECTIONS': 254,\n",
       " 'TIFF': 255,\n",
       " 'PDF': 256,\n",
       " 'SERVICE': 257,\n",
       " 'MEDICAL': 258,\n",
       " 'LIABILITY': 259,\n",
       " 'AT': 260,\n",
       " 'INSPECTION': 261,\n",
       " 'SENTENCE': 262,\n",
       " 'RULE': 263,\n",
       " 'DA': 264,\n",
       " 'COUNCIL': 265,\n",
       " 'ASSESSMENT': 266,\n",
       " 'SSFCHS': 267,\n",
       " 'SHERIFFS': 268,\n",
       " 'HOUSE': 269,\n",
       " 'SECURITY': 270,\n",
       " 'CLEET': 271,\n",
       " 'PENALTY': 272,\n",
       " 'PFE7': 273,\n",
       " 'LAW': 274,\n",
       " 'LIBRARY': 275,\n",
       " '600': 276,\n",
       " 'FOREN': 277,\n",
       " 'FORENSIC': 278,\n",
       " 'SCIENCE': 279,\n",
       " 'IMPROVEMENT': 280,\n",
       " '500': 281,\n",
       " 'SSF': 282,\n",
       " 'ARRESTS': 283,\n",
       " 'AFIS': 284,\n",
       " 'CHAB': 285,\n",
       " 'STATUTORY': 286,\n",
       " '300': 287,\n",
       " 'AGVSU': 288,\n",
       " 'GENERAL': 289,\n",
       " 'SERVICES': 290,\n",
       " 'UNIT': 291,\n",
       " 'MELRF': 292,\n",
       " 'EXPENSE': 293,\n",
       " 'Police': 294,\n",
       " 'DAINS': 295,\n",
       " 'ADVISED': 296,\n",
       " 'APPEAL': 297,\n",
       " 'CCADMIN': 298,\n",
       " 'RULE8': 299,\n",
       " 'RIGHTS': 300,\n",
       " 'Plea': 301,\n",
       " 'NOTIFICATION': 302,\n",
       " 'DefendantSTATE': 303,\n",
       " 'Guilty': 304,\n",
       " 'CTARRPL': 305,\n",
       " 'EXONERATED': 306,\n",
       " 'AS': 307,\n",
       " 'JURY': 308,\n",
       " 'TRIAL': 309,\n",
       " 'TULSA': 310,\n",
       " '21': 311,\n",
       " 'PAYMENT': 312,\n",
       " 'CTFREE': 313,\n",
       " '2': 314,\n",
       " '9AM': 315,\n",
       " 'RETRL': 316,\n",
       " 'RECEIPT': 317,\n",
       " 'JUDGMENT': 318,\n",
       " 'PlaintiffTulsa': 319,\n",
       " 'REMAIN': 320,\n",
       " 'Friday': 321,\n",
       " 'AGENCY': 322,\n",
       " 'REPORTER': 323,\n",
       " 'ADMINISTRATION': 324,\n",
       " 'REMANDED': 325,\n",
       " 'VICTIMS': 326,\n",
       " 'JAIL': 327,\n",
       " 'Monday': 328,\n",
       " 'COMPENSATION': 329,\n",
       " 'DACPAF': 330,\n",
       " 'VCA': 331,\n",
       " 'February': 332,\n",
       " 'January': 333,\n",
       " 'OVER': 334,\n",
       " 'AFPCA': 335,\n",
       " 'TRACIS': 336,\n",
       " 'ARRESTED': 337,\n",
       " 'COSTF': 338,\n",
       " '10300': 339,\n",
       " 'AC12': 340,\n",
       " '000': 341,\n",
       " 'Judge': 342,\n",
       " 'CTRS': 343,\n",
       " 'CLAIM': 344,\n",
       " 'INTERCEPT': 345,\n",
       " 'TAX': 346,\n",
       " 'REFUND': 347,\n",
       " 'General': 348,\n",
       " 'BE': 349,\n",
       " 'BEFORE': 350,\n",
       " 'SUMMARY': 351,\n",
       " 'FACTS': 352,\n",
       " 'SWORN': 353,\n",
       " 'PUBLIC': 354,\n",
       " 'PASSED': 355,\n",
       " 'PGSF': 356,\n",
       " '10052020': 357,\n",
       " 'FROM': 358,\n",
       " 'JS': 359,\n",
       " 'PAID': 360,\n",
       " 'WARRANT': 361,\n",
       " 'DEFENDER': 362,\n",
       " 'CONVICTION': 363,\n",
       " 'ACCEPTS': 364,\n",
       " 'PLUS': 365,\n",
       " 'Cost': 366,\n",
       " 'Admin': 367,\n",
       " 'OPEN': 368,\n",
       " 'YEARS': 369,\n",
       " 'FINES': 370,\n",
       " 'REPORT': 371,\n",
       " 'Tuesday': 372,\n",
       " 'CONVICTED': 373,\n",
       " 'COMMITMENT': 374,\n",
       " 'COUNSEL': 375,\n",
       " 'DEPARTMENT': 376,\n",
       " 'PAUPERS': 377,\n",
       " 'DISCOVERY': 378,\n",
       " 'DUE': 379,\n",
       " 'PA': 380,\n",
       " 'ADISC': 381,\n",
       " 'ACKNOWLEDGEMENT': 382,\n",
       " 'RECOGNIZED': 383,\n",
       " 'BACK': 384,\n",
       " 'FEES': 385,\n",
       " 'WAIVER': 386,\n",
       " 'CORRECTIONS': 387,\n",
       " 'REVIEW': 388,\n",
       " 'CTPASS': 389,\n",
       " 'FINE': 390,\n",
       " 'CNOTE': 391,\n",
       " 'RETURNED': 392,\n",
       " 'OR': 393,\n",
       " 'EACH': 394,\n",
       " 'REQUEST': 395,\n",
       " 'NO': 396,\n",
       " 'APPOINTED': 397,\n",
       " 'SENTENCED': 398,\n",
       " 'UNDER': 399,\n",
       " '3': 400,\n",
       " 'BIND': 401,\n",
       " 'ALL': 402,\n",
       " 'WAIPH': 403,\n",
       " 'PAYABLE': 404,\n",
       " 'SENT': 405,\n",
       " 'DAY': 406,\n",
       " 'SUPERVISION': 407,\n",
       " 'Wednesday': 408,\n",
       " 'March': 409,\n",
       " 'FOLLOWS': 410,\n",
       " 'DAVID': 411,\n",
       " 'CALLED': 412,\n",
       " 'PLAN': 413,\n",
       " 'Thursday': 414,\n",
       " 'POSTED': 415,\n",
       " 'UNTIL': 416,\n",
       " 'ASSESSED': 417,\n",
       " 'RUN': 418,\n",
       " 'WAIVED': 419,\n",
       " 'NUMBER': 420,\n",
       " 'OFFICE': 421,\n",
       " '9': 422,\n",
       " 'FAILED': 423,\n",
       " 'April': 424,\n",
       " 'FULL': 425,\n",
       " 'BENCH': 426,\n",
       " 'May': 427,\n",
       " 'NOTICE': 428,\n",
       " 'MONTH': 429,\n",
       " 'CONTINUING': 430,\n",
       " 'DATE': 431,\n",
       " '344': 432,\n",
       " '347': 433,\n",
       " '15000': 434,\n",
       " 'CTPPA': 435,\n",
       " 'CASES': 436,\n",
       " 'STATUS': 437,\n",
       " 'June': 438,\n",
       " 'REASSIGNED': 439,\n",
       " 'NON': 440,\n",
       " 'ENTRY': 441,\n",
       " 'RETCO': 442,\n",
       " '173': 443,\n",
       " 'SERVED': 444,\n",
       " '25': 445,\n",
       " 'July': 446,\n",
       " 'August': 447,\n",
       " 'Arraignment': 448,\n",
       " 'JAMES': 449,\n",
       " 'APPLICATION': 450,\n",
       " 'FINDS': 451,\n",
       " '4': 452,\n",
       " 'LETTER': 453,\n",
       " '10092019': 454,\n",
       " 'DRUG': 455,\n",
       " 'CARE': 456,\n",
       " 'PM': 457,\n",
       " 'SMITH': 458,\n",
       " 'SUSPENDED': 459,\n",
       " 'TCARF': 460,\n",
       " 'TRAUMA': 461,\n",
       " 'ASSISTANCE': 462,\n",
       " '10': 463,\n",
       " 'RECORD': 464,\n",
       " '5': 465,\n",
       " 'SEE': 466,\n",
       " 'ONE': 467,\n",
       " 'TOTAL': 468,\n",
       " 'WILLIAM': 469,\n",
       " 'PER': 470,\n",
       " 'DCADMIN': 471,\n",
       " 'C': 472,\n",
       " 'HEREBY': 473,\n",
       " 'CREDIT': 474,\n",
       " 'B': 475,\n",
       " 'PROFESSIONAL': 476,\n",
       " 'DEFENDERS': 477,\n",
       " 'LUDI': 478,\n",
       " 'LEITCH': 479,\n",
       " 'ACCOUNT': 480,\n",
       " 'LINE': 481,\n",
       " 'ITEMS': 482,\n",
       " 'ORDERED': 483,\n",
       " '10000': 484,\n",
       " 'September': 485,\n",
       " '10102017': 486,\n",
       " 'SENTENCING': 487,\n",
       " 'RETBW': 488,\n",
       " '2020': 489,\n",
       " '30': 490,\n",
       " 'DOC': 491,\n",
       " 'PRIVATE': 492,\n",
       " 'December': 493,\n",
       " '6': 494,\n",
       " 'PAY': 495,\n",
       " 'PREVIOUSLY': 496,\n",
       " 'CONDITIONS': 497,\n",
       " '24': 498,\n",
       " 'Bar': 499,\n",
       " '18': 500,\n",
       " 'AC01': 501,\n",
       " 'REASSIGNMENT': 502,\n",
       " '930': 503,\n",
       " 'MOTION': 504,\n",
       " '3500': 505,\n",
       " 'CHANGED': 506,\n",
       " 'O': 507,\n",
       " 'ADMININISTRATION': 508,\n",
       " '12': 509,\n",
       " 'POSSESSION': 510,\n",
       " 'DPS': 511,\n",
       " '130': 512,\n",
       " 'TRANSFERRED': 513,\n",
       " 'D': 514,\n",
       " '22': 515,\n",
       " 'DEFENDANTS': 516,\n",
       " 'ORC': 517,\n",
       " 'PROBATION': 518,\n",
       " 'BO': 519,\n",
       " 'POWER': 520,\n",
       " 'COMPLETE': 521,\n",
       " 'RELEASED': 522,\n",
       " 'AMENDED': 523,\n",
       " 'MISDEMEANOR': 524,\n",
       " 'DETAILED': 525,\n",
       " 'SERIAL': 526,\n",
       " 'ABOVE': 527,\n",
       " 'READ': 528,\n",
       " 'AFTER': 529,\n",
       " '901': 530,\n",
       " '2019': 531,\n",
       " 'APPEAR': 532,\n",
       " 'CONCURRENT': 533,\n",
       " 'AUTHORIZATION': 534,\n",
       " 'GUTEN': 535,\n",
       " 'ARREST': 536,\n",
       " '900AM': 537,\n",
       " '250': 538,\n",
       " 'CTARRPA': 539,\n",
       " 'PUNISHMENT': 540,\n",
       " 'WITNESS': 541,\n",
       " 'PAYOR': 542,\n",
       " '10182016': 543,\n",
       " 'STATES': 544,\n",
       " 'DAYS': 545,\n",
       " '13': 546,\n",
       " 'ENTERED': 547,\n",
       " '25000': 548,\n",
       " 'November': 549,\n",
       " 'DEBORRAH': 550,\n",
       " 'DACPAM': 551,\n",
       " 'JUDGEMENT': 552,\n",
       " 'J': 553,\n",
       " 'E': 554,\n",
       " 'YOULL': 555,\n",
       " 'TWO': 556,\n",
       " '700': 557,\n",
       " 'BEEN': 558,\n",
       " '60000': 559,\n",
       " 'RULES': 560,\n",
       " '2017': 561,\n",
       " '3000': 562,\n",
       " 'APPEARANCE': 563,\n",
       " '100000': 564,\n",
       " 'FAILURE': 565,\n",
       " '130PM': 566,\n",
       " '50000': 567,\n",
       " 'ABST': 568,\n",
       " 'ABSTRACT': 569,\n",
       " '20': 570,\n",
       " '2015': 571,\n",
       " 'COSTM': 572,\n",
       " '8300': 573,\n",
       " 'BDXON': 574,\n",
       " '27': 575,\n",
       " '15': 576,\n",
       " 'WITHHOLDS': 577,\n",
       " 'ENTER': 578,\n",
       " '2018': 579,\n",
       " '17': 580,\n",
       " 'October': 581,\n",
       " 'STRICKEN': 582,\n",
       " 'MILLER': 583,\n",
       " '2000': 584,\n",
       " 'GIVEN': 585,\n",
       " '16': 586,\n",
       " '930AM': 587,\n",
       " 'CTFD': 588,\n",
       " '11': 589,\n",
       " 'KEELEY': 590,\n",
       " 'COUNTS': 591,\n",
       " '28': 592,\n",
       " '47': 593,\n",
       " 'RIGHT': 594,\n",
       " 'DATED': 595,\n",
       " 'ODEF': 596,\n",
       " 'RE': 597,\n",
       " 'DISMISSED': 598,\n",
       " 'CT1': 599,\n",
       " 'NEEDS': 600,\n",
       " 'MOODY': 601,\n",
       " 'VEHICLE': 602,\n",
       " 'BINDS': 603,\n",
       " '2016': 604,\n",
       " 'DEFERRED': 605,\n",
       " 'BOTRF': 606,\n",
       " 'BOJ': 607,\n",
       " 'CCADMIN25': 608,\n",
       " 'AUTHORIZED': 609,\n",
       " '26': 610,\n",
       " 'SENTENCES': 611,\n",
       " 'GUILT': 612,\n",
       " 'WAI': 613,\n",
       " 'RETWA': 614,\n",
       " 'PROGRAM': 615,\n",
       " '23': 616,\n",
       " 'ATTORNEYS': 617,\n",
       " 'ASSESSMENTS': 618,\n",
       " '63': 619,\n",
       " 'YEAR': 620,\n",
       " 'ALSO': 621,\n",
       " 'RETCP': 622,\n",
       " '19': 623,\n",
       " 'REGARDING': 624,\n",
       " 'APPLICATIONMOTION': 625,\n",
       " 'WFPDA': 626,\n",
       " 'CONTACT': 627,\n",
       " '7': 628,\n",
       " 'CT': 629,\n",
       " 'ANTHONY': 630,\n",
       " 'BASED': 631,\n",
       " 'CTPRLW': 632,\n",
       " 'EXECUTED': 633,\n",
       " 'MAKE': 634,\n",
       " 'CONTROLLED': 635,\n",
       " '30000': 636,\n",
       " 'THREE': 637,\n",
       " 'CLIFF': 638,\n",
       " '14': 639,\n",
       " 'NONE': 640,\n",
       " '31': 641,\n",
       " 'PR': 642,\n",
       " 'COPY': 643,\n",
       " 'FORM': 644,\n",
       " 'SERVE': 645,\n",
       " '329': 646,\n",
       " 'State': 647,\n",
       " 'RETJS': 648,\n",
       " '10022015': 649,\n",
       " 'JURISDICTION': 650,\n",
       " 'REVOKE': 651,\n",
       " '29': 652,\n",
       " 'Dismissed': 653,\n",
       " 'S': 654,\n",
       " 'EARNED': 655,\n",
       " 'DISPOSITION': 656,\n",
       " 'STEPHANIE': 657,\n",
       " 'PARTIES': 658,\n",
       " 'REDUCED': 659,\n",
       " 'CTACRVBW': 660,\n",
       " 'CONFESSES': 661,\n",
       " 'CONFESSION': 662,\n",
       " 'HIDDLE': 663,\n",
       " 'AFPC': 664,\n",
       " 'PATROL': 665,\n",
       " 'MONTHS': 666,\n",
       " '2021': 667,\n",
       " '500000': 668,\n",
       " 'MAIL': 669,\n",
       " '1060': 670,\n",
       " '1590': 671,\n",
       " '1500': 672,\n",
       " '2014': 673,\n",
       " 'WEEKS': 674,\n",
       " 'ADJUSTING': 675,\n",
       " 'JOHN': 676,\n",
       " 'RPT': 677,\n",
       " 'RECALLED': 678,\n",
       " 'AC31': 679,\n",
       " 'CONCURRENTLY': 680,\n",
       " 'DPSFEE': 681,\n",
       " 'JURYNON': 682,\n",
       " 'SUPERVISED': 683,\n",
       " 'PREVIOUS': 684,\n",
       " 'ADVISEMENT': 685,\n",
       " 'CONA': 686,\n",
       " 'NEW': 687,\n",
       " 'PAROLE': 688,\n",
       " '991': 689,\n",
       " 'AKA': 690,\n",
       " '2ND': 691,\n",
       " 'FOLLOWING': 692,\n",
       " 'MULTICOUNTY': 693,\n",
       " 'ABUSE': 694,\n",
       " '7500': 695,\n",
       " 'CTBWFTA': 696,\n",
       " 'CONTINUED': 697,\n",
       " 'RESET': 698,\n",
       " 'CARD': 699,\n",
       " 'RECALL': 700,\n",
       " 'CANCELLATION': 701,\n",
       " 'BWR': 702,\n",
       " 'WRCR': 703,\n",
       " 'ALLEGATIONS': 704,\n",
       " 'JOHNSON': 705,\n",
       " 'AC79': 706,\n",
       " 'BWIFA': 707,\n",
       " 'MO': 708,\n",
       " 'MAKES': 709,\n",
       " 'F': 710,\n",
       " 'OTHER': 711,\n",
       " 'PD': 712,\n",
       " 'KEVIN': 713,\n",
       " 'RM': 714,\n",
       " 'WRCI': 715,\n",
       " 'SIGNED': 716,\n",
       " 'FORFEITED': 717,\n",
       " 'AOC': 718,\n",
       " 'Drug': 719,\n",
       " 'DAWN': 720,\n",
       " 'UPON': 721,\n",
       " 'WAIVE': 722,\n",
       " 'ADJUST': 723,\n",
       " 'MONIES': 724,\n",
       " 'AC09CARD': 725,\n",
       " 'ALLOCATION': 726,\n",
       " 'AGENCIES': 727,\n",
       " 'AC09': 728,\n",
       " 'ALLOCATIONS': 729,\n",
       " 'RECOGNIZANCE': 730,\n",
       " 'SIGNS': 731,\n",
       " 'UNLAWFUL': 732,\n",
       " 'EXECUTES': 733,\n",
       " 'AREV': 734,\n",
       " 'ASSAULT': 735,\n",
       " 'WITHOUT': 736,\n",
       " 'Request': 737,\n",
       " 'CASH': 738,\n",
       " 'RECEIVED': 739,\n",
       " 'STOLEN': 740,\n",
       " 'CLARK': 741,\n",
       " 'FIVE': 742,\n",
       " 'HOURS': 743,\n",
       " 'ARE': 744,\n",
       " 'INTO': 745,\n",
       " 'HAVE': 746,\n",
       " 'AC23': 747,\n",
       " '250000': 748,\n",
       " 'CT2': 749,\n",
       " 'RTSUB': 750,\n",
       " 'SUBPOENA': 751,\n",
       " 'CERTIFIED': 752,\n",
       " 'FOUR': 753,\n",
       " 'OARSS': 754,\n",
       " 'CARTER': 755,\n",
       " '09012020': 756,\n",
       " 'ADMINISTRATIVELY': 757,\n",
       " 'MIS': 758,\n",
       " 'HELP': 759,\n",
       " 'DESK': 760,\n",
       " '97604': 761,\n",
       " 'ADMIN': 762,\n",
       " 'ONLY': 763,\n",
       " '406': 764,\n",
       " 'SHERIFF': 765,\n",
       " 'FORFEITURE': 766,\n",
       " 'MARTHA': 767,\n",
       " 'TRANSFER': 768,\n",
       " 'AN': 769,\n",
       " '180': 770,\n",
       " 'ALLEN': 771,\n",
       " 'CTCONF': 772,\n",
       " 'INCARCERATION': 773,\n",
       " 'BDFOR': 774,\n",
       " 'DELIVERED': 775,\n",
       " 'APRIL': 776,\n",
       " 'SEIBERT': 777,\n",
       " 'RUPP': 778,\n",
       " 'HOLD': 779,\n",
       " '1000000': 780,\n",
       " 'MARK': 781,\n",
       " 'ALCOHOL': 782,\n",
       " 'CHILD': 783,\n",
       " '408': 784,\n",
       " 'ORDERS': 785,\n",
       " 'OJ': 786,\n",
       " 'DEFERS': 787,\n",
       " 'RPLEA': 788,\n",
       " 'DEFT': 789,\n",
       " 'BATTERY': 790,\n",
       " 'INVESTIGATION': 791,\n",
       " 'AGREEMENT': 792,\n",
       " 'COMMISSION': 793,\n",
       " 'OTC': 794,\n",
       " 'ACCELERATE': 795,\n",
       " 'WORK': 796,\n",
       " 'AC11': 797,\n",
       " 'AC21': 798,\n",
       " 'AC22': 799,\n",
       " 'MARY': 800,\n",
       " 'RETCM': 801,\n",
       " 'CERT': 802,\n",
       " 'BWIAR': 803,\n",
       " 'MUSSEMAN': 804,\n",
       " '12312014': 805,\n",
       " 'SARAH': 806,\n",
       " 'TREATMENT': 807,\n",
       " 'MATT': 808,\n",
       " 'AVAILABLE': 809,\n",
       " '401': 810,\n",
       " 'APP': 811,\n",
       " 'ROBERTA': 812,\n",
       " 'AC07': 813,\n",
       " 'AC69': 814,\n",
       " 'MULTIDISCIPLINARY': 815,\n",
       " '2402': 816,\n",
       " 'LARCENY': 817,\n",
       " 'BLISS': 818,\n",
       " 'LOWE': 819,\n",
       " 'SPECIALTY': 820,\n",
       " 'SAID': 821,\n",
       " 'NOTE': 822,\n",
       " 'SECOND': 823,\n",
       " 'RC': 824,\n",
       " 'FUNDS': 825,\n",
       " 'Intercept': 826,\n",
       " 'Review': 827,\n",
       " 'WINC': 828,\n",
       " '12312013': 829,\n",
       " 'STEPHEN': 830,\n",
       " 'APPOINTS': 831,\n",
       " 'OAACL': 832,\n",
       " 'AACL': 833,\n",
       " 'AC75': 834,\n",
       " 'AC76': 835,\n",
       " 'AC77': 836,\n",
       " 'AC88': 837,\n",
       " 'REC02': 838,\n",
       " 'RECEIPTS': 839,\n",
       " '2300': 840,\n",
       " 'OFFENSE': 841,\n",
       " 'BILL': 842,\n",
       " 'AC99': 843,\n",
       " 'HOLDING': 844,\n",
       " 'COURTS': 845,\n",
       " 'DEFENSE': 846,\n",
       " 'Pursuant': 847,\n",
       " '39': 848,\n",
       " '4000': 849,\n",
       " 'CC': 850,\n",
       " 'COLLECTION': 851,\n",
       " 'CBWF1': 852,\n",
       " 'CLERKS': 853,\n",
       " 'TITLE': 854,\n",
       " 'OS966A': 855,\n",
       " '12312013Closed': 856,\n",
       " 'CINDY': 857,\n",
       " 'ALLOWED': 858,\n",
       " 'CLIFFORD': 859,\n",
       " 'BECKY': 860,\n",
       " 'KELLER': 861,\n",
       " 'COMPLETION': 862,\n",
       " 'SEAN': 863,\n",
       " 'FOUND': 864,\n",
       " 'TRANSPORTATION': 865,\n",
       " 'EDUCATION': 866,\n",
       " '8800': 867,\n",
       " '501': 868,\n",
       " 'CIVIL': 869,\n",
       " '960': 870,\n",
       " '1440': 871,\n",
       " '12312014Closed': 872,\n",
       " 'PASSES': 873,\n",
       " 'RESULTS': 874,\n",
       " 'GPS': 875,\n",
       " 'KELLY': 876,\n",
       " 'AUTHORIZES': 877,\n",
       " '100': 878,\n",
       " 'CONFERENCE': 879,\n",
       " 'WITHIN': 880,\n",
       " 'BWIFP': 881,\n",
       " 'JANA': 882,\n",
       " 'HARRINGTON': 883,\n",
       " 'USE': 884,\n",
       " 'COSTT': 885,\n",
       " 'TRAFFIC': 886,\n",
       " 'DACPAT': 887,\n",
       " 'CHARGE': 888,\n",
       " 'DECLINED': 889,\n",
       " 'APPROVED': 890,\n",
       " 'SIX': 891,\n",
       " 'YOUR': 892,\n",
       " '12500': 893,\n",
       " '413': 894,\n",
       " '01032020': 895,\n",
       " 'DRIVING': 896,\n",
       " 'PROPERTY': 897,\n",
       " 'OBJECTION': 898,\n",
       " 'WITHDRAW': 899,\n",
       " 'ANN': 900,\n",
       " 'RICHARD': 901,\n",
       " 'YOU': 902,\n",
       " 'TOM': 903,\n",
       " 'BWIAA': 904,\n",
       " 'COMPLIANCE': 905,\n",
       " 'LAFORTUNE': 906,\n",
       " 'COMPLETED': 907,\n",
       " 'AC08': 908,\n",
       " 'CT3': 909,\n",
       " 'BUREAU': 910,\n",
       " 'NARCOTICS': 911,\n",
       " 'PAYMENTS': 912,\n",
       " '74119': 913,\n",
       " 'LAST': 914,\n",
       " 'DOCNO': 915,\n",
       " 'CORRECTIONSS': 916,\n",
       " 'COSTSFINES': 917,\n",
       " 'WILSON': 918,\n",
       " 'MICHAEL': 919,\n",
       " 'OBTAIN': 920,\n",
       " 'SPECIAL': 921,\n",
       " 'MHC': 922,\n",
       " '2402Date': 923,\n",
       " 'PENDING': 924,\n",
       " 'MENTAL': 925,\n",
       " 'HEALTH': 926,\n",
       " 'GREENOUGH': 927,\n",
       " 'AMIN': 928,\n",
       " 'REQUESTED': 929,\n",
       " '2013': 930,\n",
       " 'BRIAN': 931,\n",
       " 'APLI': 932,\n",
       " 'CONTROL': 933,\n",
       " '4875': 934,\n",
       " 'BRASHER': 935,\n",
       " 'FOLLOW': 936,\n",
       " 'RECEIVE': 937,\n",
       " '150': 938,\n",
       " 'TERM': 939,\n",
       " '540': 940,\n",
       " 'CUNNINGHAM': 941,\n",
       " 'OUT': 942,\n",
       " 'PURPOSE': 943,\n",
       " 'TANYA': 944,\n",
       " 'UP': 945,\n",
       " 'COMMUNITY': 946,\n",
       " 'ABDOM': 947,\n",
       " 'DOMESTIC': 948,\n",
       " 'BOUND': 949,\n",
       " 'DENIED': 950,\n",
       " 'Sheriffs': 951,\n",
       " 'POST': 952,\n",
       " '150000': 953,\n",
       " 'OFFENDER': 954,\n",
       " 'NONJURY': 955,\n",
       " 'ANOTHER': 956,\n",
       " 'AMANDA': 957,\n",
       " 'PAGE': 958,\n",
       " 'IF': 959,\n",
       " 'AC80': 960,\n",
       " 'FILED': 961,\n",
       " 'WHILE': 962,\n",
       " 'INVOCATION': 963,\n",
       " 'BNDE': 964,\n",
       " '506': 965,\n",
       " '12272019': 966,\n",
       " 'CAPUTO': 967,\n",
       " 'WITNESSES': 968,\n",
       " 'FIRST': 969,\n",
       " '12282018': 970,\n",
       " 'REDUCTION': 971,\n",
       " 'PASS': 972,\n",
       " 'TAMMY': 973,\n",
       " 'Saturday': 974,\n",
       " 'OFFICER': 975,\n",
       " '20000': 976,\n",
       " 'L': 977,\n",
       " 'DETERMINES': 978,\n",
       " 'APPOINTMENT': 979,\n",
       " 'JR': 980,\n",
       " 'ACCEPTED': 981,\n",
       " 'CONTINUANCE': 982,\n",
       " 'DEGREE': 983,\n",
       " 'CTPRLDCA': 984,\n",
       " 'DEMURRER': 985,\n",
       " 'OVERRULED': 986,\n",
       " 'INTENT': 987,\n",
       " 'PLEADS': 988,\n",
       " 'NICK': 989,\n",
       " 'LA4': 990,\n",
       " '4103Date': 991,\n",
       " '4103': 992,\n",
       " 'FFP': 993,\n",
       " 'CREATE': 994,\n",
       " 'BEN': 995,\n",
       " '200000': 996,\n",
       " '125': 997,\n",
       " 'MORGAN': 998,\n",
       " 'PERIOD': 999,\n",
       " 'PROVIDED': 1000,\n",
       " 'METHAMPHETAMINE': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'word_map' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-Defendant lawyer': 1,\n",
       " 0: 0,\n",
       " 'B-State Rep': 2,\n",
       " 'B-Defendant lawyer': 3,\n",
       " 'I-State Rep': 4,\n",
       " 'I-Judge': 5,\n",
       " 'O': 6,\n",
       " 'B-Judge': 7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pulling out the tag map that we want to focus on training the data on ( 0 = unknown/pad )\n",
    "## Does the label/ordering of this map matter?\n",
    "tags = []\n",
    "for entry in y_train:\n",
    "    for tag in entry:\n",
    "        tags.append(tag)\n",
    "tags = list(set(tags))\n",
    "\n",
    "tag_map = {}\n",
    "for i,v in enumerate(tags):\n",
    "    tag_map[v] = i+1\n",
    "    tag_map[0] = 0\n",
    "    \n",
    "tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tag_map' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-Defendant lawyer': 1,\n",
       " 0: 0,\n",
       " 'B-State Rep': 2,\n",
       " 'B-Defendant lawyer': 3,\n",
       " 'I-State Rep': 4,\n",
       " 'I-Judge': 5,\n",
       " 'O': 6,\n",
       " 'B-Judge': 7}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for sent in X_train:\n",
    "    X.append([word_map[i] for i in sent])\n",
    "for seq in y_train:\n",
    "    y.append([tag_map[i] for i in seq])\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "#TO DO: Actual Train Test Split\n",
    "for sent in X_test:\n",
    "    X_val.append([word_map[i] if i in word_map.keys() else 1 for i in sent])\n",
    "for seq in y_test:\n",
    "    y_val.append([tag_map[i] for i in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This is calling just the index within the wordmap, because NN can only handle numbers\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243\n"
     ]
    }
   ],
   "source": [
    "print(max([len(i) for i in X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Looking at the distribution of data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist([len(i) for i in X],bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744.75\n",
      "969.4499999999998\n",
      "1162.089999999999\n"
     ]
    }
   ],
   "source": [
    "#In order to achieve a confidence interval, select the quartile for the model to train on\n",
    "import numpy as np\n",
    "print(np.quantile([len(i) for i in X],0.75))\n",
    "print(np.quantile([len(i) for i in X],0.95))\n",
    "print(np.quantile([len(i) for i in X],0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "#Preparing the data for Neural Net (padding the data to be all the same length)\n",
    "X = sequence.pad_sequences(X, maxlen=max_len)\n",
    "y = sequence.pad_sequences(y, maxlen=max_len)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_len)\n",
    "y_val = sequence.pad_sequences(y_val, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing final processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X' (ndarray)\n",
      "Stored 'y' (ndarray)\n",
      "Stored 'X_val' (ndarray)\n",
      "Stored 'y_val' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store X\n",
    "%store y\n",
    "%store X_val\n",
    "%store y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "f = open('X', 'wb')\n",
    "pickle.dump(X, f)\n",
    "f.close()\n",
    "# y\n",
    "f = open('y', 'wb')\n",
    "pickle.dump(y, f)\n",
    "f.close()\n",
    "# X_val\n",
    "f = open('X_val', 'wb')\n",
    "pickle.dump(X_val, f)\n",
    "f.close()\n",
    "# y_val\n",
    "f = open('y_val', 'wb')\n",
    "pickle.dump(y_val, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#example of a padded sentence (with leading 0s)\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM\n",
    "TODO: word_map is also required to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpickle our\n",
    "# X\n",
    "X = pickle.load(open('X', 'rb'))\n",
    "# y\n",
    "y = pickle.load(open('y', 'rb'))\n",
    "#Since we are using 5 fold Cross Validation and have a small training set, this is currently just the training set\n",
    "# X_val\n",
    "X_val = pickle.load(open('X_val', 'rb'))\n",
    "# y_val\n",
    "y_val = pickle.load(open('y_val', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test NN to ensure our data is setup properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety = EarlyStopping(monitor='val_loss', patience=1)\n",
    "# create the model\n",
    "word_vector_len = 100\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(word_map), word_vector_len, input_length=max_len))\n",
    "model1.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(TimeDistributed(Dense(len(tag_map),activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does non-trainable parameters mean? is there a threshold we should expect to see in test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 100)         1582100   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 512)         731136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1000, 8)           4104      \n",
      "=================================================================\n",
      "Total params: 2,317,340\n",
      "Trainable params: 2,317,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 1.8414 - accuracy: 0.6999 - val_loss: 0.7463 - val_accuracy: 0.9911\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.3542 - accuracy: 0.9757 - val_loss: 0.0962 - val_accuracy: 0.9872\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0878 - accuracy: 0.9879 - val_loss: 0.0688 - val_accuracy: 0.9892\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0651 - accuracy: 0.9908 - val_loss: 0.0584 - val_accuracy: 0.9920\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0578 - accuracy: 0.9925 - val_loss: 0.0521 - val_accuracy: 0.9939\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.0516 - accuracy: 0.9934 - val_loss: 0.0489 - val_accuracy: 0.9930\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0500 - accuracy: 0.9935 - val_loss: 0.0476 - val_accuracy: 0.9939\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0484 - accuracy: 0.9936 - val_loss: 0.0466 - val_accuracy: 0.9939\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0472 - accuracy: 0.9936 - val_loss: 0.0457 - val_accuracy: 0.9939\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0461 - accuracy: 0.9938 - val_loss: 0.0447 - val_accuracy: 0.9939\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0445 - accuracy: 0.9937 - val_loss: 0.0884 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee129933a0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running the model\n",
    "model1.fit(X,y, epochs=100, validation_data=(X_val,y_val), batch_size=20, callbacks = [safety])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 100)         1582100   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 512)         731136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1000, 8)           4104      \n",
      "=================================================================\n",
      "Total params: 2,317,340\n",
      "Trainable params: 2,317,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 100)         1582100   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000, 512)         731136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1000, 8)           4104      \n",
      "=================================================================\n",
      "Total params: 2,317,340\n",
      "Trainable params: 2,317,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K=Fold Cross Validation with Keras\n",
    "#https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_bidir(n,dropout,learning,n_epochs,pat ):\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    acc_per_fold =[]\n",
    "    loss_per_fold=[]\n",
    "    \n",
    "    classificat_reports=[]\n",
    "    \n",
    "    safety = EarlyStopping(monitor='val_loss', patience=pat)\n",
    "\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X, y):\n",
    "\n",
    "      # Define the model architecture\n",
    "        model1 = Sequential()\n",
    "        model1.add(Embedding(len(word_map), 300, input_length=max_len))\n",
    "        model1.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "        model1.add(Dropout(dropout)) #play with this value \n",
    "        model1.add(TimeDistributed(Dense(len(tag_map),activation='softmax')))\n",
    "\n",
    "        opt =Adam(learning_rate=learning)\n",
    "        \n",
    "      # Compile the model\n",
    "        #change the learning rate\n",
    "        model1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "      # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "      # Fit data to model\n",
    "        history = model1.fit(X,y, epochs=n_epochs, validation_data=(X_val,y_val), batch_size=20, \n",
    "                             callbacks = [safety]) #add weights param\n",
    "\n",
    "      # Generate generalization metrics\n",
    "        scores = model1.evaluate(X[test], y[test], verbose=0)\n",
    "        \n",
    "        #preds = model1.predict(X[test])\n",
    "        #classificat_reports = classification_report(\n",
    "        #    y[test].ravel(), np.argmax(preds,axis=2).ravel(), digits=3\n",
    "        #)\n",
    "        print(classificat_reports)\n",
    "        print(f'Score for fold {fold_no}: {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "      # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "    return (acc_per_fold, loss_per_fold,classificat_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.9759 - accuracy: 0.5588 - val_loss: 0.3216 - val_accuracy: 0.8252\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.2009 - accuracy: 0.9345 - val_loss: 0.0761 - val_accuracy: 0.9903\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0694 - accuracy: 0.9905 - val_loss: 0.0457 - val_accuracy: 0.9920\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0456 - accuracy: 0.9919 - val_loss: 0.0326 - val_accuracy: 0.9928\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0325 - accuracy: 0.9928 - val_loss: 0.0248 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.0209 - val_accuracy: 0.9943\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0181 - val_accuracy: 0.9947\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0156 - val_accuracy: 0.9953\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0107 - val_accuracy: 0.9970\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "[]\n",
      "Score for fold 1: loss of 0.0017747508827596903; accuracy of 99.95952248573303%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.6368 - accuracy: 0.5681 - val_loss: 0.0449 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0451 - accuracy: 0.9940 - val_loss: 0.0364 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0334 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9944\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0152 - val_accuracy: 0.9955\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 8.8236e-04 - val_accuracy: 0.9998\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 7.5514e-04 - val_accuracy: 0.9998\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.3525e-04 - accuracy: 0.9998 - val_loss: 7.2215e-04 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.1303e-04 - accuracy: 0.9997 - val_loss: 9.2739e-04 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 2: loss of 0.0012275305343791842; accuracy of 99.96904730796814%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.9470 - accuracy: 0.4190 - val_loss: 0.1641 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1060 - accuracy: 0.9908 - val_loss: 0.0500 - val_accuracy: 0.9920\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0484 - accuracy: 0.9931 - val_loss: 0.0386 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0393 - accuracy: 0.9939 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0319 - accuracy: 0.9939 - val_loss: 0.0262 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.0241 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 0.0223 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0202 - val_accuracy: 0.9942\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0179 - val_accuracy: 0.9947\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0097 - val_accuracy: 0.9976\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0088 - val_accuracy: 0.9990\n",
      "[]\n",
      "Score for fold 3: loss of 0.0022377055138349533; accuracy of 99.94285702705383%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.5071 - accuracy: 0.5983 - val_loss: 0.1430 - val_accuracy: 0.9797\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1277 - accuracy: 0.9810 - val_loss: 0.0806 - val_accuracy: 0.9888\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0736 - accuracy: 0.9886 - val_loss: 0.0537 - val_accuracy: 0.9901\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0529 - accuracy: 0.9905 - val_loss: 0.0425 - val_accuracy: 0.9914\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0410 - accuracy: 0.9918 - val_loss: 0.0341 - val_accuracy: 0.9928\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0342 - accuracy: 0.9930 - val_loss: 0.0286 - val_accuracy: 0.9935\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.0228 - val_accuracy: 0.9943\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 0.0208 - val_accuracy: 0.9947\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0190 - val_accuracy: 0.9951\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0182 - val_accuracy: 0.9952\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.0170 - val_accuracy: 0.9958\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.0147 - val_accuracy: 0.9965\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
      "[]\n",
      "Score for fold 4: loss of 0.015315739437937737; accuracy of 99.60238337516785%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 2.2596 - accuracy: 0.5727 - val_loss: 0.0999 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0808 - accuracy: 0.9930 - val_loss: 0.0459 - val_accuracy: 0.9939\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0440 - accuracy: 0.9939 - val_loss: 0.0320 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0308 - accuracy: 0.9936 - val_loss: 0.0238 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.0209 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0203 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.0194 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0173 - val_accuracy: 0.9946\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0149 - val_accuracy: 0.9953\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0123 - val_accuracy: 0.9964\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0140 - val_accuracy: 0.9958\n",
      "[]\n",
      "Score for fold 5: loss of 0.010431729257106781; accuracy of 99.73333477973938%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.2424 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of nan; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.4095 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.3606 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 5.0066 - accuracy: 0.4255 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 5.5575 - accuracy: 0.6552 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.2621 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 28s 2s/step - loss: 1.5342 - accuracy: 0.5441 - val_loss: 0.1017 - val_accuracy: 0.9834\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1017 - accuracy: 0.9860 - val_loss: 0.0729 - val_accuracy: 0.9920\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0807 - accuracy: 0.9910 - val_loss: 0.0489 - val_accuracy: 0.9930\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0724 - accuracy: 0.9894 - val_loss: 0.0905 - val_accuracy: 0.9796\n",
      "[]\n",
      "Score for fold 1: loss of 0.04943469539284706; accuracy of 99.39285516738892%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 2.1741 - accuracy: 0.5786 - val_loss: 0.0780 - val_accuracy: 0.9911\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0761 - accuracy: 0.9914 - val_loss: 0.0654 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0611 - accuracy: 0.9937 - val_loss: 0.0474 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0448 - accuracy: 0.9940 - val_loss: 0.0375 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0374 - accuracy: 0.9939 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0296 - accuracy: 0.9939 - val_loss: 0.0248 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.0214 - val_accuracy: 0.9941\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0194 - val_accuracy: 0.9942\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0179 - val_accuracy: 0.9945\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0165 - val_accuracy: 0.9947\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0151 - val_accuracy: 0.9951\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0137 - val_accuracy: 0.9957\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0122 - val_accuracy: 0.9964\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0108 - val_accuracy: 0.9972\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9987\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 9.9810e-04 - val_accuracy: 0.9998\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.1641e-04 - val_accuracy: 0.9998\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.1298e-04 - val_accuracy: 0.9998\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 8.5320e-04 - val_accuracy: 0.9999\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.6556e-04 - accuracy: 0.9998 - val_loss: 7.7986e-04 - val_accuracy: 0.9999\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 8.2042e-04 - accuracy: 0.9999 - val_loss: 8.6833e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 2: loss of 0.0010295091196894646; accuracy of 99.97857213020325%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.8878 - accuracy: 0.5080 - val_loss: 0.0653 - val_accuracy: 0.9930\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0602 - accuracy: 0.9933 - val_loss: 0.0458 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0446 - accuracy: 0.9937 - val_loss: 0.0358 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0340 - accuracy: 0.9938 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0285 - accuracy: 0.9936 - val_loss: 0.0211 - val_accuracy: 0.9942\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.0171 - val_accuracy: 0.9949\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0146 - val_accuracy: 0.9958\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0107 - val_accuracy: 0.9969\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0092 - val_accuracy: 0.9978\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0079 - val_accuracy: 0.9981\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9989\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.9913e-04 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 3: loss of 0.001218933379277587; accuracy of 99.9666690826416%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.9835 - accuracy: 0.5136 - val_loss: 0.0710 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0645 - accuracy: 0.9932 - val_loss: 0.0448 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.0299 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0286 - accuracy: 0.9939 - val_loss: 0.0226 - val_accuracy: 0.9941\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0181 - val_accuracy: 0.9947\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0150 - val_accuracy: 0.9954\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0126 - val_accuracy: 0.9962\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0107 - val_accuracy: 0.9970\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0090 - val_accuracy: 0.9976\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0077 - val_accuracy: 0.9982\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 9.5804e-04 - val_accuracy: 0.9998\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 8.9053e-04 - val_accuracy: 0.9998\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 7.5952e-04 - val_accuracy: 0.9998\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.3099e-04 - accuracy: 0.9998 - val_loss: 7.0395e-04 - val_accuracy: 0.9998\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.1741e-04 - accuracy: 0.9998 - val_loss: 6.5755e-04 - val_accuracy: 0.9998\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.7884e-04 - accuracy: 0.9997 - val_loss: 6.7756e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 4: loss of 0.0007276802789419889; accuracy of 99.9833345413208%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 2.1775 - accuracy: 0.5769 - val_loss: 0.0770 - val_accuracy: 0.9918\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0692 - accuracy: 0.9924 - val_loss: 0.0549 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0509 - accuracy: 0.9939 - val_loss: 0.0354 - val_accuracy: 0.9936\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0351 - accuracy: 0.9933 - val_loss: 0.0280 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: 0.0240 - val_accuracy: 0.9941\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0210 - val_accuracy: 0.9944\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0190 - val_accuracy: 0.9945\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0175 - val_accuracy: 0.9949\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0161 - val_accuracy: 0.9952\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0148 - val_accuracy: 0.9956\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 25s 2s/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0121 - val_accuracy: 0.9968\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0093 - val_accuracy: 0.9975\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 5: loss of 0.0007920603966340423; accuracy of 99.99285936355591%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.0005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.8296 - accuracy: 0.6889 - val_loss: 1.1563 - val_accuracy: 0.9402\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.0148 - accuracy: 0.9710 - val_loss: 0.1560 - val_accuracy: 0.9873\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1341 - accuracy: 0.9867 - val_loss: 0.0671 - val_accuracy: 0.9891\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0656 - accuracy: 0.9907 - val_loss: 0.0603 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0595 - accuracy: 0.9922 - val_loss: 0.0530 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0522 - accuracy: 0.9936 - val_loss: 0.0500 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0502 - accuracy: 0.9937 - val_loss: 0.0484 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0487 - accuracy: 0.9938 - val_loss: 0.0475 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0479 - accuracy: 0.9939 - val_loss: 0.0468 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0474 - accuracy: 0.9939 - val_loss: 0.0462 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0456 - accuracy: 0.9940 - val_loss: 0.0456 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0465 - accuracy: 0.9938 - val_loss: 0.0450 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0455 - accuracy: 0.9939 - val_loss: 0.0442 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0448 - accuracy: 0.9939 - val_loss: 0.0434 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0435 - accuracy: 0.9940 - val_loss: 0.0424 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0426 - accuracy: 0.9939 - val_loss: 0.0413 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0416 - accuracy: 0.9939 - val_loss: 0.0396 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0399 - accuracy: 0.9939 - val_loss: 0.0378 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0378 - accuracy: 0.9940 - val_loss: 0.0359 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0362 - accuracy: 0.9939 - val_loss: 0.0341 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0342 - accuracy: 0.9940 - val_loss: 0.0318 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0324 - accuracy: 0.9940 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.0284 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.0253 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.0243 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0229 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.0211 - val_accuracy: 0.9941\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.0205 - val_accuracy: 0.9941\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0200 - val_accuracy: 0.9941\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0191 - val_accuracy: 0.9942\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0184 - val_accuracy: 0.9943\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0177 - val_accuracy: 0.9944\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0163 - val_accuracy: 0.9947\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0157 - val_accuracy: 0.9949\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0155 - val_accuracy: 0.9947\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0151 - val_accuracy: 0.9953\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0145 - val_accuracy: 0.9952\n",
      "[]\n",
      "Score for fold 1: loss of 0.016007255762815475; accuracy of 99.51666593551636%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.8508 - accuracy: 0.6679 - val_loss: 1.1522 - val_accuracy: 0.9305\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.7990 - accuracy: 0.9668 - val_loss: 0.0939 - val_accuracy: 0.9815\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0836 - accuracy: 0.9839 - val_loss: 0.0663 - val_accuracy: 0.9901\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0639 - accuracy: 0.9907 - val_loss: 0.0559 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0548 - accuracy: 0.9934 - val_loss: 0.0512 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0508 - accuracy: 0.9935 - val_loss: 0.0488 - val_accuracy: 0.9930\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0491 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0478 - accuracy: 0.9938 - val_loss: 0.0464 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0457 - accuracy: 0.9940 - val_loss: 0.0454 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0457 - accuracy: 0.9939 - val_loss: 0.0443 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0443 - accuracy: 0.9939 - val_loss: 0.0430 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0434 - accuracy: 0.9939 - val_loss: 0.0611 - val_accuracy: 0.9907\n",
      "[]\n",
      "Score for fold 2: loss of 0.042621348053216934; accuracy of 99.37381148338318%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.8478 - accuracy: 0.6268 - val_loss: 1.1329 - val_accuracy: 0.9008\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.9977 - accuracy: 0.9571 - val_loss: 0.1690 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1269 - accuracy: 0.9929 - val_loss: 0.0675 - val_accuracy: 0.9901\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1010 - accuracy: 0.9752 - val_loss: 0.0876 - val_accuracy: 0.9805\n",
      "[]\n",
      "Score for fold 3: loss of 0.08630858361721039; accuracy of 98.07618856430054%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.8584 - accuracy: 0.6679 - val_loss: 1.1104 - val_accuracy: 0.8734\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.6495 - accuracy: 0.9154 - val_loss: 0.0892 - val_accuracy: 0.9815\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.5019 - accuracy: 0.9184 - val_loss: 0.1292 - val_accuracy: 0.9776\n",
      "[]\n",
      "Score for fold 4: loss of 0.12859337031841278; accuracy of 97.79285788536072%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.8402 - accuracy: 0.6639 - val_loss: 1.1716 - val_accuracy: 0.9174\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.1911 - accuracy: 0.9063 - val_loss: 0.1560 - val_accuracy: 0.9892\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1270 - accuracy: 0.9829 - val_loss: 0.0868 - val_accuracy: 0.9882\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0793 - accuracy: 0.9896 - val_loss: 0.0611 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0610 - accuracy: 0.9927 - val_loss: 0.0561 - val_accuracy: 0.9920\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0549 - accuracy: 0.9927 - val_loss: 0.0514 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0517 - accuracy: 0.9937 - val_loss: 0.0494 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0492 - accuracy: 0.9937 - val_loss: 0.0481 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0480 - accuracy: 0.9938 - val_loss: 0.0471 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0472 - accuracy: 0.9937 - val_loss: 0.0463 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0466 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0456 - accuracy: 0.9939 - val_loss: 0.0445 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0456 - accuracy: 0.9937 - val_loss: 0.0435 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0441 - accuracy: 0.9939 - val_loss: 0.0422 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0426 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0401 - accuracy: 0.9940 - val_loss: 0.0382 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0387 - accuracy: 0.9939 - val_loss: 0.0366 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0363 - accuracy: 0.9940 - val_loss: 0.0351 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0348 - accuracy: 0.9940 - val_loss: 0.0327 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0320 - accuracy: 0.9939 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0308 - accuracy: 0.9940 - val_loss: 0.0290 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.0277 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0264 - accuracy: 0.9940 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.0238 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0224 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.0215 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.0194 - val_accuracy: 0.9943\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0187 - val_accuracy: 0.9942\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0182 - val_accuracy: 0.9944\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 25s 2s/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0174 - val_accuracy: 0.9945\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0173 - val_accuracy: 0.9945\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0181 - val_accuracy: 0.9944\n",
      "[]\n",
      "Score for fold 5: loss of 0.01770816184580326; accuracy of 99.45714473724365%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.075...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 5.5843 - accuracy: 0.4615 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 5.9065 - accuracy: 0.6335 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 1: loss of 4.29316520690918; accuracy of 73.36428761482239%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 5.7494 - accuracy: 0.4361 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 5.4503 - accuracy: 0.6457 - val_loss: 0.1310 - val_accuracy: 0.9814\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1616 - accuracy: 0.9809 - val_loss: 0.0987 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0985 - accuracy: 0.9938 - val_loss: 0.0986 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0985 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0983 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0989 - accuracy: 0.9939 - val_loss: 0.0983 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0983 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0988 - accuracy: 0.9939 - val_loss: 0.0983 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0982 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0981 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0990 - accuracy: 0.9938 - val_loss: 0.0979 - val_accuracy: 0.9939\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0992 - accuracy: 0.9938 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0997 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0993 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0985 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0988 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0989 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0986 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0990 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0976 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0983 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0962 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0985 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0996 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0987 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "[]\n",
      "Score for fold 2: loss of 0.10093022882938385; accuracy of 99.37381148338318%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 8.1058 - accuracy: 0.3293 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 10.4904 - accuracy: 0.3492 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of 10.778419494628906; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.2935 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 4: loss of nan; accuracy of 41.07857048511505%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 8.1757 - accuracy: 0.2905 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 10.2330 - accuracy: 0.3651 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of 8.572149276733398; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.025...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 4.1467 - accuracy: 0.3208 - val_loss: 0.3176 - val_accuracy: 0.9817\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.3075 - accuracy: 0.8984 - val_loss: 0.1276 - val_accuracy: 0.9865\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1218 - accuracy: 0.9870 - val_loss: 0.0992 - val_accuracy: 0.9937\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0994 - accuracy: 0.9936 - val_loss: 0.0979 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0964 - accuracy: 0.9940 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0958 - accuracy: 0.9940 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0961 - accuracy: 0.9940 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0965 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0992 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0996 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0959 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0968 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0997 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0969 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0950 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0989 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "[]\n",
      "Score for fold 1: loss of 0.09792470932006836; accuracy of 99.39285516738892%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.3335 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 3.4944 - accuracy: 0.3428 - val_loss: 0.8605 - val_accuracy: 0.7540\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.8111 - accuracy: 0.6688 - val_loss: 0.1517 - val_accuracy: 0.9752\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1391 - accuracy: 0.9791 - val_loss: 0.1016 - val_accuracy: 0.9919\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1029 - accuracy: 0.9921 - val_loss: 0.1012 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1020 - accuracy: 0.9922 - val_loss: 0.1005 - val_accuracy: 0.9930\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0996 - accuracy: 0.9927 - val_loss: 0.0999 - val_accuracy: 0.9930\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0977 - accuracy: 0.9931 - val_loss: 0.0992 - val_accuracy: 0.9930\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1006 - accuracy: 0.9929 - val_loss: 0.0988 - val_accuracy: 0.9930\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1003 - accuracy: 0.9931 - val_loss: 0.0984 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0987 - accuracy: 0.9934 - val_loss: 0.0982 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0992 - accuracy: 0.9935 - val_loss: 0.0980 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0981 - accuracy: 0.9937 - val_loss: 0.0979 - val_accuracy: 0.9939\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0979 - accuracy: 0.9938 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0973 - accuracy: 0.9938 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0975 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0984 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0981 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0983 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1000 - accuracy: 0.9937 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0969 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0992 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1000 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0975 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0974 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0964 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0986 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0968 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0963 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0985 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0992 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0961 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0976 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 3: loss of 0.0955914631485939; accuracy of 99.40714240074158%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 3.2305 - accuracy: 0.5416 - val_loss: 0.2447 - val_accuracy: 0.9646\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.3408 - accuracy: 0.9378 - val_loss: 0.1025 - val_accuracy: 0.9920\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.1026 - accuracy: 0.9925 - val_loss: 0.0980 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0980 - accuracy: 0.9936 - val_loss: 0.0977 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0984 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0987 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0975 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0967 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0968 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0964 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0976 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0974 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0973 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0971 - val_accuracy: 0.9939\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0966 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0989 - accuracy: 0.9938 - val_loss: 0.0965 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0955 - accuracy: 0.9941 - val_loss: 0.0964 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0963 - accuracy: 0.9940 - val_loss: 0.0963 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0962 - accuracy: 0.9940 - val_loss: 0.0964 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 4: loss of 0.09403770416975021; accuracy of 99.41666722297668%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: nan - accuracy: 0.4804 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.03...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.3538 - accuracy: 0.2561 - val_loss: 2.6178 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8922 - accuracy: 0.6046 - val_loss: 0.2943 - val_accuracy: 0.9444\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.3216 - accuracy: 0.8980 - val_loss: 0.1352 - val_accuracy: 0.9873\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.1535 - accuracy: 0.9800 - val_loss: 0.1105 - val_accuracy: 0.9933\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1201 - accuracy: 0.9890 - val_loss: 0.1032 - val_accuracy: 0.9932\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.1098 - accuracy: 0.9922 - val_loss: 0.0998 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.1020 - accuracy: 0.9934 - val_loss: 0.0989 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1024 - accuracy: 0.9935 - val_loss: 0.0985 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1013 - accuracy: 0.9936 - val_loss: 0.0983 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1009 - accuracy: 0.9937 - val_loss: 0.0981 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1012 - accuracy: 0.9937 - val_loss: 0.0979 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1001 - accuracy: 0.9937 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0999 - accuracy: 0.9937 - val_loss: 0.0973 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0983 - accuracy: 0.9938 - val_loss: 0.0970 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0990 - accuracy: 0.9937 - val_loss: 0.0969 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0973 - accuracy: 0.9939 - val_loss: 0.0968 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0985 - accuracy: 0.9938 - val_loss: 0.0966 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0979 - accuracy: 0.9938 - val_loss: 0.0964 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0958 - accuracy: 0.9940 - val_loss: 0.0963 - val_accuracy: 0.9939\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0959 - accuracy: 0.9940 - val_loss: 0.0961 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0971 - accuracy: 0.9939 - val_loss: 0.0957 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0962 - accuracy: 0.9938 - val_loss: 0.0953 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0960 - accuracy: 0.9939 - val_loss: 0.0951 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0970 - accuracy: 0.9938 - val_loss: 0.0949 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0969 - accuracy: 0.9939 - val_loss: 0.0948 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0943 - accuracy: 0.9940 - val_loss: 0.0947 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0938 - accuracy: 0.9939 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0949 - accuracy: 0.9939 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0950 - accuracy: 0.9938 - val_loss: 0.0940 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0938 - accuracy: 0.9939 - val_loss: 0.0938 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0956 - accuracy: 0.9939 - val_loss: 0.0936 - val_accuracy: 0.9940\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0936 - accuracy: 0.9939 - val_loss: 0.0935 - val_accuracy: 0.9940\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0941 - accuracy: 0.9939 - val_loss: 0.0932 - val_accuracy: 0.9940\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0943 - accuracy: 0.9938 - val_loss: 0.0930 - val_accuracy: 0.9940\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0936 - accuracy: 0.9939 - val_loss: 0.0924 - val_accuracy: 0.9940\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0921 - accuracy: 0.9940 - val_loss: 0.0921 - val_accuracy: 0.9940\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0932 - accuracy: 0.9939 - val_loss: 0.0919 - val_accuracy: 0.9940\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0933 - accuracy: 0.9939 - val_loss: 0.0916 - val_accuracy: 0.9940\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0925 - accuracy: 0.9938 - val_loss: 0.0912 - val_accuracy: 0.9940\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0920 - accuracy: 0.9939 - val_loss: 0.0908 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 1: loss of 0.09399310499429703; accuracy of 99.39285516738892%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 3.4884 - accuracy: 0.4694 - val_loss: 0.0773 - val_accuracy: 0.9929\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0820 - accuracy: 0.9920 - val_loss: 0.0816 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 2: loss of 0.0845741257071495; accuracy of 99.37381148338318%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: nan - accuracy: 0.3614 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.2369 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 4: loss of nan; accuracy of 41.07857048511505%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: nan - accuracy: 0.3200 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 2s/step - loss: 2.2698 - accuracy: 0.5262 - val_loss: 0.1401 - val_accuracy: 0.9800\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0832 - accuracy: 0.9882 - val_loss: 0.0468 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0473 - accuracy: 0.9939 - val_loss: 0.0427 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0414 - accuracy: 0.9940 - val_loss: 0.0334 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0319 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.0227 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.0204 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0184 - val_accuracy: 0.9941\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0161 - val_accuracy: 0.9949\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0144 - val_accuracy: 0.9959\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0120 - val_accuracy: 0.9966\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0108 - val_accuracy: 0.9965\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0091 - val_accuracy: 0.9972\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0079 - val_accuracy: 0.9977\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0075 - val_accuracy: 0.9976\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "[]\n",
      "Score for fold 1: loss of 0.0025469462852925062; accuracy of 99.92619156837463%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 2.5344 - accuracy: 0.5117 - val_loss: 0.0507 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0483 - accuracy: 0.9939 - val_loss: 0.0340 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0309 - accuracy: 0.9937 - val_loss: 0.0241 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.0193 - val_accuracy: 0.9944\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0153 - val_accuracy: 0.9953\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0116 - val_accuracy: 0.9964\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0087 - val_accuracy: 0.9976\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 9.7369e-04 - val_accuracy: 0.9998\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.0357e-04 - val_accuracy: 0.9998\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.7326e-04 - accuracy: 0.9997 - val_loss: 8.9269e-04 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.6593e-04 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 2: loss of 0.0015234010061249137; accuracy of 99.9571442604065%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.3376 - accuracy: 0.7436 - val_loss: 0.0577 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0472 - accuracy: 0.9927 - val_loss: 0.0291 - val_accuracy: 0.9939\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0267 - accuracy: 0.9939 - val_loss: 0.0225 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0191 - val_accuracy: 0.9941\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.0159 - val_accuracy: 0.9946\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0144 - val_accuracy: 0.9954\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0114 - val_accuracy: 0.9964\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 9.8698e-04 - val_accuracy: 0.9998\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 9.7911e-04 - accuracy: 0.9998 - val_loss: 8.0362e-04 - val_accuracy: 0.9998\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 8.9582e-04 - accuracy: 0.9998 - val_loss: 7.5965e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 7.3578e-04 - accuracy: 0.9999 - val_loss: 8.3360e-04 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 3: loss of 0.000968217384070158; accuracy of 99.96904730796814%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.0864 - accuracy: 0.7305 - val_loss: 1.1571 - val_accuracy: 0.8599\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.4875 - accuracy: 0.9401 - val_loss: 0.0314 - val_accuracy: 0.9938\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0289 - accuracy: 0.9936 - val_loss: 0.0219 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0177 - val_accuracy: 0.9948\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0147 - val_accuracy: 0.9956\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0150 - val_accuracy: 0.9954\n",
      "[]\n",
      "Score for fold 4: loss of 0.014342579059302807; accuracy of 99.54047799110413%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 29s 2s/step - loss: 1.9001 - accuracy: 0.6251 - val_loss: 0.0478 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0459 - accuracy: 0.9940 - val_loss: 0.0345 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0332 - accuracy: 0.9939 - val_loss: 0.0253 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.0193 - val_accuracy: 0.9944\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0154 - val_accuracy: 0.9952\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0156 - val_accuracy: 0.9950\n",
      "[]\n",
      "Score for fold 5: loss of 0.014619546011090279; accuracy of 99.55475926399231%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: nan - accuracy: 0.2359 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of nan; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.3387 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 5.3220 - accuracy: 0.3317 - val_loss: 5.8382 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 5.7310 - accuracy: 0.6414 - val_loss: 5.8192 - val_accuracy: 0.6352\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 3.5337 - accuracy: 0.7044 - val_loss: 0.1155 - val_accuracy: 0.9893\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1090 - accuracy: 0.9882 - val_loss: 0.0767 - val_accuracy: 0.9933\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0758 - accuracy: 0.9931 - val_loss: 0.0585 - val_accuracy: 0.9937\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0601 - accuracy: 0.9930 - val_loss: 0.0481 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0507 - accuracy: 0.9933 - val_loss: 0.0440 - val_accuracy: 0.9944\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0465 - accuracy: 0.9937 - val_loss: 0.0392 - val_accuracy: 0.9949\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0414 - accuracy: 0.9944 - val_loss: 0.0360 - val_accuracy: 0.9952\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0382 - accuracy: 0.9943 - val_loss: 0.0267 - val_accuracy: 0.9956\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.0210 - val_accuracy: 0.9961\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0250 - accuracy: 0.9952 - val_loss: 0.0199 - val_accuracy: 0.9965\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0180 - val_accuracy: 0.9968\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.0176 - val_accuracy: 0.9968\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0160 - val_accuracy: 0.9972\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.0131 - val_accuracy: 0.9979\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.0123 - val_accuracy: 0.9981\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.0122 - val_accuracy: 0.9980\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.0121 - val_accuracy: 0.9981\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0110 - val_accuracy: 0.9983\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.0105 - val_accuracy: 0.9984\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.0107 - val_accuracy: 0.9984\n",
      "[]\n",
      "Score for fold 3: loss of 0.008294396102428436; accuracy of 99.8380959033966%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 5.0234 - accuracy: 0.4323 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 5.7544 - accuracy: 0.6430 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 5.2691 - accuracy: 0.4480 - val_loss: 5.8696 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 5.6042 - accuracy: 0.6519 - val_loss: 5.8700 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 5: loss of 7.635958671569824; accuracy of 52.57856845855713%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.8196 - accuracy: 0.6260 - val_loss: 0.0716 - val_accuracy: 0.9891\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0647 - accuracy: 0.9915 - val_loss: 0.0779 - val_accuracy: 0.9896\n",
      "[]\n",
      "Score for fold 1: loss of 0.19330449402332306; accuracy of 97.2000002861023%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 2.0014 - accuracy: 0.5009 - val_loss: 0.0741 - val_accuracy: 0.9911\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0714 - accuracy: 0.9916 - val_loss: 0.0561 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0519 - accuracy: 0.9940 - val_loss: 0.0418 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0393 - accuracy: 0.9940 - val_loss: 0.0330 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0313 - accuracy: 0.9937 - val_loss: 0.0258 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0184 - val_accuracy: 0.9946\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0160 - val_accuracy: 0.9950\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0121 - val_accuracy: 0.9966\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "[]\n",
      "Score for fold 2: loss of 0.0041774422861635685; accuracy of 99.871426820755%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 2.2924 - accuracy: 0.5807 - val_loss: 0.0703 - val_accuracy: 0.9937\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0637 - accuracy: 0.9940 - val_loss: 0.0547 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0497 - accuracy: 0.9940 - val_loss: 0.0347 - val_accuracy: 0.9938\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0329 - accuracy: 0.9937 - val_loss: 0.0255 - val_accuracy: 0.9941\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.0206 - val_accuracy: 0.9944\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0170 - val_accuracy: 0.9948\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0145 - val_accuracy: 0.9960\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0125 - val_accuracy: 0.9962\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0108 - val_accuracy: 0.9972\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9988\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 3: loss of 0.001639006775803864; accuracy of 99.96428489685059%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.4463 - accuracy: 0.6320 - val_loss: 0.0488 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0524 - accuracy: 0.9934 - val_loss: 0.0458 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0446 - accuracy: 0.9933 - val_loss: 0.0395 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0398 - accuracy: 0.9936 - val_loss: 0.0290 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0276 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.0201 - val_accuracy: 0.9943\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0172 - val_accuracy: 0.9947\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0146 - val_accuracy: 0.9953\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0121 - val_accuracy: 0.9962\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.9056e-04 - val_accuracy: 0.9998\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 8.4109e-04 - val_accuracy: 0.9998\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 9.7074e-04 - accuracy: 0.9998 - val_loss: 8.3950e-04 - val_accuracy: 0.9998\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 9.2883e-04 - accuracy: 0.9998 - val_loss: 7.3467e-04 - val_accuracy: 0.9999\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 8.5588e-04 - accuracy: 0.9998 - val_loss: 6.9865e-04 - val_accuracy: 0.9999\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 8.0610e-04 - accuracy: 0.9998 - val_loss: 6.8845e-04 - val_accuracy: 0.9998\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 7.1855e-04 - accuracy: 0.9998 - val_loss: 5.5183e-04 - val_accuracy: 0.9999\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 5.9833e-04 - accuracy: 0.9999 - val_loss: 4.6573e-04 - val_accuracy: 0.9999\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.8091e-04 - accuracy: 0.9999 - val_loss: 4.3191e-04 - val_accuracy: 0.9999\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.3349e-04 - accuracy: 0.9999 - val_loss: 3.8856e-04 - val_accuracy: 0.9999\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.1837e-04 - accuracy: 0.9999 - val_loss: 3.3035e-04 - val_accuracy: 0.9999\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 4.0278e-04 - accuracy: 0.9999 - val_loss: 3.6592e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 4: loss of 0.00036060932325199246; accuracy of 99.99762177467346%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.9941 - accuracy: 0.6279 - val_loss: 0.0770 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0685 - accuracy: 0.9919 - val_loss: 0.0521 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0488 - accuracy: 0.9938 - val_loss: 0.0394 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0379 - accuracy: 0.9940 - val_loss: 0.0314 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.0213 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0192 - val_accuracy: 0.9941\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0173 - val_accuracy: 0.9944\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0154 - val_accuracy: 0.9952\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0134 - val_accuracy: 0.9957\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0112 - val_accuracy: 0.9967\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "[]\n",
      "Score for fold 5: loss of 0.0012885762844234705; accuracy of 99.9833345413208%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.0005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.8559 - accuracy: 0.6857 - val_loss: 1.1065 - val_accuracy: 0.8824\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.6518 - accuracy: 0.9401 - val_loss: 0.0877 - val_accuracy: 0.9863\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.8115 - accuracy: 0.8836 - val_loss: 0.1319 - val_accuracy: 0.9747\n",
      "[]\n",
      "Score for fold 1: loss of 0.12694232165813446; accuracy of 97.5928544998169%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8774 - accuracy: 0.6761 - val_loss: 1.1268 - val_accuracy: 0.8792\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.7120 - accuracy: 0.9450 - val_loss: 0.1022 - val_accuracy: 0.9840\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.7415 - accuracy: 0.8775 - val_loss: 0.1465 - val_accuracy: 0.9738\n",
      "[]\n",
      "Score for fold 2: loss of 0.15009835362434387; accuracy of 97.27857112884521%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8801 - accuracy: 0.6916 - val_loss: 1.0720 - val_accuracy: 0.8974\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.5860 - accuracy: 0.9464 - val_loss: 0.0756 - val_accuracy: 0.9882\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0682 - accuracy: 0.9889 - val_loss: 0.0663 - val_accuracy: 0.9913\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0570 - accuracy: 0.9920 - val_loss: 0.0461 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0449 - accuracy: 0.9935 - val_loss: 0.0418 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0420 - accuracy: 0.9938 - val_loss: 0.0393 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0382 - accuracy: 0.9940 - val_loss: 0.0373 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0377 - accuracy: 0.9940 - val_loss: 0.0358 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0357 - accuracy: 0.9939 - val_loss: 0.0344 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0343 - accuracy: 0.9940 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0328 - accuracy: 0.9940 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 0.0309 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0312 - accuracy: 0.9939 - val_loss: 0.0297 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.0287 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0293 - accuracy: 0.9938 - val_loss: 0.0277 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0273 - accuracy: 0.9940 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0269 - accuracy: 0.9940 - val_loss: 0.0257 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.0246 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.0235 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0216 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0208 - val_accuracy: 0.9942\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0198 - val_accuracy: 0.9942\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.0190 - val_accuracy: 0.9945\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0184 - val_accuracy: 0.9942\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0173 - val_accuracy: 0.9948\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 1.1794 - val_accuracy: 0.8173\n",
      "[]\n",
      "Score for fold 3: loss of 0.99396812915802; accuracy of 84.23571586608887%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.8477 - accuracy: 0.6962 - val_loss: 0.9955 - val_accuracy: 0.8709\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.5607 - accuracy: 0.8293 - val_loss: 0.0757 - val_accuracy: 0.9844\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0711 - accuracy: 0.9874 - val_loss: 0.0755 - val_accuracy: 0.9884\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1010 - accuracy: 0.9828 - val_loss: 0.0548 - val_accuracy: 0.9901\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0531 - accuracy: 0.9916 - val_loss: 0.0492 - val_accuracy: 0.9930\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0492 - accuracy: 0.9932 - val_loss: 0.0473 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0469 - accuracy: 0.9938 - val_loss: 0.0455 - val_accuracy: 0.9930\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0456 - accuracy: 0.9932 - val_loss: 0.0496 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 4: loss of 0.04880214482545853; accuracy of 99.40714240074158%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 1.8539 - accuracy: 0.6808 - val_loss: 1.1460 - val_accuracy: 0.9485\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.0044 - accuracy: 0.9756 - val_loss: 0.0958 - val_accuracy: 0.9928\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0862 - accuracy: 0.9890 - val_loss: 0.0634 - val_accuracy: 0.9920\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0637 - accuracy: 0.9926 - val_loss: 0.0608 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0596 - accuracy: 0.9922 - val_loss: 0.0541 - val_accuracy: 0.9930\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0528 - accuracy: 0.9935 - val_loss: 0.0505 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0510 - accuracy: 0.9934 - val_loss: 0.0489 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0491 - accuracy: 0.9939 - val_loss: 0.0477 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0475 - accuracy: 0.9939 - val_loss: 0.0468 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0463 - accuracy: 0.9940 - val_loss: 0.0460 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.0460 - accuracy: 0.9939 - val_loss: 0.0452 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0453 - accuracy: 0.9939 - val_loss: 0.0444 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0439 - accuracy: 0.9940 - val_loss: 0.0434 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0427 - accuracy: 0.9940 - val_loss: 0.0422 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0423 - accuracy: 0.9939 - val_loss: 0.0408 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0406 - accuracy: 0.9940 - val_loss: 0.0391 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0385 - accuracy: 0.9940 - val_loss: 0.0373 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0370 - accuracy: 0.9940 - val_loss: 0.0355 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0353 - accuracy: 0.9939 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0338 - accuracy: 0.9940 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0330 - accuracy: 0.9939 - val_loss: 0.0310 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0294 - accuracy: 0.9940 - val_loss: 0.0287 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0272 - accuracy: 0.9940 - val_loss: 0.0265 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.0255 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0253 - accuracy: 0.9940 - val_loss: 0.0246 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0237 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.0228 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0219 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 0.0211 - val_accuracy: 0.9941\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0196 - val_accuracy: 0.9942\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.0189 - val_accuracy: 0.9943\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0182 - val_accuracy: 0.9943\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0177 - val_accuracy: 0.9943\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0170 - val_accuracy: 0.9945\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0164 - val_accuracy: 0.9948\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0156 - val_accuracy: 0.9950\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0151 - val_accuracy: 0.9951\n",
      "[]\n",
      "Score for fold 5: loss of 0.0144786536693573; accuracy of 99.53333139419556%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.075...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 35s 3s/step - loss: 8.0818 - accuracy: 0.2957 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 10.3190 - accuracy: 0.3598 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of 11.922809600830078; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: nan - accuracy: 0.3593 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 8.1084 - accuracy: 0.2911 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 10.3563 - accuracy: 0.3575 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of 10.778419494628906; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 2s/step - loss: 8.0734 - accuracy: 0.2950 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 10.1588 - accuracy: 0.3697 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 4: loss of 9.497025489807129; accuracy of 41.07857048511505%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 8.2502 - accuracy: 0.2790 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 10.3373 - accuracy: 0.3587 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of 8.572149276733398; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.025...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.0773 - accuracy: 0.4968 - val_loss: 0.0700 - val_accuracy: 0.9912\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0899 - accuracy: 0.9866 - val_loss: 0.0642 - val_accuracy: 0.9918\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0596 - accuracy: 0.9923 - val_loss: 0.0455 - val_accuracy: 0.9937\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0450 - accuracy: 0.9935 - val_loss: 0.0360 - val_accuracy: 0.9938\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0352 - accuracy: 0.9940 - val_loss: 0.0299 - val_accuracy: 0.9941\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0299 - accuracy: 0.9940 - val_loss: 0.0260 - val_accuracy: 0.9945\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0260 - accuracy: 0.9946 - val_loss: 0.0231 - val_accuracy: 0.9948\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.0208 - val_accuracy: 0.9951\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0218 - accuracy: 0.9950 - val_loss: 0.0189 - val_accuracy: 0.9956\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 0.0170 - val_accuracy: 0.9960\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.0154 - val_accuracy: 0.9963\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.0141 - val_accuracy: 0.9966\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.0128 - val_accuracy: 0.9969\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.0116 - val_accuracy: 0.9973\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0104 - val_accuracy: 0.9976\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0095 - val_accuracy: 0.9979\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0086 - val_accuracy: 0.9981\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0057 - val_accuracy: 0.9989\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 1: loss of 0.002820731373503804; accuracy of 99.93809461593628%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: nan - accuracy: 0.5449 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.7094 - accuracy: 0.4856 - val_loss: 0.1049 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1061 - accuracy: 0.9923 - val_loss: 0.1029 - val_accuracy: 0.9937\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.1025 - accuracy: 0.9932 - val_loss: 0.0988 - val_accuracy: 0.9936\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0992 - accuracy: 0.9936 - val_loss: 0.0981 - val_accuracy: 0.9938\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0975 - accuracy: 0.9938 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0973 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0994 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0989 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0959 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0983 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0952 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0976 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 3: loss of 0.09557858854532242; accuracy of 99.40714240074158%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.7287 - accuracy: 0.4934 - val_loss: 0.1067 - val_accuracy: 0.9902\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0930 - accuracy: 0.9916 - val_loss: 0.0600 - val_accuracy: 0.9929\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0606 - accuracy: 0.9930 - val_loss: 0.0447 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0482 - accuracy: 0.9939 - val_loss: 0.0418 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0425 - accuracy: 0.9940 - val_loss: 0.0362 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0362 - accuracy: 0.9939 - val_loss: 0.0279 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0280 - accuracy: 0.9938 - val_loss: 0.0225 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.0193 - val_accuracy: 0.9941\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0187 - val_accuracy: 0.9942\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0165 - val_accuracy: 0.9945\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0153 - val_accuracy: 0.9947\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0141 - val_accuracy: 0.9951\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0133 - val_accuracy: 0.9953\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0114 - val_accuracy: 0.9962\n",
      "[]\n",
      "Score for fold 4: loss of 0.011587308719754219; accuracy of 99.59285855293274%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: nan - accuracy: 0.3585 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.1 and 0.03...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 35s 3s/step - loss: 3.5615 - accuracy: 0.3865 - val_loss: 2.1971 - val_accuracy: 0.6294\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 31s 3s/step - loss: 1.2270 - accuracy: 0.7141 - val_loss: 0.2617 - val_accuracy: 0.8986\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.2331 - accuracy: 0.9313 - val_loss: 0.1359 - val_accuracy: 0.9764\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.1338 - accuracy: 0.9761 - val_loss: 0.0985 - val_accuracy: 0.9822\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0926 - accuracy: 0.9844 - val_loss: 0.0774 - val_accuracy: 0.9892\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0807 - accuracy: 0.9893 - val_loss: 0.0698 - val_accuracy: 0.9897\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0701 - accuracy: 0.9891 - val_loss: 0.0658 - val_accuracy: 0.9886\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0655 - accuracy: 0.9889 - val_loss: 0.0590 - val_accuracy: 0.9898\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0647 - accuracy: 0.9889 - val_loss: 0.0628 - val_accuracy: 0.9894\n",
      "[]\n",
      "Score for fold 1: loss of 0.05999995395541191; accuracy of 99.03809428215027%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.6899 - accuracy: 0.5005 - val_loss: 0.8874 - val_accuracy: 0.6316\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.9061 - accuracy: 0.6584 - val_loss: 0.7809 - val_accuracy: 0.8512\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.4843 - accuracy: 0.9022 - val_loss: 0.0953 - val_accuracy: 0.9896\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0930 - accuracy: 0.9884 - val_loss: 0.0784 - val_accuracy: 0.9911\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0788 - accuracy: 0.9914 - val_loss: 0.0695 - val_accuracy: 0.9929\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0707 - accuracy: 0.9930 - val_loss: 0.0655 - val_accuracy: 0.9931\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0674 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9931\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0620 - accuracy: 0.9932 - val_loss: 0.0551 - val_accuracy: 0.9929\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0553 - accuracy: 0.9934 - val_loss: 0.0519 - val_accuracy: 0.9934\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0518 - accuracy: 0.9937 - val_loss: 0.0491 - val_accuracy: 0.9943\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0518 - accuracy: 0.9938 - val_loss: 0.0464 - val_accuracy: 0.9943\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0464 - accuracy: 0.9941 - val_loss: 0.0394 - val_accuracy: 0.9941\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0416 - accuracy: 0.9936 - val_loss: 0.0364 - val_accuracy: 0.9943\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0371 - accuracy: 0.9942 - val_loss: 0.0336 - val_accuracy: 0.9944\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0345 - accuracy: 0.9943 - val_loss: 0.0318 - val_accuracy: 0.9946\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0333 - accuracy: 0.9943 - val_loss: 0.0302 - val_accuracy: 0.9947\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0326 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9948\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0300 - accuracy: 0.9945 - val_loss: 0.0277 - val_accuracy: 0.9949\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0292 - accuracy: 0.9948 - val_loss: 0.0269 - val_accuracy: 0.9951\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0283 - accuracy: 0.9949 - val_loss: 0.0259 - val_accuracy: 0.9952\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0268 - accuracy: 0.9951 - val_loss: 0.0252 - val_accuracy: 0.9952\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0270 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9952\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 0.0235 - val_accuracy: 0.9954\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.0228 - val_accuracy: 0.9955\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0238 - accuracy: 0.9955 - val_loss: 0.0219 - val_accuracy: 0.9956\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0231 - accuracy: 0.9955 - val_loss: 0.0212 - val_accuracy: 0.9957\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0226 - accuracy: 0.9955 - val_loss: 0.0205 - val_accuracy: 0.9959\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0215 - accuracy: 0.9958 - val_loss: 0.0198 - val_accuracy: 0.9961\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.0192 - val_accuracy: 0.9960\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 0.0185 - val_accuracy: 0.9961\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 0.0178 - val_accuracy: 0.9963\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.0172 - val_accuracy: 0.9964\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.0195 - accuracy: 0.9959 - val_loss: 0.0166 - val_accuracy: 0.9964\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.0160 - val_accuracy: 0.9965\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0152 - val_accuracy: 0.9966\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.0141 - val_accuracy: 0.9966\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.0119 - val_accuracy: 0.9971\n",
      "[]\n",
      "Score for fold 2: loss of 0.01437490712851286; accuracy of 99.64761734008789%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: nan - accuracy: 0.2331 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: nan - accuracy: 0.2645 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 4: loss of nan; accuracy of 41.07857048511505%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.9403 - accuracy: 0.4440 - val_loss: 0.1526 - val_accuracy: 0.9890\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1291 - accuracy: 0.9887 - val_loss: 0.1232 - val_accuracy: 0.9856\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.1235 - accuracy: 0.9859 - val_loss: 0.1086 - val_accuracy: 0.9897\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1073 - accuracy: 0.9910 - val_loss: 0.1010 - val_accuracy: 0.9925\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0988 - accuracy: 0.9928 - val_loss: 0.0988 - val_accuracy: 0.9936\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0994 - accuracy: 0.9935 - val_loss: 0.0983 - val_accuracy: 0.9938\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0965 - accuracy: 0.9939 - val_loss: 0.0980 - val_accuracy: 0.9938\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0991 - accuracy: 0.9937 - val_loss: 0.0979 - val_accuracy: 0.9938\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0983 - accuracy: 0.9937 - val_loss: 0.0978 - val_accuracy: 0.9939\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0970 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0974 - accuracy: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0975 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0992 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0983 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0986 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0964 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0976 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0962 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0991 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0969 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0986 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0974 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 5: loss of 0.0975005254149437; accuracy of 99.39523935317993%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.6123 - accuracy: 0.6377 - val_loss: 0.2765 - val_accuracy: 0.9608\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1898 - accuracy: 0.9719 - val_loss: 0.0409 - val_accuracy: 0.9938\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0412 - accuracy: 0.9936 - val_loss: 0.0315 - val_accuracy: 0.9937\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0309 - accuracy: 0.9935 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.0190 - val_accuracy: 0.9947\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.0160 - val_accuracy: 0.9954\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.0135 - val_accuracy: 0.9963\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "[]\n",
      "Score for fold 1: loss of 0.00215088645927608; accuracy of 99.94999766349792%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 28s 2s/step - loss: 1.3886 - accuracy: 0.6175 - val_loss: 0.0503 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0497 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0439 - accuracy: 0.9936 - val_loss: 0.0351 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0343 - accuracy: 0.9937 - val_loss: 0.0268 - val_accuracy: 0.9938\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 0.0196 - val_accuracy: 0.9942\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.0192 - val_accuracy: 0.9942\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0149 - val_accuracy: 0.9956\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0118 - val_accuracy: 0.9966\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "[]\n",
      "Score for fold 2: loss of 0.00245226314291358; accuracy of 99.91190433502197%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.6661 - accuracy: 0.5473 - val_loss: 0.0506 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0468 - accuracy: 0.9939 - val_loss: 0.0321 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0318 - accuracy: 0.9938 - val_loss: 0.0231 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0188 - val_accuracy: 0.9943\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0169 - val_accuracy: 0.9947\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0135 - val_accuracy: 0.9959\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0105 - val_accuracy: 0.9970\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 3: loss of 0.0010541105875745416; accuracy of 99.96428489685059%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8854 - accuracy: 0.5928 - val_loss: 0.0824 - val_accuracy: 0.9884\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0677 - accuracy: 0.9896 - val_loss: 0.0435 - val_accuracy: 0.9939\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0425 - accuracy: 0.9937 - val_loss: 0.0325 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0323 - accuracy: 0.9939 - val_loss: 0.0241 - val_accuracy: 0.9942\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.0186 - val_accuracy: 0.9951\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0147 - val_accuracy: 0.9959\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0115 - val_accuracy: 0.9968\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0089 - val_accuracy: 0.9976\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 9.5415e-04 - val_accuracy: 0.9998\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 7.7376e-04 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 6.6720e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 9.7552e-04 - accuracy: 0.9998 - val_loss: 7.2713e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 4: loss of 0.0005425358540378511; accuracy of 99.99523758888245%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.3738 - accuracy: 0.6209 - val_loss: 0.0552 - val_accuracy: 0.9901\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0512 - accuracy: 0.9917 - val_loss: 0.0376 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0361 - accuracy: 0.9938 - val_loss: 0.0249 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0197 - val_accuracy: 0.9942\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0163 - val_accuracy: 0.9945\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0128 - val_accuracy: 0.9960\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0093 - val_accuracy: 0.9975\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "[]\n",
      "Score for fold 5: loss of 0.0018634321168065071; accuracy of 99.96904730796814%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 3.9572 - accuracy: 0.3752 - val_loss: 0.1539 - val_accuracy: 0.9796\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1373 - accuracy: 0.9839 - val_loss: 0.1484 - val_accuracy: 0.9840\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1238 - accuracy: 0.9881 - val_loss: 0.0965 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0968 - accuracy: 0.9937 - val_loss: 0.0962 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0964 - accuracy: 0.9938 - val_loss: 0.0955 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0933 - accuracy: 0.9939 - val_loss: 0.0943 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0942 - accuracy: 0.9937 - val_loss: 0.0931 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0934 - accuracy: 0.9938 - val_loss: 0.0915 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0919 - accuracy: 0.9937 - val_loss: 0.0898 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0900 - accuracy: 0.9937 - val_loss: 0.0882 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0903 - accuracy: 0.9937 - val_loss: 0.0869 - val_accuracy: 0.9941\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0870 - accuracy: 0.9938 - val_loss: 0.0858 - val_accuracy: 0.9942\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0848 - accuracy: 0.9939 - val_loss: 0.0828 - val_accuracy: 0.9942\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0834 - accuracy: 0.9938 - val_loss: 0.0819 - val_accuracy: 0.9942\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0810 - accuracy: 0.9941 - val_loss: 0.0790 - val_accuracy: 0.9943\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0807 - accuracy: 0.9939 - val_loss: 0.0757 - val_accuracy: 0.9943\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0791 - accuracy: 0.9936 - val_loss: 0.0737 - val_accuracy: 0.9945\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0752 - accuracy: 0.9940 - val_loss: 0.0708 - val_accuracy: 0.9945\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0727 - accuracy: 0.9941 - val_loss: 0.0687 - val_accuracy: 0.9947\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0701 - accuracy: 0.9942 - val_loss: 0.0649 - val_accuracy: 0.9948\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0697 - accuracy: 0.9940 - val_loss: 0.0623 - val_accuracy: 0.9949\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0644 - accuracy: 0.9941 - val_loss: 0.0592 - val_accuracy: 0.9949\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0647 - accuracy: 0.9940 - val_loss: 0.0564 - val_accuracy: 0.9952\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0600 - accuracy: 0.9940 - val_loss: 0.0505 - val_accuracy: 0.9953\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0547 - accuracy: 0.9938 - val_loss: 0.0417 - val_accuracy: 0.9950\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0487 - accuracy: 0.9933 - val_loss: 0.0377 - val_accuracy: 0.9952\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0439 - accuracy: 0.9937 - val_loss: 0.0344 - val_accuracy: 0.9953\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0395 - accuracy: 0.9939 - val_loss: 0.0281 - val_accuracy: 0.9955\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0347 - accuracy: 0.9941 - val_loss: 0.0259 - val_accuracy: 0.9957\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0313 - accuracy: 0.9945 - val_loss: 0.0234 - val_accuracy: 0.9960\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0301 - accuracy: 0.9944 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 36s 3s/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.0198 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Score for fold 1: loss of 0.024613678455352783; accuracy of 99.56190586090088%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 35s 3s/step - loss: 4.7156 - accuracy: 0.4480 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 6.0039 - accuracy: 0.6275 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 2: loss of 5.299397945404053; accuracy of 67.12142825126648%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: nan - accuracy: 0.3121 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: 3.8732 - accuracy: 0.5515 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 5.9264 - accuracy: 0.6323 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: 5.0131 - accuracy: 0.4390 - val_loss: 5.8482 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 5.7872 - accuracy: 0.6393 - val_loss: 5.8618 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 5: loss of 7.628314971923828; accuracy of 52.57856845855713%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: 1.4331 - accuracy: 0.6655 - val_loss: 0.0619 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0621 - accuracy: 0.9926 - val_loss: 0.0446 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0437 - accuracy: 0.9939 - val_loss: 0.0556 - val_accuracy: 0.9917\n",
      "[]\n",
      "Score for fold 1: loss of 0.03801320865750313; accuracy of 99.39285516738892%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4887 - accuracy: 0.5883 - val_loss: 0.0618 - val_accuracy: 0.9891\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0637 - accuracy: 0.9892 - val_loss: 0.0480 - val_accuracy: 0.9911\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0432 - accuracy: 0.9925 - val_loss: 0.0309 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0297 - accuracy: 0.9935 - val_loss: 0.0220 - val_accuracy: 0.9941\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0178 - val_accuracy: 0.9948\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0149 - val_accuracy: 0.9954\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0110 - val_accuracy: 0.9966\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0081 - val_accuracy: 0.9979\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 9.7755e-04 - val_accuracy: 0.9998\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 8.6019e-04 - val_accuracy: 0.9999\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.7845e-04 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 2: loss of 0.0010162618709728122; accuracy of 99.96904730796814%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.0261 - accuracy: 0.5088 - val_loss: 0.0718 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0646 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0436 - accuracy: 0.9939 - val_loss: 0.0402 - val_accuracy: 0.9919\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0338 - accuracy: 0.9934 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.0243 - val_accuracy: 0.9943\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0194 - val_accuracy: 0.9942\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0163 - val_accuracy: 0.9950\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0144 - val_accuracy: 0.9957\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.6333e-04 - val_accuracy: 0.9998\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 9.0473e-04 - val_accuracy: 0.9998\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 7.3553e-04 - val_accuracy: 0.9999\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 8.9624e-04 - accuracy: 0.9998 - val_loss: 6.8966e-04 - val_accuracy: 0.9999\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 8.5556e-04 - accuracy: 0.9998 - val_loss: 6.1979e-04 - val_accuracy: 0.9999\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 8.3551e-04 - accuracy: 0.9998 - val_loss: 5.9654e-04 - val_accuracy: 0.9999\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 9.9185e-04 - accuracy: 0.9998 - val_loss: 6.4191e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 3: loss of 0.0008637195569463074; accuracy of 99.9738097190857%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.4624 - accuracy: 0.6210 - val_loss: 0.0690 - val_accuracy: 0.9843\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0622 - accuracy: 0.9898 - val_loss: 0.0463 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0470 - accuracy: 0.9935 - val_loss: 0.0391 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0390 - accuracy: 0.9939 - val_loss: 0.0294 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0293 - accuracy: 0.9939 - val_loss: 0.0240 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0183 - val_accuracy: 0.9943\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0159 - val_accuracy: 0.9949\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0112 - val_accuracy: 0.9968\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0062 - val_accuracy: 0.9986\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.0562e-04 - val_accuracy: 0.9998\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 8.9095e-04 - val_accuracy: 0.9998\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.1412e-04 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 4: loss of 0.0011636397102847695; accuracy of 99.9738097190857%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.4551 - accuracy: 0.6002 - val_loss: 0.0750 - val_accuracy: 0.9897\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0546 - accuracy: 0.9932 - val_loss: 0.0576 - val_accuracy: 0.9903\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0405 - accuracy: 0.9940 - val_loss: 0.0264 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0275 - accuracy: 0.9936 - val_loss: 0.0218 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0182 - val_accuracy: 0.9945\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0157 - val_accuracy: 0.9949\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0134 - val_accuracy: 0.9958\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0115 - val_accuracy: 0.9963\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0101 - val_accuracy: 0.9969\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 9.7276e-04 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.6769e-04 - val_accuracy: 0.9998\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.2178e-04 - val_accuracy: 0.9998\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 5: loss of 0.0008561826543882489; accuracy of 99.98095035552979%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.0005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8342 - accuracy: 0.6945 - val_loss: 1.0947 - val_accuracy: 0.9584\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.7026 - accuracy: 0.9744 - val_loss: 0.0949 - val_accuracy: 0.9851\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0915 - accuracy: 0.9856 - val_loss: 0.0769 - val_accuracy: 0.9872\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0733 - accuracy: 0.9881 - val_loss: 0.0599 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0584 - accuracy: 0.9932 - val_loss: 0.0520 - val_accuracy: 0.9930\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0512 - accuracy: 0.9934 - val_loss: 0.0478 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0482 - accuracy: 0.9935 - val_loss: 0.0457 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0452 - accuracy: 0.9937 - val_loss: 0.0433 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0467 - accuracy: 0.9923 - val_loss: 0.0440 - val_accuracy: 0.9930\n",
      "[]\n",
      "Score for fold 1: loss of 0.045289140194654465; accuracy of 99.30475950241089%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8413 - accuracy: 0.6850 - val_loss: 1.0021 - val_accuracy: 0.8254\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.7387 - accuracy: 0.9393 - val_loss: 0.0932 - val_accuracy: 0.9786\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0842 - accuracy: 0.9837 - val_loss: 0.0709 - val_accuracy: 0.9901\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0675 - accuracy: 0.9904 - val_loss: 0.0597 - val_accuracy: 0.9911\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0592 - accuracy: 0.9919 - val_loss: 0.0539 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0543 - accuracy: 0.9933 - val_loss: 0.0503 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0500 - accuracy: 0.9935 - val_loss: 0.0475 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0479 - accuracy: 0.9937 - val_loss: 0.0647 - val_accuracy: 0.9916\n",
      "[]\n",
      "Score for fold 2: loss of 0.04731319472193718; accuracy of 99.37381148338318%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8524 - accuracy: 0.6496 - val_loss: 1.1360 - val_accuracy: 0.9550\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.8461 - accuracy: 0.9775 - val_loss: 0.1190 - val_accuracy: 0.9939\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0958 - accuracy: 0.9900 - val_loss: 0.4341 - val_accuracy: 0.8420\n",
      "[]\n",
      "Score for fold 3: loss of 0.36622655391693115; accuracy of 87.05714344978333%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8418 - accuracy: 0.6820 - val_loss: 1.0444 - val_accuracy: 0.9471\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.5964 - accuracy: 0.9623 - val_loss: 0.0864 - val_accuracy: 0.9882\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1108 - accuracy: 0.9806 - val_loss: 0.1875 - val_accuracy: 0.9700\n",
      "[]\n",
      "Score for fold 4: loss of 0.185435488820076; accuracy of 97.0380961894989%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8574 - accuracy: 0.6954 - val_loss: 1.1336 - val_accuracy: 0.9369\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.7943 - accuracy: 0.9677 - val_loss: 0.0881 - val_accuracy: 0.9805\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0827 - accuracy: 0.9861 - val_loss: 0.0618 - val_accuracy: 0.9911\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0750 - accuracy: 0.9881 - val_loss: 0.0633 - val_accuracy: 0.9920\n",
      "[]\n",
      "Score for fold 5: loss of 0.06332230567932129; accuracy of 99.19523596763611%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.075...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 8.2664 - accuracy: 0.2795 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 10.2376 - accuracy: 0.3648 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of 11.922809600830078; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 26s 2s/step - loss: 8.2833 - accuracy: 0.2760 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 10.4111 - accuracy: 0.3541 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of 10.919645309448242; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: nan - accuracy: 0.3017 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 8.2642 - accuracy: 0.2822 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 10.2913 - accuracy: 0.3615 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 4: loss of 9.497025489807129; accuracy of 41.07857048511505%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 28s 2s/step - loss: 8.3461 - accuracy: 0.2778 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 10.5587 - accuracy: 0.3449 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of 8.572149276733398; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.025...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.0030 - accuracy: 0.4843 - val_loss: 0.1093 - val_accuracy: 0.9896\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.1082 - accuracy: 0.9904 - val_loss: 0.0976 - val_accuracy: 0.9925\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.0952 - accuracy: 0.9929 - val_loss: 0.0783 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0700 - accuracy: 0.9933 - val_loss: 0.0462 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0444 - accuracy: 0.9937 - val_loss: 0.0292 - val_accuracy: 0.9938\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 0.0233 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.0211 - val_accuracy: 0.9941\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0225 - accuracy: 0.9940 - val_loss: 0.0175 - val_accuracy: 0.9949\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.0148 - val_accuracy: 0.9957\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0115 - val_accuracy: 0.9968\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
      "[]\n",
      "Score for fold 1: loss of 0.006471353117376566; accuracy of 99.80475902557373%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.6600 - accuracy: 0.5042 - val_loss: 0.0942 - val_accuracy: 0.9898\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0898 - accuracy: 0.9894 - val_loss: 0.0565 - val_accuracy: 0.9936\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0611 - accuracy: 0.9929 - val_loss: 0.0484 - val_accuracy: 0.9936\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0559 - accuracy: 0.9930 - val_loss: 0.0436 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0458 - accuracy: 0.9937 - val_loss: 0.0363 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0391 - accuracy: 0.9938 - val_loss: 0.0307 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0340 - accuracy: 0.9939 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.0217 - val_accuracy: 0.9943\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0185 - val_accuracy: 0.9948\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0165 - val_accuracy: 0.9951\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.0148 - val_accuracy: 0.9953\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0134 - val_accuracy: 0.9960\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0121 - val_accuracy: 0.9964\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0110 - val_accuracy: 0.9967\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0102 - val_accuracy: 0.9969\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0090 - val_accuracy: 0.9974\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0077 - val_accuracy: 0.9978\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "[]\n",
      "Score for fold 2: loss of 0.004336431622505188; accuracy of 99.84999895095825%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 33s 3s/step - loss: 2.3101 - accuracy: 0.4966 - val_loss: 0.2430 - val_accuracy: 0.9649\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2188 - accuracy: 0.9622 - val_loss: 0.1043 - val_accuracy: 0.9922\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.1087 - accuracy: 0.9908 - val_loss: 0.1006 - val_accuracy: 0.9928\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.1016 - accuracy: 0.9926 - val_loss: 0.0983 - val_accuracy: 0.9933\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0996 - accuracy: 0.9933 - val_loss: 0.0970 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0973 - accuracy: 0.9937 - val_loss: 0.0966 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0952 - accuracy: 0.9940 - val_loss: 0.0964 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0954 - accuracy: 0.9939 - val_loss: 0.0962 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.0960 - accuracy: 0.9940 - val_loss: 0.0959 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0959 - accuracy: 0.9939 - val_loss: 0.0957 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0949 - accuracy: 0.9940 - val_loss: 0.0954 - val_accuracy: 0.9939\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0948 - accuracy: 0.9940 - val_loss: 0.0950 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0951 - accuracy: 0.9940 - val_loss: 0.0947 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0939 - accuracy: 0.9940 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0954 - accuracy: 0.9939 - val_loss: 0.0944 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0935 - accuracy: 0.9940 - val_loss: 0.0941 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0925 - accuracy: 0.9941 - val_loss: 0.0937 - val_accuracy: 0.9941\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0924 - accuracy: 0.9941 - val_loss: 0.0936 - val_accuracy: 0.9941\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0929 - accuracy: 0.9941 - val_loss: 0.0935 - val_accuracy: 0.9941\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0947 - accuracy: 0.9940 - val_loss: 0.0934 - val_accuracy: 0.9941\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0922 - accuracy: 0.9941 - val_loss: 0.0933 - val_accuracy: 0.9941\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0934 - accuracy: 0.9941 - val_loss: 0.0931 - val_accuracy: 0.9941\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0921 - accuracy: 0.9941 - val_loss: 0.0929 - val_accuracy: 0.9941\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0927 - accuracy: 0.9941 - val_loss: 0.0927 - val_accuracy: 0.9941\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0938 - accuracy: 0.9940 - val_loss: 0.0924 - val_accuracy: 0.9941\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0931 - accuracy: 0.9940 - val_loss: 0.0923 - val_accuracy: 0.9941\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0925 - accuracy: 0.9941 - val_loss: 0.0920 - val_accuracy: 0.9942\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0910 - accuracy: 0.9942 - val_loss: 0.0917 - val_accuracy: 0.9942\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0908 - accuracy: 0.9942 - val_loss: 0.0915 - val_accuracy: 0.9942\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0910 - accuracy: 0.9942 - val_loss: 0.0910 - val_accuracy: 0.9942\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0903 - accuracy: 0.9942 - val_loss: 0.0907 - val_accuracy: 0.9942\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0902 - accuracy: 0.9942 - val_loss: 0.0903 - val_accuracy: 0.9942\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0912 - accuracy: 0.9942 - val_loss: 0.0899 - val_accuracy: 0.9942\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0889 - accuracy: 0.9942 - val_loss: 0.0893 - val_accuracy: 0.9943\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0892 - accuracy: 0.9943 - val_loss: 0.0891 - val_accuracy: 0.9943\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0902 - accuracy: 0.9942 - val_loss: 0.0887 - val_accuracy: 0.9943\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0884 - accuracy: 0.9942 - val_loss: 0.0882 - val_accuracy: 0.9943\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0869 - accuracy: 0.9943 - val_loss: 0.0875 - val_accuracy: 0.9943\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0893 - accuracy: 0.9941 - val_loss: 0.0868 - val_accuracy: 0.9943\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0861 - accuracy: 0.9942 - val_loss: 0.0839 - val_accuracy: 0.9943\n",
      "[]\n",
      "Score for fold 3: loss of 0.08519803732633591; accuracy of 99.42380785942078%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.8635 - accuracy: 0.5549 - val_loss: 0.1193 - val_accuracy: 0.9891\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1145 - accuracy: 0.9905 - val_loss: 0.0993 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1006 - accuracy: 0.9934 - val_loss: 0.0976 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0976 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0960 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0952 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0962 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0965 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0974 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0979 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 27s 2s/step - loss: 0.0940 - accuracy: 0.9942 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0962 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0974 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0959 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0974 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0972 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0987 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0973 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0967 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0994 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9940\n",
      "[]\n",
      "Score for fold 4: loss of 0.09556049108505249; accuracy of 99.40714240074158%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 2s/step - loss: nan - accuracy: 0.3367 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.03...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 4.3237 - accuracy: 0.3183 - val_loss: 0.5262 - val_accuracy: 0.6606\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.3940 - accuracy: 0.8699 - val_loss: 0.1374 - val_accuracy: 0.9889\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1376 - accuracy: 0.9892 - val_loss: 0.1229 - val_accuracy: 0.9920\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.1228 - accuracy: 0.9917 - val_loss: 0.1182 - val_accuracy: 0.9920\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1173 - accuracy: 0.9917 - val_loss: 0.1145 - val_accuracy: 0.9920\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1156 - accuracy: 0.9920 - val_loss: 0.1138 - val_accuracy: 0.9924\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1116 - accuracy: 0.9926 - val_loss: 0.1137 - val_accuracy: 0.9930\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1137 - accuracy: 0.9924 - val_loss: 0.1122 - val_accuracy: 0.9930\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1139 - accuracy: 0.9923 - val_loss: 0.1101 - val_accuracy: 0.9930\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1113 - accuracy: 0.9924 - val_loss: 0.1079 - val_accuracy: 0.9930\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.1079 - accuracy: 0.9925 - val_loss: 0.1055 - val_accuracy: 0.9921\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1030 - accuracy: 0.9925 - val_loss: 0.1028 - val_accuracy: 0.9920\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1027 - accuracy: 0.9924 - val_loss: 0.1002 - val_accuracy: 0.9926\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1016 - accuracy: 0.9926 - val_loss: 0.0987 - val_accuracy: 0.9930\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.1003 - accuracy: 0.9931 - val_loss: 0.0981 - val_accuracy: 0.9939\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0993 - accuracy: 0.9933 - val_loss: 0.0979 - val_accuracy: 0.9939\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0996 - accuracy: 0.9935 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0992 - accuracy: 0.9936 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0997 - accuracy: 0.9937 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0974 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0990 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0977 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0971 - accuracy: 0.9939 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0988 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0967 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0982 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0987 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0990 - accuracy: 0.9938 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0971 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0981 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0970 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0980 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0976 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0987 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0961 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0974 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0978 - accuracy: 0.9939 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "[]\n",
      "Score for fold 1: loss of 0.09790518134832382; accuracy of 99.39047694206238%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: 4.6401 - accuracy: 0.4334 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 5.9905 - accuracy: 0.6283 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 2: loss of 5.299397945404053; accuracy of 67.12142825126648%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 3s/step - loss: nan - accuracy: 0.2613 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 30s 2s/step - loss: 3.9203 - accuracy: 0.5565 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 5.8966 - accuracy: 0.6342 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.5586 - accuracy: 0.3735 - val_loss: 0.0966 - val_accuracy: 0.9898\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0913 - accuracy: 0.9908 - val_loss: 0.0871 - val_accuracy: 0.9939\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0866 - accuracy: 0.9929 - val_loss: 0.0741 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0747 - accuracy: 0.9935 - val_loss: 0.0632 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0681 - accuracy: 0.9927 - val_loss: 0.0578 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0621 - accuracy: 0.9932 - val_loss: 0.0511 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0577 - accuracy: 0.9931 - val_loss: 0.0463 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0531 - accuracy: 0.9933 - val_loss: 0.0424 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0475 - accuracy: 0.9936 - val_loss: 0.0386 - val_accuracy: 0.9941\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0470 - accuracy: 0.9935 - val_loss: 0.0361 - val_accuracy: 0.9941\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0436 - accuracy: 0.9935 - val_loss: 0.0335 - val_accuracy: 0.9942\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0372 - accuracy: 0.9937 - val_loss: 0.0312 - val_accuracy: 0.9943\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0347 - accuracy: 0.9939 - val_loss: 0.0295 - val_accuracy: 0.9943\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0351 - accuracy: 0.9937 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0319 - accuracy: 0.9938 - val_loss: 0.0242 - val_accuracy: 0.9945\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0204 - val_accuracy: 0.9948\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.0191 - val_accuracy: 0.9948\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.0161 - val_accuracy: 0.9953\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0164 - val_accuracy: 0.9953\n",
      "[]\n",
      "Score for fold 5: loss of 0.014740519225597382; accuracy of 99.53333139419556%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 29s 2s/step - loss: 2.5614 - accuracy: 0.5597 - val_loss: 0.0779 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.0678 - accuracy: 0.9928 - val_loss: 0.0454 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0462 - accuracy: 0.9935 - val_loss: 0.0346 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0338 - accuracy: 0.9940 - val_loss: 0.0252 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0215 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 0.0185 - val_accuracy: 0.9942\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0159 - val_accuracy: 0.9947\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0135 - val_accuracy: 0.9955\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0112 - val_accuracy: 0.9962\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 23s 2s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "[]\n",
      "Score for fold 1: loss of 0.0018792020855471492; accuracy of 99.94523525238037%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.6862 - accuracy: 0.6521 - val_loss: 0.0532 - val_accuracy: 0.9930\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0513 - accuracy: 0.9931 - val_loss: 0.0356 - val_accuracy: 0.9928\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0344 - accuracy: 0.9928 - val_loss: 0.0224 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.0173 - val_accuracy: 0.9945\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0145 - val_accuracy: 0.9956\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0108 - val_accuracy: 0.9968\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0084 - val_accuracy: 0.9973\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 8.1501e-04 - val_accuracy: 0.9998\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.6023e-04 - val_accuracy: 0.9999\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 6.2275e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 6.2729e-04 - val_accuracy: 0.9998\n",
      "[]\n",
      "Score for fold 2: loss of 0.0008249424863606691; accuracy of 99.97618794441223%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.1778 - accuracy: 0.5413 - val_loss: 0.1026 - val_accuracy: 0.9872\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0772 - accuracy: 0.9908 - val_loss: 0.0501 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0519 - accuracy: 0.9938 - val_loss: 0.0455 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0474 - accuracy: 0.9939 - val_loss: 0.0374 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0384 - accuracy: 0.9939 - val_loss: 0.0283 - val_accuracy: 0.9939\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0296 - accuracy: 0.9937 - val_loss: 0.0227 - val_accuracy: 0.9941\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0197 - val_accuracy: 0.9943\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.0185 - val_accuracy: 0.9944\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0166 - val_accuracy: 0.9947\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0137 - val_accuracy: 0.9953\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0126 - val_accuracy: 0.9955\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0112 - val_accuracy: 0.9960\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0102 - val_accuracy: 0.9963\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0089 - val_accuracy: 0.9969\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.0079 - val_accuracy: 0.9974\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "[]\n",
      "Score for fold 3: loss of 0.0017751391278579831; accuracy of 99.94999766349792%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.1881 - accuracy: 0.7016 - val_loss: 0.0734 - val_accuracy: 0.9932\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0683 - accuracy: 0.9935 - val_loss: 0.0394 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0411 - accuracy: 0.9937 - val_loss: 0.0250 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0181 - val_accuracy: 0.9941\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0130 - val_accuracy: 0.9956\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "[]\n",
      "Score for fold 4: loss of 0.001052049919962883; accuracy of 99.96904730796814%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.5545 - accuracy: 0.7273 - val_loss: 0.0601 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0528 - accuracy: 0.9927 - val_loss: 0.0378 - val_accuracy: 0.9924\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0374 - accuracy: 0.9930 - val_loss: 0.0267 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0180 - val_accuracy: 0.9943\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0146 - val_accuracy: 0.9952\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0113 - val_accuracy: 0.9964\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 8.0852e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 6.8714e-04 - val_accuracy: 0.9999\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 9.3877e-04 - accuracy: 0.9997 - val_loss: 6.4536e-04 - val_accuracy: 0.9999\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 9.4229e-04 - accuracy: 0.9998 - val_loss: 5.0071e-04 - val_accuracy: 0.9999\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 7.4460e-04 - accuracy: 0.9999 - val_loss: 4.4498e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 7.0783e-04 - accuracy: 0.9998 - val_loss: 4.3227e-04 - val_accuracy: 0.9999\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 6.5140e-04 - accuracy: 0.9999 - val_loss: 4.4767e-04 - val_accuracy: 0.9999\n",
      "[]\n",
      "Score for fold 5: loss of 0.00028275910881347954; accuracy of 99.99523758888245%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 27s 2s/step - loss: nan - accuracy: 0.2978 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of nan; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: nan - accuracy: 0.3035 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: nan - accuracy: 0.2496 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 5.5299 - accuracy: 0.4493 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 6.0348 - accuracy: 0.6256 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: nan - accuracy: 0.3617 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.5417 - accuracy: 0.5823 - val_loss: 0.0605 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0634 - accuracy: 0.9940 - val_loss: 0.0474 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0472 - accuracy: 0.9940 - val_loss: 0.0399 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0396 - accuracy: 0.9940 - val_loss: 0.0288 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0485 - accuracy: 0.9912 - val_loss: 0.0246 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0190 - val_accuracy: 0.9942\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0171 - val_accuracy: 0.9943\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0134 - val_accuracy: 0.9958\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0115 - val_accuracy: 0.9963\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0096 - val_accuracy: 0.9974\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9989\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "[]\n",
      "Score for fold 1: loss of 0.0027297239284962416; accuracy of 99.93095397949219%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.5604 - accuracy: 0.6006 - val_loss: 0.0583 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0620 - accuracy: 0.9940 - val_loss: 0.0517 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0482 - accuracy: 0.9941 - val_loss: 0.0377 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0384 - accuracy: 0.9939 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0264 - accuracy: 0.9941 - val_loss: 0.0221 - val_accuracy: 0.9943\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0189 - val_accuracy: 0.9943\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.0166 - val_accuracy: 0.9948\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0148 - val_accuracy: 0.9953\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0115 - val_accuracy: 0.9964\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 2: loss of 0.00144611531868577; accuracy of 99.97143149375916%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.5189 - accuracy: 0.5982 - val_loss: 0.0685 - val_accuracy: 0.9940\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0712 - accuracy: 0.9939 - val_loss: 0.0608 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0556 - accuracy: 0.9940 - val_loss: 0.0449 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0473 - accuracy: 0.9939 - val_loss: 0.0408 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0412 - accuracy: 0.9939 - val_loss: 0.0336 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0336 - accuracy: 0.9939 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0221 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0299 - accuracy: 0.9924 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0179 - val_accuracy: 0.9944\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0167 - val_accuracy: 0.9945\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0151 - val_accuracy: 0.9949\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0112 - val_accuracy: 0.9967\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0074 - val_accuracy: 0.9979\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "[]\n",
      "Score for fold 3: loss of 0.0017556911334395409; accuracy of 99.9571442604065%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.4904 - accuracy: 0.5738 - val_loss: 0.0717 - val_accuracy: 0.9911\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0765 - accuracy: 0.9910 - val_loss: 0.0692 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0632 - accuracy: 0.9934 - val_loss: 0.0477 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0692 - accuracy: 0.9898 - val_loss: 0.0371 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0372 - accuracy: 0.9940 - val_loss: 0.0296 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0300 - accuracy: 0.9938 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.0186 - val_accuracy: 0.9943\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0150 - val_accuracy: 0.9954\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0129 - val_accuracy: 0.9958\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "[]\n",
      "Score for fold 4: loss of 0.002182510681450367; accuracy of 99.93809461593628%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.5056 - accuracy: 0.6457 - val_loss: 0.0740 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0740 - accuracy: 0.9929 - val_loss: 0.0486 - val_accuracy: 0.9940\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0479 - accuracy: 0.9941 - val_loss: 0.0410 - val_accuracy: 0.9940\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0425 - accuracy: 0.9940 - val_loss: 0.0341 - val_accuracy: 0.9940\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0355 - accuracy: 0.9940 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0283 - accuracy: 0.9939 - val_loss: 0.0225 - val_accuracy: 0.9942\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0197 - val_accuracy: 0.9943\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.0173 - val_accuracy: 0.9948\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0156 - val_accuracy: 0.9951\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0139 - val_accuracy: 0.9958\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0113 - val_accuracy: 0.9966\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0090 - val_accuracy: 0.9977\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "[]\n",
      "Score for fold 5: loss of 0.0009512969409115613; accuracy of 99.98809695243835%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.0005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8602 - accuracy: 0.6300 - val_loss: 1.6549 - val_accuracy: 0.3995\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 1.1280 - accuracy: 0.8248 - val_loss: 0.2057 - val_accuracy: 0.9911\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1795 - accuracy: 0.9867 - val_loss: 0.0636 - val_accuracy: 0.9920\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0648 - accuracy: 0.9922 - val_loss: 0.0613 - val_accuracy: 0.9930\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0616 - accuracy: 0.9926 - val_loss: 0.0550 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0546 - accuracy: 0.9934 - val_loss: 0.0499 - val_accuracy: 0.9940\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0515 - accuracy: 0.9934 - val_loss: 0.0484 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0508 - accuracy: 0.9935 - val_loss: 0.0475 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0489 - accuracy: 0.9936 - val_loss: 0.0471 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0488 - accuracy: 0.9936 - val_loss: 0.0465 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0489 - accuracy: 0.9936 - val_loss: 0.0459 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0471 - accuracy: 0.9938 - val_loss: 0.0453 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0466 - accuracy: 0.9939 - val_loss: 0.0447 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0460 - accuracy: 0.9938 - val_loss: 0.0440 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0453 - accuracy: 0.9938 - val_loss: 0.0432 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0443 - accuracy: 0.9939 - val_loss: 0.0422 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0434 - accuracy: 0.9939 - val_loss: 0.0410 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0420 - accuracy: 0.9939 - val_loss: 0.0396 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0406 - accuracy: 0.9938 - val_loss: 0.0380 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0392 - accuracy: 0.9939 - val_loss: 0.0363 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0369 - accuracy: 0.9939 - val_loss: 0.0346 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0357 - accuracy: 0.9939 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0351 - accuracy: 0.9938 - val_loss: 0.0317 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0324 - accuracy: 0.9939 - val_loss: 0.0304 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0312 - accuracy: 0.9939 - val_loss: 0.0291 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0298 - accuracy: 0.9940 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0290 - accuracy: 0.9938 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0263 - accuracy: 0.9940 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.0236 - val_accuracy: 0.9940\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0241 - accuracy: 0.9940 - val_loss: 0.0227 - val_accuracy: 0.9940\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0218 - val_accuracy: 0.9940\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.0211 - val_accuracy: 0.9940\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.0202 - val_accuracy: 0.9941\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0198 - val_accuracy: 0.9941\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0191 - val_accuracy: 0.9942\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0183 - val_accuracy: 0.9942\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0175 - val_accuracy: 0.9944\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0170 - val_accuracy: 0.9944\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0164 - val_accuracy: 0.9946\n",
      "[]\n",
      "Score for fold 1: loss of 0.017739608883857727; accuracy of 99.43333268165588%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8588 - accuracy: 0.6541 - val_loss: 1.1326 - val_accuracy: 0.9517\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.8198 - accuracy: 0.9718 - val_loss: 0.0903 - val_accuracy: 0.9823\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0905 - accuracy: 0.9853 - val_loss: 1.7750 - val_accuracy: 0.5419\n",
      "[]\n",
      "Score for fold 2: loss of 1.8972501754760742; accuracy of 51.076191663742065%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.8601 - accuracy: 0.6439 - val_loss: 1.7915 - val_accuracy: 0.4060\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 1.0436 - accuracy: 0.7541 - val_loss: 0.1167 - val_accuracy: 0.9930\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1012 - accuracy: 0.9894 - val_loss: 0.0808 - val_accuracy: 0.9882\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0797 - accuracy: 0.9896 - val_loss: 0.0693 - val_accuracy: 0.9930\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0680 - accuracy: 0.9927 - val_loss: 0.0588 - val_accuracy: 0.9930\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0587 - accuracy: 0.9930 - val_loss: 0.0542 - val_accuracy: 0.9930\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0548 - accuracy: 0.9932 - val_loss: 0.0516 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0530 - accuracy: 0.9934 - val_loss: 0.0502 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0518 - accuracy: 0.9936 - val_loss: 0.0491 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0502 - accuracy: 0.9937 - val_loss: 0.0482 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0500 - accuracy: 0.9936 - val_loss: 0.0472 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0486 - accuracy: 0.9937 - val_loss: 0.0463 - val_accuracy: 0.9940\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0482 - accuracy: 0.9937 - val_loss: 0.0451 - val_accuracy: 0.9940\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0461 - accuracy: 0.9939 - val_loss: 0.0436 - val_accuracy: 0.9940\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0447 - accuracy: 0.9938 - val_loss: 0.0416 - val_accuracy: 0.9940\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0425 - accuracy: 0.9939 - val_loss: 0.0395 - val_accuracy: 0.9940\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0400 - accuracy: 0.9939 - val_loss: 0.0369 - val_accuracy: 0.9940\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0379 - accuracy: 0.9939 - val_loss: 0.0344 - val_accuracy: 0.9940\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0350 - accuracy: 0.9939 - val_loss: 0.0321 - val_accuracy: 0.9940\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0332 - accuracy: 0.9939 - val_loss: 0.0300 - val_accuracy: 0.9940\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 0.0293 - val_accuracy: 0.9940\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0300 - accuracy: 0.9939 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0255 - val_accuracy: 0.9940\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0269 - accuracy: 0.9939 - val_loss: 0.0246 - val_accuracy: 0.9940\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0253 - accuracy: 0.9940 - val_loss: 0.0233 - val_accuracy: 0.9940\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0218 - val_accuracy: 0.9940\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0207 - val_accuracy: 0.9940\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0192 - val_accuracy: 0.9941\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0181 - val_accuracy: 0.9942\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0173 - val_accuracy: 0.9943\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0157 - val_accuracy: 0.9946\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0152 - val_accuracy: 0.9947\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0147 - val_accuracy: 0.9950\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0147 - val_accuracy: 0.9949\n",
      "[]\n",
      "Score for fold 3: loss of 0.014548310078680515; accuracy of 99.50714111328125%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8680 - accuracy: 0.6508 - val_loss: 1.1555 - val_accuracy: 0.9395\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 1.0073 - accuracy: 0.9715 - val_loss: 0.1412 - val_accuracy: 0.9921\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1138 - accuracy: 0.9924 - val_loss: 0.0642 - val_accuracy: 0.9905\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0718 - accuracy: 0.9885 - val_loss: 0.0817 - val_accuracy: 0.9824\n",
      "[]\n",
      "Score for fold 4: loss of 0.08042135834693909; accuracy of 98.26666712760925%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.8090 - accuracy: 0.7269 - val_loss: 0.9422 - val_accuracy: 0.9709\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.5584 - accuracy: 0.9732 - val_loss: 0.0645 - val_accuracy: 0.9920\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0672 - accuracy: 0.9894 - val_loss: 0.0657 - val_accuracy: 0.9920\n",
      "[]\n",
      "Score for fold 5: loss of 0.06578928977251053; accuracy of 99.19523596763611%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.075...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 5.3460 - accuracy: 0.4388 - val_loss: 0.1566 - val_accuracy: 0.9864\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1814 - accuracy: 0.9844 - val_loss: 0.2023 - val_accuracy: 0.9858\n",
      "[]\n",
      "Score for fold 1: loss of 0.23355402052402496; accuracy of 98.33095073699951%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 5.4192 - accuracy: 0.4526 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 6.0850 - accuracy: 0.6225 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 2: loss of 5.299373149871826; accuracy of 67.12142825126648%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: nan - accuracy: 0.2994 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 5.5746 - accuracy: 0.3845 - val_loss: 0.7573 - val_accuracy: 0.8672\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.4810 - accuracy: 0.9238 - val_loss: 0.1120 - val_accuracy: 0.9911\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1376 - accuracy: 0.9866 - val_loss: 0.1034 - val_accuracy: 0.9923\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1202 - accuracy: 0.9900 - val_loss: 0.0989 - val_accuracy: 0.9937\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1076 - accuracy: 0.9920 - val_loss: 0.0979 - val_accuracy: 0.9938\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1046 - accuracy: 0.9926 - val_loss: 0.0977 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1025 - accuracy: 0.9930 - val_loss: 0.0976 - val_accuracy: 0.9939\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0995 - accuracy: 0.9934 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1025 - accuracy: 0.9933 - val_loss: 0.0975 - val_accuracy: 0.9939\n",
      "[]\n",
      "Score for fold 4: loss of 0.09568899869918823; accuracy of 99.40237998962402%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 8.3330 - accuracy: 0.3481 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 10.3858 - accuracy: 0.3556 - val_loss: 10.3380 - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of 8.572149276733398; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.025...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 3.0408 - accuracy: 0.4076 - val_loss: 0.1256 - val_accuracy: 0.9814\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: nan - accuracy: 0.7066 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 1: loss of nan; accuracy of 26.028570532798767%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: nan - accuracy: 0.4037 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 2: loss of nan; accuracy of 32.25238025188446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 2.5986 - accuracy: 0.4729 - val_loss: 0.1003 - val_accuracy: 0.9926\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.1014 - accuracy: 0.9922 - val_loss: 0.1009 - val_accuracy: 0.9930\n",
      "[]\n",
      "Score for fold 3: loss of 0.09626881033182144; accuracy of 99.38095211982727%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.8398 - accuracy: 0.4563 - val_loss: 1.4176 - val_accuracy: 0.6364\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.6444 - accuracy: 0.8026 - val_loss: 0.0797 - val_accuracy: 0.9835\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.0485 - val_accuracy: 0.9939\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0538 - accuracy: 0.9932 - val_loss: 0.0430 - val_accuracy: 0.9939\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0489 - accuracy: 0.9935 - val_loss: 0.0401 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0422 - accuracy: 0.9937 - val_loss: 0.0342 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0368 - accuracy: 0.9937 - val_loss: 0.0305 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0337 - accuracy: 0.9937 - val_loss: 0.0289 - val_accuracy: 0.9940\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0316 - accuracy: 0.9938 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0308 - accuracy: 0.9938 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 23s 2s/step - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0271 - accuracy: 0.9941 - val_loss: 0.0244 - val_accuracy: 0.9941\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9942\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0222 - val_accuracy: 0.9943\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0213 - val_accuracy: 0.9943\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.0209 - val_accuracy: 0.9944\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.0199 - val_accuracy: 0.9943\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0192 - val_accuracy: 0.9945\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0188 - val_accuracy: 0.9944\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0188 - val_accuracy: 0.9944\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0186 - val_accuracy: 0.9944\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0181 - val_accuracy: 0.9945\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0173 - val_accuracy: 0.9947\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0169 - val_accuracy: 0.9947\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0163 - val_accuracy: 0.9948\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0156 - val_accuracy: 0.9949\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0159 - val_accuracy: 0.9949\n",
      "[]\n",
      "Score for fold 4: loss of 0.016296977177262306; accuracy of 99.48809742927551%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: nan - accuracy: 0.3293 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 5: loss of nan; accuracy of 46.816667914390564%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.03...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 3.5891 - accuracy: 0.3719 - val_loss: 0.1899 - val_accuracy: 0.9782\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.2230 - accuracy: 0.9408 - val_loss: 0.0912 - val_accuracy: 0.9923\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0988 - accuracy: 0.9896 - val_loss: 0.0812 - val_accuracy: 0.9934\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0837 - accuracy: 0.9923 - val_loss: 0.0739 - val_accuracy: 0.9938\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0764 - accuracy: 0.9929 - val_loss: 0.0663 - val_accuracy: 0.9937\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0664 - accuracy: 0.9931 - val_loss: 0.0602 - val_accuracy: 0.9939\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0621 - accuracy: 0.9931 - val_loss: 0.0535 - val_accuracy: 0.9940\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0561 - accuracy: 0.9932 - val_loss: 0.0484 - val_accuracy: 0.9941\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0511 - accuracy: 0.9935 - val_loss: 0.0427 - val_accuracy: 0.9943\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0480 - accuracy: 0.9934 - val_loss: 0.0383 - val_accuracy: 0.9945\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0416 - accuracy: 0.9937 - val_loss: 0.0340 - val_accuracy: 0.9947\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0380 - accuracy: 0.9938 - val_loss: 0.0299 - val_accuracy: 0.9949\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0347 - accuracy: 0.9942 - val_loss: 0.0277 - val_accuracy: 0.9951\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0303 - accuracy: 0.9943 - val_loss: 0.0252 - val_accuracy: 0.9952\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0275 - accuracy: 0.9945 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0278 - accuracy: 0.9944 - val_loss: 0.0212 - val_accuracy: 0.9956\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0253 - accuracy: 0.9948 - val_loss: 0.0196 - val_accuracy: 0.9959\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0183 - val_accuracy: 0.9960\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.0169 - val_accuracy: 0.9962\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0159 - val_accuracy: 0.9964\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 0.0151 - val_accuracy: 0.9965\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.0140 - val_accuracy: 0.9968\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.0135 - val_accuracy: 0.9968\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0107 - val_accuracy: 0.9975\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.0100 - val_accuracy: 0.9976\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.0094 - val_accuracy: 0.9978\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0079 - val_accuracy: 0.9982\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0077 - val_accuracy: 0.9982\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0070 - val_accuracy: 0.9984\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "[]\n",
      "Score for fold 1: loss of 0.007090512663125992; accuracy of 99.84047412872314%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 26s 2s/step - loss: 1.9106 - accuracy: 0.4896 - val_loss: 0.0949 - val_accuracy: 0.9920\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0888 - accuracy: 0.9917 - val_loss: 0.0629 - val_accuracy: 0.9929\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0661 - accuracy: 0.9909 - val_loss: 0.0587 - val_accuracy: 0.9913\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0674 - accuracy: 0.9892 - val_loss: 0.0419 - val_accuracy: 0.9937\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0458 - accuracy: 0.9924 - val_loss: 0.0308 - val_accuracy: 0.9940\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.0378 - accuracy: 0.9926 - val_loss: 0.0254 - val_accuracy: 0.9944\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0289 - accuracy: 0.9936 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0180 - val_accuracy: 0.9952\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.0156 - val_accuracy: 0.9958\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0112 - val_accuracy: 0.9968\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0098 - val_accuracy: 0.9972\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
      "[]\n",
      "Score for fold 2: loss of 0.002085304819047451; accuracy of 99.92619156837463%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 2.8337 - accuracy: 0.4080 - val_loss: 0.7699 - val_accuracy: 0.7611\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: nan - accuracy: 0.5621 - val_loss: nan - val_accuracy: 0.3586\n",
      "[]\n",
      "Score for fold 3: loss of nan; accuracy of 33.12857151031494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 4.6573 - accuracy: 0.4371 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 5.9520 - accuracy: 0.6307 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 4: loss of 6.7166428565979; accuracy of 58.32856893539429%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 27s 2s/step - loss: 4.0108 - accuracy: 0.5534 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 23s 2s/step - loss: 5.9090 - accuracy: 0.6334 - val_loss: 5.8776 - val_accuracy: 0.6353\n",
      "[]\n",
      "Score for fold 5: loss of 7.643436908721924; accuracy of 52.57856845855713%\n"
     ]
    }
   ],
   "source": [
    "#word_vector_search = [100,200,300,400,500,600,700,800,900]\n",
    "dropout_search = [0.25,0.10,0.35,0.5]\n",
    "learning_search = [0.01,0.05,0.005,0.0005,0.075,0.025,0.03,]\n",
    "full_acc_per_fold =[]\n",
    "full_loss_per_fold=[]\n",
    "full_classificat_reports = []\n",
    "k = 5\n",
    "for i in range(len(dropout_search)):\n",
    "    avg_acc_per_fold =[]\n",
    "    avg_loss_per_fold=[]\n",
    "    classificat_reports = []\n",
    "    for j in range(len(learning_search)):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training fordropout {dropout_search[i]} and {learning_search[j]}...')\n",
    "        results = kfolds_bidir(k,dropout_search[i],learning_search[j],40, 1) #40 epochs, 1 stop tolerance\n",
    "        avg_acc_per_fold.append(sum(results[0])/k)\n",
    "        avg_loss_per_fold.append(sum(results[1])/k)\n",
    "        classificat_reports.append(results[2])\n",
    "    full_acc_per_fold.append(avg_acc_per_fold)\n",
    "    full_loss_per_fold.append(avg_loss_per_fold)\n",
    "    full_classificat_reports.append(classificat_reports)\n",
    "\n",
    "\n",
    "# create the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 with dropout 0.25 and learning 0.01   accuracy 99.84142899513245 loss 0.006197491125203669\n",
      "Run 0 with dropout 0.25 and learning 0.05   accuracy 39.310951828956604 loss nan\n",
      "Run 0 with dropout 0.25 and learning 0.005   accuracy 99.8628580570221 loss 0.01064057571347803\n",
      "Run 0 with dropout 0.25 and learning 0.0005   accuracy 98.84333372116089 loss 0.058247743919491765\n",
      "Run 0 with dropout 0.25 and learning 0.075   accuracy 58.752381801605225 loss nan\n",
      "Run 0 with dropout 0.25 and learning 0.025   accuracy 75.45714259147644 loss nan\n",
      "Run 0 with dropout 0.25 and learning 0.03   accuracy 63.95809531211853 loss nan\n",
      "Run 1 with dropout 0.1 and learning 0.01   accuracy 99.78952407836914 loss 0.006800137949176133\n",
      "Run 1 with dropout 0.1 and learning 0.05   accuracy 53.80523681640625 loss nan\n",
      "Run 1 with dropout 0.1 and learning 0.005   accuracy 99.40333366394043 loss 0.04015402573859319\n",
      "Run 1 with dropout 0.1 and learning 0.0005   accuracy 95.60952305793762 loss 0.2668579205870628\n",
      "Run 1 with dropout 0.1 and learning 0.075   accuracy 35.86095213890076 loss nan\n",
      "Run 1 with dropout 0.1 and learning 0.025   accuracy 75.60142874717712 loss nan\n",
      "Run 1 with dropout 0.1 and learning 0.03   accuracy 74.45761859416962 loss nan\n",
      "Run 2 with dropout 0.35 and learning 0.01   accuracy 99.95809435844421 loss 0.001612645632121712\n",
      "Run 2 with dropout 0.35 and learning 0.05   accuracy 62.14380860328674 loss nan\n",
      "Run 2 with dropout 0.35 and learning 0.005   accuracy 99.85809445381165 loss 0.008382602490019053\n",
      "Run 2 with dropout 0.35 and learning 0.0005   accuracy 96.39380931854248 loss 0.141517336666584\n",
      "Run 2 with dropout 0.35 and learning 0.075   accuracy 35.86095213890076 loss nan\n",
      "Run 2 with dropout 0.35 and learning 0.025   accuracy 89.06047523021698 loss nan\n",
      "Run 2 with dropout 0.35 and learning 0.03   accuracy 71.50047540664673 loss nan\n",
      "Run 3 with dropout 0.5 and learning 0.01   accuracy 99.96714115142822 loss 0.0011628185457084328\n",
      "Run 3 with dropout 0.5 and learning 0.05   accuracy 39.310951828956604 loss nan\n",
      "Run 3 with dropout 0.5 and learning 0.005   accuracy 99.9571442604065 loss 0.001813067600596696\n",
      "Run 3 with dropout 0.5 and learning 0.0005   accuracy 89.49571371078491 loss 0.4151497485116124\n",
      "Run 3 with dropout 0.5 and learning 0.075   accuracy 68.9599996805191 loss nan\n",
      "Run 3 with dropout 0.5 and learning 0.025   accuracy 60.793333649635315 loss nan\n",
      "Run 3 with dropout 0.5 and learning 0.03   accuracy 68.76047492027283 loss nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dropout_search)):\n",
    "    for j in range(len(learning_search)):\n",
    "        print(f'Run {i} with dropout {dropout_search[i]} and learning {learning_search[j]} ',\n",
    "              f' accuracy {full_acc_per_fold[i][j]} loss {full_loss_per_fold[i][j]}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'full_acc_per_fold' (list)\n",
      "Stored 'full_loss_per_fold' (list)\n"
     ]
    }
   ],
   "source": [
    "%store full_acc_per_fold\n",
    "%store full_loss_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tag_map\n",
    "%store -r word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 2000.0,\n",
       " 2: 2000.0,\n",
       " 3: 2000.0,\n",
       " 4: 2000.0,\n",
       " 5: 2000.0,\n",
       " 6: 1.0,\n",
       " 7: 2000.0,\n",
       " 8: 1.0,\n",
       " 9: 1.0,\n",
       " 10: 1.0,\n",
       " 11: 1.0,\n",
       " 12: 1.0,\n",
       " 13: 1.0,\n",
       " 14: 1.0,\n",
       " 15: 1.0,\n",
       " 16: 1.0,\n",
       " 17: 1.0,\n",
       " 18: 1.0,\n",
       " 19: 1.0,\n",
       " 20: 1.0,\n",
       " 21: 1.0,\n",
       " 22: 1.0,\n",
       " 23: 1.0,\n",
       " 24: 1.0,\n",
       " 25: 1.0,\n",
       " 26: 1.0,\n",
       " 27: 1.0,\n",
       " 28: 1.0,\n",
       " 29: 1.0,\n",
       " 30: 1.0,\n",
       " 31: 1.0,\n",
       " 32: 1.0,\n",
       " 33: 1.0,\n",
       " 34: 1.0,\n",
       " 35: 1.0,\n",
       " 36: 1.0,\n",
       " 37: 1.0,\n",
       " 38: 1.0,\n",
       " 39: 1.0,\n",
       " 40: 1.0,\n",
       " 41: 1.0,\n",
       " 42: 1.0,\n",
       " 43: 1.0,\n",
       " 44: 1.0,\n",
       " 45: 1.0,\n",
       " 46: 1.0,\n",
       " 47: 1.0,\n",
       " 48: 1.0,\n",
       " 49: 1.0,\n",
       " 50: 1.0,\n",
       " 51: 1.0,\n",
       " 52: 1.0,\n",
       " 53: 1.0,\n",
       " 54: 1.0,\n",
       " 55: 1.0,\n",
       " 56: 1.0,\n",
       " 57: 1.0,\n",
       " 58: 1.0,\n",
       " 59: 1.0,\n",
       " 60: 1.0,\n",
       " 61: 1.0,\n",
       " 62: 1.0,\n",
       " 63: 1.0,\n",
       " 64: 1.0,\n",
       " 65: 1.0,\n",
       " 66: 1.0,\n",
       " 67: 1.0,\n",
       " 68: 1.0,\n",
       " 69: 1.0,\n",
       " 70: 1.0,\n",
       " 71: 1.0,\n",
       " 72: 1.0,\n",
       " 73: 1.0,\n",
       " 74: 1.0,\n",
       " 75: 1.0,\n",
       " 76: 1.0,\n",
       " 77: 1.0,\n",
       " 78: 1.0,\n",
       " 79: 1.0,\n",
       " 80: 1.0,\n",
       " 81: 1.0,\n",
       " 82: 1.0,\n",
       " 83: 1.0,\n",
       " 84: 1.0,\n",
       " 85: 1.0,\n",
       " 86: 1.0,\n",
       " 87: 1.0,\n",
       " 88: 1.0,\n",
       " 89: 1.0,\n",
       " 90: 1.0,\n",
       " 91: 1.0,\n",
       " 92: 1.0,\n",
       " 93: 1.0,\n",
       " 94: 1.0,\n",
       " 95: 1.0,\n",
       " 96: 1.0,\n",
       " 97: 1.0,\n",
       " 98: 1.0,\n",
       " 99: 1.0,\n",
       " 100: 1.0,\n",
       " 101: 1.0,\n",
       " 102: 1.0,\n",
       " 103: 1.0,\n",
       " 104: 1.0,\n",
       " 105: 1.0,\n",
       " 106: 1.0,\n",
       " 107: 1.0,\n",
       " 108: 1.0,\n",
       " 109: 1.0,\n",
       " 110: 1.0,\n",
       " 111: 1.0,\n",
       " 112: 1.0,\n",
       " 113: 1.0,\n",
       " 114: 1.0,\n",
       " 115: 1.0,\n",
       " 116: 1.0,\n",
       " 117: 1.0,\n",
       " 118: 1.0,\n",
       " 119: 1.0,\n",
       " 120: 1.0,\n",
       " 121: 1.0,\n",
       " 122: 1.0,\n",
       " 123: 1.0,\n",
       " 124: 1.0,\n",
       " 125: 1.0,\n",
       " 126: 1.0,\n",
       " 127: 1.0,\n",
       " 128: 1.0,\n",
       " 129: 1.0,\n",
       " 130: 1.0,\n",
       " 131: 1.0,\n",
       " 132: 1.0,\n",
       " 133: 1.0,\n",
       " 134: 1.0,\n",
       " 135: 1.0,\n",
       " 136: 1.0,\n",
       " 137: 1.0,\n",
       " 138: 1.0,\n",
       " 139: 1.0,\n",
       " 140: 1.0,\n",
       " 141: 1.0,\n",
       " 142: 1.0,\n",
       " 143: 1.0,\n",
       " 144: 1.0,\n",
       " 145: 1.0,\n",
       " 146: 1.0,\n",
       " 147: 1.0,\n",
       " 148: 1.0,\n",
       " 149: 1.0,\n",
       " 150: 1.0,\n",
       " 151: 1.0,\n",
       " 152: 1.0,\n",
       " 153: 1.0,\n",
       " 154: 1.0,\n",
       " 155: 1.0,\n",
       " 156: 1.0,\n",
       " 157: 1.0,\n",
       " 158: 1.0,\n",
       " 159: 1.0,\n",
       " 160: 1.0,\n",
       " 161: 1.0,\n",
       " 162: 1.0,\n",
       " 163: 1.0,\n",
       " 164: 1.0,\n",
       " 165: 1.0,\n",
       " 166: 1.0,\n",
       " 167: 1.0,\n",
       " 168: 1.0,\n",
       " 169: 1.0,\n",
       " 170: 1.0,\n",
       " 171: 1.0,\n",
       " 172: 1.0,\n",
       " 173: 1.0,\n",
       " 174: 1.0,\n",
       " 175: 1.0,\n",
       " 176: 1.0,\n",
       " 177: 1.0,\n",
       " 178: 1.0,\n",
       " 179: 1.0,\n",
       " 180: 1.0,\n",
       " 181: 1.0,\n",
       " 182: 1.0,\n",
       " 183: 1.0,\n",
       " 184: 1.0,\n",
       " 185: 1.0,\n",
       " 186: 1.0,\n",
       " 187: 1.0,\n",
       " 188: 1.0,\n",
       " 189: 1.0,\n",
       " 190: 1.0,\n",
       " 191: 1.0,\n",
       " 192: 1.0,\n",
       " 193: 1.0,\n",
       " 194: 1.0,\n",
       " 195: 1.0,\n",
       " 196: 1.0,\n",
       " 197: 1.0,\n",
       " 198: 1.0,\n",
       " 199: 1.0,\n",
       " 200: 1.0,\n",
       " 201: 1.0,\n",
       " 202: 1.0,\n",
       " 203: 1.0,\n",
       " 204: 1.0,\n",
       " 205: 1.0,\n",
       " 206: 1.0,\n",
       " 207: 1.0,\n",
       " 208: 1.0,\n",
       " 209: 1.0,\n",
       " 210: 1.0,\n",
       " 211: 1.0,\n",
       " 212: 1.0,\n",
       " 213: 1.0,\n",
       " 214: 1.0,\n",
       " 215: 1.0,\n",
       " 216: 1.0,\n",
       " 217: 1.0,\n",
       " 218: 1.0,\n",
       " 219: 1.0,\n",
       " 220: 1.0,\n",
       " 221: 1.0,\n",
       " 222: 1.0,\n",
       " 223: 1.0,\n",
       " 224: 1.0,\n",
       " 225: 1.0,\n",
       " 226: 1.0,\n",
       " 227: 1.0,\n",
       " 228: 1.0,\n",
       " 229: 1.0,\n",
       " 230: 1.0,\n",
       " 231: 1.0,\n",
       " 232: 1.0,\n",
       " 233: 1.0,\n",
       " 234: 1.0,\n",
       " 235: 1.0,\n",
       " 236: 1.0,\n",
       " 237: 1.0,\n",
       " 238: 1.0,\n",
       " 239: 1.0,\n",
       " 240: 1.0,\n",
       " 241: 1.0,\n",
       " 242: 1.0,\n",
       " 243: 1.0,\n",
       " 244: 1.0,\n",
       " 245: 1.0,\n",
       " 246: 1.0,\n",
       " 247: 1.0,\n",
       " 248: 1.0,\n",
       " 249: 1.0,\n",
       " 250: 1.0,\n",
       " 251: 1.0,\n",
       " 252: 1.0,\n",
       " 253: 1.0,\n",
       " 254: 1.0,\n",
       " 255: 1.0,\n",
       " 256: 1.0,\n",
       " 257: 1.0,\n",
       " 258: 1.0,\n",
       " 259: 1.0,\n",
       " 260: 1.0,\n",
       " 261: 1.0,\n",
       " 262: 1.0,\n",
       " 263: 1.0,\n",
       " 264: 1.0,\n",
       " 265: 1.0,\n",
       " 266: 1.0,\n",
       " 267: 1.0,\n",
       " 268: 1.0,\n",
       " 269: 1.0,\n",
       " 270: 1.0,\n",
       " 271: 1.0,\n",
       " 272: 1.0,\n",
       " 273: 1.0,\n",
       " 274: 1.0,\n",
       " 275: 1.0,\n",
       " 276: 1.0,\n",
       " 277: 1.0,\n",
       " 278: 1.0,\n",
       " 279: 1.0,\n",
       " 280: 1.0,\n",
       " 281: 1.0,\n",
       " 282: 1.0,\n",
       " 283: 1.0,\n",
       " 284: 1.0,\n",
       " 285: 1.0,\n",
       " 286: 1.0,\n",
       " 287: 1.0,\n",
       " 288: 1.0,\n",
       " 289: 1.0,\n",
       " 290: 1.0,\n",
       " 291: 1.0,\n",
       " 292: 1.0,\n",
       " 293: 1.0,\n",
       " 294: 1.0,\n",
       " 295: 1.0,\n",
       " 296: 1.0,\n",
       " 297: 1.0,\n",
       " 298: 1.0,\n",
       " 299: 1.0,\n",
       " 300: 1.0,\n",
       " 301: 1.0,\n",
       " 302: 1.0,\n",
       " 303: 1.0,\n",
       " 304: 1.0,\n",
       " 305: 1.0,\n",
       " 306: 1.0,\n",
       " 307: 1.0,\n",
       " 308: 1.0,\n",
       " 309: 1.0,\n",
       " 310: 1.0,\n",
       " 311: 1.0,\n",
       " 312: 1.0,\n",
       " 313: 1.0,\n",
       " 314: 1.0,\n",
       " 315: 1.0,\n",
       " 316: 1.0,\n",
       " 317: 1.0,\n",
       " 318: 1.0,\n",
       " 319: 1.0,\n",
       " 320: 1.0,\n",
       " 321: 1.0,\n",
       " 322: 1.0,\n",
       " 323: 1.0,\n",
       " 324: 1.0,\n",
       " 325: 1.0,\n",
       " 326: 1.0,\n",
       " 327: 1.0,\n",
       " 328: 1.0,\n",
       " 329: 1.0,\n",
       " 330: 1.0,\n",
       " 331: 1.0,\n",
       " 332: 1.0,\n",
       " 333: 1.0,\n",
       " 334: 1.0,\n",
       " 335: 1.0,\n",
       " 336: 1.0,\n",
       " 337: 1.0,\n",
       " 338: 1.0,\n",
       " 339: 1.0,\n",
       " 340: 1.0,\n",
       " 341: 1.0,\n",
       " 342: 1.0,\n",
       " 343: 1.0,\n",
       " 344: 1.0,\n",
       " 345: 1.0,\n",
       " 346: 1.0,\n",
       " 347: 1.0,\n",
       " 348: 1.0,\n",
       " 349: 1.0,\n",
       " 350: 1.0,\n",
       " 351: 1.0,\n",
       " 352: 1.0,\n",
       " 353: 1.0,\n",
       " 354: 1.0,\n",
       " 355: 1.0,\n",
       " 356: 1.0,\n",
       " 357: 1.0,\n",
       " 358: 1.0,\n",
       " 359: 1.0,\n",
       " 360: 1.0,\n",
       " 361: 1.0,\n",
       " 362: 1.0,\n",
       " 363: 1.0,\n",
       " 364: 1.0,\n",
       " 365: 1.0,\n",
       " 366: 1.0,\n",
       " 367: 1.0,\n",
       " 368: 1.0,\n",
       " 369: 1.0,\n",
       " 370: 1.0,\n",
       " 371: 1.0,\n",
       " 372: 1.0,\n",
       " 373: 1.0,\n",
       " 374: 1.0,\n",
       " 375: 1.0,\n",
       " 376: 1.0,\n",
       " 377: 1.0,\n",
       " 378: 1.0,\n",
       " 379: 1.0,\n",
       " 380: 1.0,\n",
       " 381: 1.0,\n",
       " 382: 1.0,\n",
       " 383: 1.0,\n",
       " 384: 1.0,\n",
       " 385: 1.0,\n",
       " 386: 1.0,\n",
       " 387: 1.0,\n",
       " 388: 1.0,\n",
       " 389: 1.0,\n",
       " 390: 1.0,\n",
       " 391: 1.0,\n",
       " 392: 1.0,\n",
       " 393: 1.0,\n",
       " 394: 1.0,\n",
       " 395: 1.0,\n",
       " 396: 1.0,\n",
       " 397: 1.0,\n",
       " 398: 1.0,\n",
       " 399: 1.0,\n",
       " 400: 1.0,\n",
       " 401: 1.0,\n",
       " 402: 1.0,\n",
       " 403: 1.0,\n",
       " 404: 1.0,\n",
       " 405: 1.0,\n",
       " 406: 1.0,\n",
       " 407: 1.0,\n",
       " 408: 1.0,\n",
       " 409: 1.0,\n",
       " 410: 1.0,\n",
       " 411: 1.0,\n",
       " 412: 1.0,\n",
       " 413: 1.0,\n",
       " 414: 1.0,\n",
       " 415: 1.0,\n",
       " 416: 1.0,\n",
       " 417: 1.0,\n",
       " 418: 1.0,\n",
       " 419: 1.0,\n",
       " 420: 1.0,\n",
       " 421: 1.0,\n",
       " 422: 1.0,\n",
       " 423: 1.0,\n",
       " 424: 1.0,\n",
       " 425: 1.0,\n",
       " 426: 1.0,\n",
       " 427: 1.0,\n",
       " 428: 1.0,\n",
       " 429: 1.0,\n",
       " 430: 1.0,\n",
       " 431: 1.0,\n",
       " 432: 1.0,\n",
       " 433: 1.0,\n",
       " 434: 1.0,\n",
       " 435: 1.0,\n",
       " 436: 1.0,\n",
       " 437: 1.0,\n",
       " 438: 1.0,\n",
       " 439: 1.0,\n",
       " 440: 1.0,\n",
       " 441: 1.0,\n",
       " 442: 1.0,\n",
       " 443: 1.0,\n",
       " 444: 1.0,\n",
       " 445: 1.0,\n",
       " 446: 1.0,\n",
       " 447: 1.0,\n",
       " 448: 1.0,\n",
       " 449: 1.0,\n",
       " 450: 1.0,\n",
       " 451: 1.0,\n",
       " 452: 1.0,\n",
       " 453: 1.0,\n",
       " 454: 1.0,\n",
       " 455: 1.0,\n",
       " 456: 1.0,\n",
       " 457: 1.0,\n",
       " 458: 1.0,\n",
       " 459: 1.0,\n",
       " 460: 1.0,\n",
       " 461: 1.0,\n",
       " 462: 1.0,\n",
       " 463: 1.0,\n",
       " 464: 1.0,\n",
       " 465: 1.0,\n",
       " 466: 1.0,\n",
       " 467: 1.0,\n",
       " 468: 1.0,\n",
       " 469: 1.0,\n",
       " 470: 1.0,\n",
       " 471: 1.0,\n",
       " 472: 1.0,\n",
       " 473: 1.0,\n",
       " 474: 1.0,\n",
       " 475: 1.0,\n",
       " 476: 1.0,\n",
       " 477: 1.0,\n",
       " 478: 1.0,\n",
       " 479: 1.0,\n",
       " 480: 1.0,\n",
       " 481: 1.0,\n",
       " 482: 1.0,\n",
       " 483: 1.0,\n",
       " 484: 1.0,\n",
       " 485: 1.0,\n",
       " 486: 1.0,\n",
       " 487: 1.0,\n",
       " 488: 1.0,\n",
       " 489: 1.0,\n",
       " 490: 1.0,\n",
       " 491: 1.0,\n",
       " 492: 1.0,\n",
       " 493: 1.0,\n",
       " 494: 1.0,\n",
       " 495: 1.0,\n",
       " 496: 1.0,\n",
       " 497: 1.0,\n",
       " 498: 1.0,\n",
       " 499: 1.0,\n",
       " 500: 1.0,\n",
       " 501: 1.0,\n",
       " 502: 1.0,\n",
       " 503: 1.0,\n",
       " 504: 1.0,\n",
       " 505: 1.0,\n",
       " 506: 1.0,\n",
       " 507: 1.0,\n",
       " 508: 1.0,\n",
       " 509: 1.0,\n",
       " 510: 1.0,\n",
       " 511: 1.0,\n",
       " 512: 1.0,\n",
       " 513: 1.0,\n",
       " 514: 1.0,\n",
       " 515: 1.0,\n",
       " 516: 1.0,\n",
       " 517: 1.0,\n",
       " 518: 1.0,\n",
       " 519: 1.0,\n",
       " 520: 1.0,\n",
       " 521: 1.0,\n",
       " 522: 1.0,\n",
       " 523: 1.0,\n",
       " 524: 1.0,\n",
       " 525: 1.0,\n",
       " 526: 1.0,\n",
       " 527: 1.0,\n",
       " 528: 1.0,\n",
       " 529: 1.0,\n",
       " 530: 1.0,\n",
       " 531: 1.0,\n",
       " 532: 1.0,\n",
       " 533: 1.0,\n",
       " 534: 1.0,\n",
       " 535: 1.0,\n",
       " 536: 1.0,\n",
       " 537: 1.0,\n",
       " 538: 1.0,\n",
       " 539: 1.0,\n",
       " 540: 1.0,\n",
       " 541: 1.0,\n",
       " 542: 1.0,\n",
       " 543: 1.0,\n",
       " 544: 1.0,\n",
       " 545: 1.0,\n",
       " 546: 1.0,\n",
       " 547: 1.0,\n",
       " 548: 1.0,\n",
       " 549: 1.0,\n",
       " 550: 1.0,\n",
       " 551: 1.0,\n",
       " 552: 1.0,\n",
       " 553: 1.0,\n",
       " 554: 1.0,\n",
       " 555: 1.0,\n",
       " 556: 1.0,\n",
       " 557: 1.0,\n",
       " 558: 1.0,\n",
       " 559: 1.0,\n",
       " 560: 1.0,\n",
       " 561: 1.0,\n",
       " 562: 1.0,\n",
       " 563: 1.0,\n",
       " 564: 1.0,\n",
       " 565: 1.0,\n",
       " 566: 1.0,\n",
       " 567: 1.0,\n",
       " 568: 1.0,\n",
       " 569: 1.0,\n",
       " 570: 1.0,\n",
       " 571: 1.0,\n",
       " 572: 1.0,\n",
       " 573: 1.0,\n",
       " 574: 1.0,\n",
       " 575: 1.0,\n",
       " 576: 1.0,\n",
       " 577: 1.0,\n",
       " 578: 1.0,\n",
       " 579: 1.0,\n",
       " 580: 1.0,\n",
       " 581: 1.0,\n",
       " 582: 1.0,\n",
       " 583: 1.0,\n",
       " 584: 1.0,\n",
       " 585: 1.0,\n",
       " 586: 1.0,\n",
       " 587: 1.0,\n",
       " 588: 1.0,\n",
       " 589: 1.0,\n",
       " 590: 1.0,\n",
       " 591: 1.0,\n",
       " 592: 1.0,\n",
       " 593: 1.0,\n",
       " 594: 1.0,\n",
       " 595: 1.0,\n",
       " 596: 1.0,\n",
       " 597: 1.0,\n",
       " 598: 1.0,\n",
       " 599: 1.0,\n",
       " 600: 1.0,\n",
       " 601: 1.0,\n",
       " 602: 1.0,\n",
       " 603: 1.0,\n",
       " 604: 1.0,\n",
       " 605: 1.0,\n",
       " 606: 1.0,\n",
       " 607: 1.0,\n",
       " 608: 1.0,\n",
       " 609: 1.0,\n",
       " 610: 1.0,\n",
       " 611: 1.0,\n",
       " 612: 1.0,\n",
       " 613: 1.0,\n",
       " 614: 1.0,\n",
       " 615: 1.0,\n",
       " 616: 1.0,\n",
       " 617: 1.0,\n",
       " 618: 1.0,\n",
       " 619: 1.0,\n",
       " 620: 1.0,\n",
       " 621: 1.0,\n",
       " 622: 1.0,\n",
       " 623: 1.0,\n",
       " 624: 1.0,\n",
       " 625: 1.0,\n",
       " 626: 1.0,\n",
       " 627: 1.0,\n",
       " 628: 1.0,\n",
       " 629: 1.0,\n",
       " 630: 1.0,\n",
       " 631: 1.0,\n",
       " 632: 1.0,\n",
       " 633: 1.0,\n",
       " 634: 1.0,\n",
       " 635: 1.0,\n",
       " 636: 1.0,\n",
       " 637: 1.0,\n",
       " 638: 1.0,\n",
       " 639: 1.0,\n",
       " 640: 1.0,\n",
       " 641: 1.0,\n",
       " 642: 1.0,\n",
       " 643: 1.0,\n",
       " 644: 1.0,\n",
       " 645: 1.0,\n",
       " 646: 1.0,\n",
       " 647: 1.0,\n",
       " 648: 1.0,\n",
       " 649: 1.0,\n",
       " 650: 1.0,\n",
       " 651: 1.0,\n",
       " 652: 1.0,\n",
       " 653: 1.0,\n",
       " 654: 1.0,\n",
       " 655: 1.0,\n",
       " 656: 1.0,\n",
       " 657: 1.0,\n",
       " 658: 1.0,\n",
       " 659: 1.0,\n",
       " 660: 1.0,\n",
       " 661: 1.0,\n",
       " 662: 1.0,\n",
       " 663: 1.0,\n",
       " 664: 1.0,\n",
       " 665: 1.0,\n",
       " 666: 1.0,\n",
       " 667: 1.0,\n",
       " 668: 1.0,\n",
       " 669: 1.0,\n",
       " 670: 1.0,\n",
       " 671: 1.0,\n",
       " 672: 1.0,\n",
       " 673: 1.0,\n",
       " 674: 1.0,\n",
       " 675: 1.0,\n",
       " 676: 1.0,\n",
       " 677: 1.0,\n",
       " 678: 1.0,\n",
       " 679: 1.0,\n",
       " 680: 1.0,\n",
       " 681: 1.0,\n",
       " 682: 1.0,\n",
       " 683: 1.0,\n",
       " 684: 1.0,\n",
       " 685: 1.0,\n",
       " 686: 1.0,\n",
       " 687: 1.0,\n",
       " 688: 1.0,\n",
       " 689: 1.0,\n",
       " 690: 1.0,\n",
       " 691: 1.0,\n",
       " 692: 1.0,\n",
       " 693: 1.0,\n",
       " 694: 1.0,\n",
       " 695: 1.0,\n",
       " 696: 1.0,\n",
       " 697: 1.0,\n",
       " 698: 1.0,\n",
       " 699: 1.0,\n",
       " 700: 1.0,\n",
       " 701: 1.0,\n",
       " 702: 1.0,\n",
       " 703: 1.0,\n",
       " 704: 1.0,\n",
       " 705: 1.0,\n",
       " 706: 1.0,\n",
       " 707: 1.0,\n",
       " 708: 1.0,\n",
       " 709: 1.0,\n",
       " 710: 1.0,\n",
       " 711: 1.0,\n",
       " 712: 1.0,\n",
       " 713: 1.0,\n",
       " 714: 1.0,\n",
       " 715: 1.0,\n",
       " 716: 1.0,\n",
       " 717: 1.0,\n",
       " 718: 1.0,\n",
       " 719: 1.0,\n",
       " 720: 1.0,\n",
       " 721: 1.0,\n",
       " 722: 1.0,\n",
       " 723: 1.0,\n",
       " 724: 1.0,\n",
       " 725: 1.0,\n",
       " 726: 1.0,\n",
       " 727: 1.0,\n",
       " 728: 1.0,\n",
       " 729: 1.0,\n",
       " 730: 1.0,\n",
       " 731: 1.0,\n",
       " 732: 1.0,\n",
       " 733: 1.0,\n",
       " 734: 1.0,\n",
       " 735: 1.0,\n",
       " 736: 1.0,\n",
       " 737: 1.0,\n",
       " 738: 1.0,\n",
       " 739: 1.0,\n",
       " 740: 1.0,\n",
       " 741: 1.0,\n",
       " 742: 1.0,\n",
       " 743: 1.0,\n",
       " 744: 1.0,\n",
       " 745: 1.0,\n",
       " 746: 1.0,\n",
       " 747: 1.0,\n",
       " 748: 1.0,\n",
       " 749: 1.0,\n",
       " 750: 1.0,\n",
       " 751: 1.0,\n",
       " 752: 1.0,\n",
       " 753: 1.0,\n",
       " 754: 1.0,\n",
       " 755: 1.0,\n",
       " 756: 1.0,\n",
       " 757: 1.0,\n",
       " 758: 1.0,\n",
       " 759: 1.0,\n",
       " 760: 1.0,\n",
       " 761: 1.0,\n",
       " 762: 1.0,\n",
       " 763: 1.0,\n",
       " 764: 1.0,\n",
       " 765: 1.0,\n",
       " 766: 1.0,\n",
       " 767: 1.0,\n",
       " 768: 1.0,\n",
       " 769: 1.0,\n",
       " 770: 1.0,\n",
       " 771: 1.0,\n",
       " 772: 1.0,\n",
       " 773: 1.0,\n",
       " 774: 1.0,\n",
       " 775: 1.0,\n",
       " 776: 1.0,\n",
       " 777: 1.0,\n",
       " 778: 1.0,\n",
       " 779: 1.0,\n",
       " 780: 1.0,\n",
       " 781: 1.0,\n",
       " 782: 1.0,\n",
       " 783: 1.0,\n",
       " 784: 1.0,\n",
       " 785: 1.0,\n",
       " 786: 1.0,\n",
       " 787: 1.0,\n",
       " 788: 1.0,\n",
       " 789: 1.0,\n",
       " 790: 1.0,\n",
       " 791: 1.0,\n",
       " 792: 1.0,\n",
       " 793: 1.0,\n",
       " 794: 1.0,\n",
       " 795: 1.0,\n",
       " 796: 1.0,\n",
       " 797: 1.0,\n",
       " 798: 1.0,\n",
       " 799: 1.0,\n",
       " 800: 1.0,\n",
       " 801: 1.0,\n",
       " 802: 1.0,\n",
       " 803: 1.0,\n",
       " 804: 1.0,\n",
       " 805: 1.0,\n",
       " 806: 1.0,\n",
       " 807: 1.0,\n",
       " 808: 1.0,\n",
       " 809: 1.0,\n",
       " 810: 1.0,\n",
       " 811: 1.0,\n",
       " 812: 1.0,\n",
       " 813: 1.0,\n",
       " 814: 1.0,\n",
       " 815: 1.0,\n",
       " 816: 1.0,\n",
       " 817: 1.0,\n",
       " 818: 1.0,\n",
       " 819: 1.0,\n",
       " 820: 1.0,\n",
       " 821: 1.0,\n",
       " 822: 1.0,\n",
       " 823: 1.0,\n",
       " 824: 1.0,\n",
       " 825: 1.0,\n",
       " 826: 1.0,\n",
       " 827: 1.0,\n",
       " 828: 1.0,\n",
       " 829: 1.0,\n",
       " 830: 1.0,\n",
       " 831: 1.0,\n",
       " 832: 1.0,\n",
       " 833: 1.0,\n",
       " 834: 1.0,\n",
       " 835: 1.0,\n",
       " 836: 1.0,\n",
       " 837: 1.0,\n",
       " 838: 1.0,\n",
       " 839: 1.0,\n",
       " 840: 1.0,\n",
       " 841: 1.0,\n",
       " 842: 1.0,\n",
       " 843: 1.0,\n",
       " 844: 1.0,\n",
       " 845: 1.0,\n",
       " 846: 1.0,\n",
       " 847: 1.0,\n",
       " 848: 1.0,\n",
       " 849: 1.0,\n",
       " 850: 1.0,\n",
       " 851: 1.0,\n",
       " 852: 1.0,\n",
       " 853: 1.0,\n",
       " 854: 1.0,\n",
       " 855: 1.0,\n",
       " 856: 1.0,\n",
       " 857: 1.0,\n",
       " 858: 1.0,\n",
       " 859: 1.0,\n",
       " 860: 1.0,\n",
       " 861: 1.0,\n",
       " 862: 1.0,\n",
       " 863: 1.0,\n",
       " 864: 1.0,\n",
       " 865: 1.0,\n",
       " 866: 1.0,\n",
       " 867: 1.0,\n",
       " 868: 1.0,\n",
       " 869: 1.0,\n",
       " 870: 1.0,\n",
       " 871: 1.0,\n",
       " 872: 1.0,\n",
       " 873: 1.0,\n",
       " 874: 1.0,\n",
       " 875: 1.0,\n",
       " 876: 1.0,\n",
       " 877: 1.0,\n",
       " 878: 1.0,\n",
       " 879: 1.0,\n",
       " 880: 1.0,\n",
       " 881: 1.0,\n",
       " 882: 1.0,\n",
       " 883: 1.0,\n",
       " 884: 1.0,\n",
       " 885: 1.0,\n",
       " 886: 1.0,\n",
       " 887: 1.0,\n",
       " 888: 1.0,\n",
       " 889: 1.0,\n",
       " 890: 1.0,\n",
       " 891: 1.0,\n",
       " 892: 1.0,\n",
       " 893: 1.0,\n",
       " 894: 1.0,\n",
       " 895: 1.0,\n",
       " 896: 1.0,\n",
       " 897: 1.0,\n",
       " 898: 1.0,\n",
       " 899: 1.0,\n",
       " 900: 1.0,\n",
       " 901: 1.0,\n",
       " 902: 1.0,\n",
       " 903: 1.0,\n",
       " 904: 1.0,\n",
       " 905: 1.0,\n",
       " 906: 1.0,\n",
       " 907: 1.0,\n",
       " 908: 1.0,\n",
       " 909: 1.0,\n",
       " 910: 1.0,\n",
       " 911: 1.0,\n",
       " 912: 1.0,\n",
       " 913: 1.0,\n",
       " 914: 1.0,\n",
       " 915: 1.0,\n",
       " 916: 1.0,\n",
       " 917: 1.0,\n",
       " 918: 1.0,\n",
       " 919: 1.0,\n",
       " 920: 1.0,\n",
       " 921: 1.0,\n",
       " 922: 1.0,\n",
       " 923: 1.0,\n",
       " 924: 1.0,\n",
       " 925: 1.0,\n",
       " 926: 1.0,\n",
       " 927: 1.0,\n",
       " 928: 1.0,\n",
       " 929: 1.0,\n",
       " 930: 1.0,\n",
       " 931: 1.0,\n",
       " 932: 1.0,\n",
       " 933: 1.0,\n",
       " 934: 1.0,\n",
       " 935: 1.0,\n",
       " 936: 1.0,\n",
       " 937: 1.0,\n",
       " 938: 1.0,\n",
       " 939: 1.0,\n",
       " 940: 1.0,\n",
       " 941: 1.0,\n",
       " 942: 1.0,\n",
       " 943: 1.0,\n",
       " 944: 1.0,\n",
       " 945: 1.0,\n",
       " 946: 1.0,\n",
       " 947: 1.0,\n",
       " 948: 1.0,\n",
       " 949: 1.0,\n",
       " 950: 1.0,\n",
       " 951: 1.0,\n",
       " 952: 1.0,\n",
       " 953: 1.0,\n",
       " 954: 1.0,\n",
       " 955: 1.0,\n",
       " 956: 1.0,\n",
       " 957: 1.0,\n",
       " 958: 1.0,\n",
       " 959: 1.0,\n",
       " 960: 1.0,\n",
       " 961: 1.0,\n",
       " 962: 1.0,\n",
       " 963: 1.0,\n",
       " 964: 1.0,\n",
       " 965: 1.0,\n",
       " 966: 1.0,\n",
       " 967: 1.0,\n",
       " 968: 1.0,\n",
       " 969: 1.0,\n",
       " 970: 1.0,\n",
       " 971: 1.0,\n",
       " 972: 1.0,\n",
       " 973: 1.0,\n",
       " 974: 1.0,\n",
       " 975: 1.0,\n",
       " 976: 1.0,\n",
       " 977: 1.0,\n",
       " 978: 1.0,\n",
       " 979: 1.0,\n",
       " 980: 1.0,\n",
       " 981: 1.0,\n",
       " 982: 1.0,\n",
       " 983: 1.0,\n",
       " 984: 1.0,\n",
       " 985: 1.0,\n",
       " 986: 1.0,\n",
       " 987: 1.0,\n",
       " 988: 1.0,\n",
       " 989: 1.0,\n",
       " 990: 1.0,\n",
       " 991: 1.0,\n",
       " 992: 1.0,\n",
       " 993: 1.0,\n",
       " 994: 1.0,\n",
       " 995: 1.0,\n",
       " 996: 1.0,\n",
       " 997: 1.0,\n",
       " 998: 1.0,\n",
       " 999: 1.0,\n",
       " ...}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    inv_map = {v: k for k, v in tag_map.items()}\n",
    "    label_class_weight = {}\n",
    "    for i in range(len(word_map)):\n",
    "        if i < 8:\n",
    "            if inv_map[i]=='O' or inv_map[i]==0: # freuqent class of 'O' or '0'\n",
    "                label_class_weight[i] = 1.0\n",
    "            else:\n",
    "                label_class_weight[i] = 2000.0 # tags we actually care about (ratio for # of 0 tags to true labels)\n",
    "        else: \n",
    "            label_class_weight[i] = 1.0\n",
    "label_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_bidir_weights(n,dropout,learning,n_epochs,pat ):\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    acc_per_fold =[]\n",
    "    loss_per_fold=[]\n",
    "    \n",
    "    preds_per_fold = []\n",
    "    y_test_per_fold = []\n",
    "    histories = []\n",
    "    models =[]\n",
    "    #classificat_reports=[]\n",
    "    \n",
    "    safety = EarlyStopping(monitor='val_loss', patience=pat)\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X, y):\n",
    "\n",
    "      # Define the model architecture\n",
    "        model1 = Sequential()\n",
    "        model1.add(Embedding(len(word_map), 300, input_length=max_len))\n",
    "        model1.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "        model1.add(Dropout(dropout)) #play with this value \n",
    "        model1.add(TimeDistributed(Dense(len(tag_map),activation='softmax')))\n",
    "\n",
    "        opt =Adam(learning_rate=learning)\n",
    "        \n",
    "      # Compile the model\n",
    "        #change the learning rate\n",
    "        model1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "      # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "      # Fit data to model\n",
    "        history = model1.fit(X[train], y[train], epochs=n_epochs, validation_data=(X[test], y[test]), batch_size=20, \n",
    "                             callbacks = [safety], class_weight = label_class_weight) #add weights param\n",
    "        histories.append(history)\n",
    "      # Generate generalization metrics\n",
    "        scores = model1.evaluate(X[test], y[test], verbose=0)\n",
    "        \n",
    "        preds = model1.predict(X[test])\n",
    "        y_test = y[test]\n",
    "        y_test_per_fold.append(y_test)\n",
    "        preds_per_fold.append(preds)\n",
    "        \n",
    "        print(f'Score for fold {fold_no}: {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "      # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "    return (acc_per_fold, loss_per_fold,y_test_per_fold,y_test_per_fold,histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vector_search = [100,200,300,400,500,600,700,800,900]\n",
    "dropout_search = [0.25,0.35,0.5]\n",
    "learning_search = [0.01,0.05,0.005]\n",
    "max_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 21s 2s/step - loss: 1.9312 - accuracy: 0.5549 - val_loss: 0.1041 - val_accuracy: 0.9867\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1098 - accuracy: 0.9894 - val_loss: 0.0531 - val_accuracy: 0.9939\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0510 - accuracy: 0.9939 - val_loss: 0.0483 - val_accuracy: 0.9936\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0424 - accuracy: 0.9940 - val_loss: 0.0425 - val_accuracy: 0.9936\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.0389 - val_accuracy: 0.9936\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0280 - accuracy: 0.9938 - val_loss: 0.0388 - val_accuracy: 0.9936\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.0394 - val_accuracy: 0.9932\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.0384 - val_accuracy: 0.9926\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0384 - val_accuracy: 0.9925\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0386 - val_accuracy: 0.9923\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0393 - val_accuracy: 0.9920\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0401 - val_accuracy: 0.9922\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0390 - val_accuracy: 0.9921\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0397 - val_accuracy: 0.9918\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026087237CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 0.039723243564367294; accuracy of 99.18333292007446%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: 1.7736 - accuracy: 0.5072 - val_loss: 0.2018 - val_accuracy: 0.8949\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0740 - accuracy: 0.9850 - val_loss: 0.0463 - val_accuracy: 0.9937\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0373 - accuracy: 0.9941 - val_loss: 0.0418 - val_accuracy: 0.9937\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0286 - accuracy: 0.9939 - val_loss: 0.0344 - val_accuracy: 0.9935\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0297 - val_accuracy: 0.9935\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0277 - val_accuracy: 0.9938\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0260 - val_accuracy: 0.9940\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0272 - val_accuracy: 0.9945\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0267 - val_accuracy: 0.9945\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0292 - val_accuracy: 0.9946\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0279 - val_accuracy: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002608676BE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.02794753946363926; accuracy of 99.44761991500854%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: 1.3044 - accuracy: 0.6334 - val_loss: 0.2142 - val_accuracy: 0.9860\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1338 - accuracy: 0.9792 - val_loss: 0.0506 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0501 - accuracy: 0.9938 - val_loss: 0.0438 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0413 - accuracy: 0.9940 - val_loss: 0.0405 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0374 - accuracy: 0.9940 - val_loss: 0.0369 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0325 - accuracy: 0.9939 - val_loss: 0.0345 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0284 - accuracy: 0.9941 - val_loss: 0.0330 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.0309 - val_accuracy: 0.9938\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.0298 - val_accuracy: 0.9937\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 0.0288 - val_accuracy: 0.9936\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9937\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9937\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0258 - val_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0258 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0249 - val_accuracy: 0.9944\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0253 - val_accuracy: 0.9946\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0256 - val_accuracy: 0.9946\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0266 - val_accuracy: 0.9952\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260BE4C2C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.026410624384880066; accuracy of 99.41666722297668%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.4326 - accuracy: 0.4972 - val_loss: 0.2680 - val_accuracy: 0.9922\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1303 - accuracy: 0.9742 - val_loss: 0.0449 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0409 - accuracy: 0.9940 - val_loss: 0.0388 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0319 - accuracy: 0.9939 - val_loss: 0.0336 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0287 - val_accuracy: 0.9942\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0275 - val_accuracy: 0.9945\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0267 - val_accuracy: 0.9949\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0274 - val_accuracy: 0.9950\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0272 - val_accuracy: 0.9951\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0285 - val_accuracy: 0.9953\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0312 - val_accuracy: 0.9953\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0324 - val_accuracy: 0.9952\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260C147E700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.03236551582813263; accuracy of 99.52380657196045%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 20s 2s/step - loss: 1.4359 - accuracy: 0.5970 - val_loss: 0.1099 - val_accuracy: 0.9940\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0791 - accuracy: 0.9935 - val_loss: 0.0462 - val_accuracy: 0.9930\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0515 - accuracy: 0.9937 - val_loss: 0.0451 - val_accuracy: 0.9940\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0477 - accuracy: 0.9939 - val_loss: 0.0440 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0447 - accuracy: 0.9939 - val_loss: 0.0396 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0408 - accuracy: 0.9940 - val_loss: 0.0369 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0346 - accuracy: 0.9939 - val_loss: 0.0337 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0286 - accuracy: 0.9939 - val_loss: 0.0310 - val_accuracy: 0.9939\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.0322 - val_accuracy: 0.9938\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0309 - val_accuracy: 0.9934\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0314 - val_accuracy: 0.9936\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0316 - val_accuracy: 0.9936\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0325 - val_accuracy: 0.9938\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.0321 - val_accuracy: 0.9939\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9936\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260C66D55E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.03251514583826065; accuracy of 99.36428666114807%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 5.0021 - accuracy: 0.3999 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.2115 - accuracy: 0.6146 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.6566 - accuracy: 0.5870 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.3332 - accuracy: 0.6071 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.1819 - accuracy: 0.6165 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 15s 2s/step - loss: 6.3385 - accuracy: 0.6067 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260CEECC8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 4.29316520690918; accuracy of 73.36428761482239%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 20s 2s/step - loss: nan - accuracy: 0.2259 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3529 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3501 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3713 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3515 - val_loss: nan - val_accuracy: 0.3218\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260A75A9D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of nan; accuracy of 32.17619061470032%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: nan - accuracy: 0.3196 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3671 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3608 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3549 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3780 - val_loss: nan - val_accuracy: 0.3300\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260B9D8BEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of nan; accuracy of 32.99523890018463%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: 4.7343 - accuracy: 0.3976 - val_loss: 0.1089 - val_accuracy: 0.9922\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.1105 - accuracy: 0.9923 - val_loss: 0.0976 - val_accuracy: 0.9931\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0991 - accuracy: 0.9933 - val_loss: 0.0957 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0992 - accuracy: 0.9937 - val_loss: 0.0953 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0994 - accuracy: 0.9937 - val_loss: 0.0955 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0968 - accuracy: 0.9940 - val_loss: 0.0955 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0953 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0971 - accuracy: 0.9939 - val_loss: 0.0952 - val_accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0974 - accuracy: 0.9938 - val_loss: 0.0962 - val_accuracy: 0.9939\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0956 - accuracy: 0.9940 - val_loss: 0.0953 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0991 - accuracy: 0.9938 - val_loss: 0.0948 - val_accuracy: 0.9940\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0965 - accuracy: 0.9939 - val_loss: 0.0951 - val_accuracy: 0.9940\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0969 - accuracy: 0.9939 - val_loss: 0.0949 - val_accuracy: 0.9940\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0988 - accuracy: 0.9938 - val_loss: 0.0944 - val_accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0964 - accuracy: 0.9939 - val_loss: 0.0944 - val_accuracy: 0.9940\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0963 - accuracy: 0.9939 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0960 - accuracy: 0.9939 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0949 - accuracy: 0.9940 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0947 - accuracy: 0.9941 - val_loss: 0.0944 - val_accuracy: 0.9940\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0966 - accuracy: 0.9940 - val_loss: 0.0943 - val_accuracy: 0.9940\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0943 - accuracy: 0.9941 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0956 - accuracy: 0.9940 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0969 - accuracy: 0.9939 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0945 - accuracy: 0.9941 - val_loss: 0.0942 - val_accuracy: 0.9940\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0941 - accuracy: 0.9941 - val_loss: 0.0943 - val_accuracy: 0.9940\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0947 - accuracy: 0.9941 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0946 - accuracy: 0.9940 - val_loss: 0.0945 - val_accuracy: 0.9940\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260A1C9E670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.09447569400072098; accuracy of 99.40000176429749%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: nan - accuracy: 0.2072 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3132 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3274 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3403 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3422 - val_loss: nan - val_accuracy: 0.4663\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026097C888B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of nan; accuracy of 46.6309517621994%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.25 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6404 - accuracy: 0.5142 - val_loss: 0.0502 - val_accuracy: 0.9939\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0612 - accuracy: 0.9938 - val_loss: 0.0711 - val_accuracy: 0.9939\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0675 - accuracy: 0.9940 - val_loss: 0.0544 - val_accuracy: 0.9939\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0479 - accuracy: 0.9939 - val_loss: 0.0474 - val_accuracy: 0.9939\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0359 - accuracy: 0.9940 - val_loss: 0.0408 - val_accuracy: 0.9937\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0349 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0335 - val_accuracy: 0.9935\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0320 - val_accuracy: 0.9937\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0310 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0318 - val_accuracy: 0.9939\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0319 - val_accuracy: 0.9941\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0314 - val_accuracy: 0.9940\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0309 - val_accuracy: 0.9937\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.9939\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0317 - val_accuracy: 0.9938\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0318 - val_accuracy: 0.9938\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0334 - val_accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0350 - val_accuracy: 0.9942\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260A9F38550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 0.03497595712542534; accuracy of 99.41904544830322%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.1261 - accuracy: 0.5501 - val_loss: 0.1058 - val_accuracy: 0.9897\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0828 - accuracy: 0.9913 - val_loss: 0.0630 - val_accuracy: 0.9937\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0553 - accuracy: 0.9939 - val_loss: 0.0454 - val_accuracy: 0.9937\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0432 - accuracy: 0.9940 - val_loss: 0.0402 - val_accuracy: 0.9937\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0360 - accuracy: 0.9940 - val_loss: 0.0345 - val_accuracy: 0.9937\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0281 - accuracy: 0.9941 - val_loss: 0.0302 - val_accuracy: 0.9937\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0292 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0286 - val_accuracy: 0.9937\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.0284 - val_accuracy: 0.9938\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0288 - val_accuracy: 0.9938\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0289 - val_accuracy: 0.9937\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0283 - val_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0288 - val_accuracy: 0.9941\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0283 - val_accuracy: 0.9932\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0292 - val_accuracy: 0.9943\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0281 - val_accuracy: 0.9936\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0285 - val_accuracy: 0.9942\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0297 - val_accuracy: 0.9927\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260D4E82280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.02974054403603077; accuracy of 99.26666617393494%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.2621 - accuracy: 0.4461 - val_loss: 0.0950 - val_accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0977 - accuracy: 0.9872 - val_loss: 0.0583 - val_accuracy: 0.9912\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0564 - accuracy: 0.9918 - val_loss: 0.0427 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0406 - accuracy: 0.9939 - val_loss: 0.0370 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0354 - accuracy: 0.9938 - val_loss: 0.0315 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0275 - accuracy: 0.9940 - val_loss: 0.0282 - val_accuracy: 0.9941\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0256 - val_accuracy: 0.9941\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0250 - val_accuracy: 0.9942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0248 - val_accuracy: 0.9943\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0242 - val_accuracy: 0.9944\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0240 - val_accuracy: 0.9943\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0239 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0237 - val_accuracy: 0.9945\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0232 - val_accuracy: 0.9946\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0231 - val_accuracy: 0.9946\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0234 - val_accuracy: 0.9943\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0230 - val_accuracy: 0.9949\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0233 - val_accuracy: 0.9950\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0233 - val_accuracy: 0.9949\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0233 - val_accuracy: 0.9946\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0237 - val_accuracy: 0.9949\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0242 - val_accuracy: 0.9951\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260E387F8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.024153629317879677; accuracy of 99.51428771018982%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 20s 2s/step - loss: 1.6696 - accuracy: 0.5155 - val_loss: 0.0760 - val_accuracy: 0.9866\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0833 - accuracy: 0.9852 - val_loss: 0.0783 - val_accuracy: 0.9904\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0760 - accuracy: 0.9912 - val_loss: 0.0598 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0568 - accuracy: 0.9933 - val_loss: 0.0457 - val_accuracy: 0.9931\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0676 - accuracy: 0.9903 - val_loss: 0.0400 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0685 - accuracy: 0.9855 - val_loss: 0.0434 - val_accuracy: 0.9941\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0367 - accuracy: 0.9939 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0290 - accuracy: 0.9937 - val_loss: 0.0317 - val_accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.0313 - val_accuracy: 0.9940\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.0305 - val_accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0308 - val_accuracy: 0.9940\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0303 - val_accuracy: 0.9939\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0297 - val_accuracy: 0.9938\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0305 - val_accuracy: 0.9941\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0297 - val_accuracy: 0.9941\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0308 - val_accuracy: 0.9942\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0298 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.0290 - val_accuracy: 0.9942\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0299 - val_accuracy: 0.9946\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0301 - val_accuracy: 0.9948\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0311 - val_accuracy: 0.9946\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0324 - val_accuracy: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260AA073670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.03240014240145683; accuracy of 99.47142601013184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6699 - accuracy: 0.5274 - val_loss: 0.0564 - val_accuracy: 0.9920\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0563 - accuracy: 0.9903 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0506 - accuracy: 0.9907 - val_loss: 0.0436 - val_accuracy: 0.9930\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0427 - accuracy: 0.9930 - val_loss: 0.0377 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0349 - accuracy: 0.9938 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0511 - accuracy: 0.9892 - val_loss: 0.0345 - val_accuracy: 0.9939\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0303 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.0278 - val_accuracy: 0.9939\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0267 - val_accuracy: 0.9937\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0268 - val_accuracy: 0.9937\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9935\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9937\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0279 - val_accuracy: 0.9927\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0294 - val_accuracy: 0.9940\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0282 - val_accuracy: 0.9940\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000260F3EBC5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.028229758143424988; accuracy of 99.40476417541504%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.7709 - accuracy: 0.5314 - val_loss: 0.1412 - val_accuracy: 0.9924\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1061 - accuracy: 0.9874 - val_loss: 0.0505 - val_accuracy: 0.9930\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0507 - accuracy: 0.9934 - val_loss: 0.0446 - val_accuracy: 0.9939\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0424 - accuracy: 0.9940 - val_loss: 0.0423 - val_accuracy: 0.9938\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0376 - accuracy: 0.9939 - val_loss: 0.0419 - val_accuracy: 0.9933\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0320 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9925\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0276 - accuracy: 0.9939 - val_loss: 0.0387 - val_accuracy: 0.9927\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.0394 - val_accuracy: 0.9921\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0359 - val_accuracy: 0.9924\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0387 - val_accuracy: 0.9920\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0372 - val_accuracy: 0.9919\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0356 - val_accuracy: 0.9920\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0359 - val_accuracy: 0.9925\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0357 - val_accuracy: 0.9925\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0367 - val_accuracy: 0.9925\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0368 - val_accuracy: 0.9928\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0398 - val_accuracy: 0.9906\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000261B8154DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.03981706127524376; accuracy of 99.06428456306458%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.3972 - accuracy: 0.5092 - val_loss: 0.1596 - val_accuracy: 0.9927\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1062 - accuracy: 0.9926 - val_loss: 0.0476 - val_accuracy: 0.9927\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0425 - accuracy: 0.9933 - val_loss: 0.0369 - val_accuracy: 0.9937\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0309 - accuracy: 0.9937 - val_loss: 0.0298 - val_accuracy: 0.9939\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0264 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.0247 - val_accuracy: 0.9943\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.0253 - val_accuracy: 0.9946\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0248 - val_accuracy: 0.9949\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0252 - val_accuracy: 0.9948\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0255 - val_accuracy: 0.9949\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000261F40665E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.02553299255669117; accuracy of 99.48809742927551%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.4573 - accuracy: 0.4523 - val_loss: 0.0531 - val_accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0511 - accuracy: 0.9934 - val_loss: 0.0379 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0345 - accuracy: 0.9940 - val_loss: 0.0311 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.0300 - val_accuracy: 0.9939\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0291 - val_accuracy: 0.9938\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0270 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0271 - val_accuracy: 0.9941\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0263 - val_accuracy: 0.9941\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0267 - val_accuracy: 0.9942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0256 - val_accuracy: 0.9944\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0253 - val_accuracy: 0.9947\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0267 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0257 - val_accuracy: 0.9946\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0257 - val_accuracy: 0.9949\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002621B97EAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.025723282247781754; accuracy of 99.4857132434845%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.5700 - accuracy: 0.5477 - val_loss: 0.0542 - val_accuracy: 0.9941\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0515 - accuracy: 0.9939 - val_loss: 0.0404 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0432 - accuracy: 0.9939 - val_loss: 0.0367 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0299 - accuracy: 0.9937 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.0305 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0284 - val_accuracy: 0.9939\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.0282 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0280 - val_accuracy: 0.9941\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0280 - val_accuracy: 0.9944\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0278 - val_accuracy: 0.9942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0283 - val_accuracy: 0.9938\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0268 - val_accuracy: 0.9943\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0291 - val_accuracy: 0.9932\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0305 - val_accuracy: 0.9925\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0299 - val_accuracy: 0.9932\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0302 - val_accuracy: 0.9933\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0297 - val_accuracy: 0.9943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026248581E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.029666395857930183; accuracy of 99.43095445632935%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6181 - accuracy: 0.5708 - val_loss: 0.0929 - val_accuracy: 0.9840\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0732 - accuracy: 0.9886 - val_loss: 0.0513 - val_accuracy: 0.9930\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0482 - accuracy: 0.9935 - val_loss: 0.0401 - val_accuracy: 0.9940\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0405 - accuracy: 0.9929 - val_loss: 0.0361 - val_accuracy: 0.9939\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.0295 - val_accuracy: 0.9939\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0284 - val_accuracy: 0.9941\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0276 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0273 - val_accuracy: 0.9941\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0300 - val_accuracy: 0.9938\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0286 - val_accuracy: 0.9942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0316 - val_accuracy: 0.9941\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0328 - val_accuracy: 0.9941\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0299 - val_accuracy: 0.9942\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026253FD48B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.029873475432395935; accuracy of 99.42142963409424%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: 5.1249 - accuracy: 0.3289 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.1659 - accuracy: 0.6175 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 17s 2s/step - loss: 6.3544 - accuracy: 0.6058 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.3899 - accuracy: 0.6036 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.1905 - accuracy: 0.6159 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.3258 - accuracy: 0.6075 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262661AD820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 4.29316520690918; accuracy of 73.36428761482239%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: nan - accuracy: 0.2280 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: nan - accuracy: 0.3692 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 17s 2s/step - loss: nan - accuracy: 0.3734 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 17s 2s/step - loss: nan - accuracy: 0.3699 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3669 - val_loss: nan - val_accuracy: 0.3218\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002626FF9F310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of nan; accuracy of 32.17619061470032%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 19s 2s/step - loss: nan - accuracy: 0.2351 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3651 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: nan - accuracy: 0.3664 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3772 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3709 - val_loss: nan - val_accuracy: 0.3300\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026277605280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of nan; accuracy of 32.99523890018463%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 5.2955 - accuracy: 0.4675 - val_loss: 6.6821 - val_accuracy: 0.5851\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.7913 - accuracy: 0.6398 - val_loss: 6.6809 - val_accuracy: 0.5851\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.4310 - accuracy: 0.6620 - val_loss: 6.6762 - val_accuracy: 0.5851\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.5435 - accuracy: 0.6547 - val_loss: 6.6711 - val_accuracy: 0.5851\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.9703 - accuracy: 0.6279 - val_loss: 6.6717 - val_accuracy: 0.5846\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.6594 - accuracy: 0.6469 - val_loss: 6.6754 - val_accuracy: 0.5851\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.5715 - accuracy: 0.6527 - val_loss: 6.6754 - val_accuracy: 0.5851\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.6663 - accuracy: 0.6468 - val_loss: 6.6731 - val_accuracy: 0.5849\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.4703 - accuracy: 0.6589 - val_loss: 6.6727 - val_accuracy: 0.5843\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002628D32D940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 6.672739028930664; accuracy of 58.430951833724976%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 5.1118 - accuracy: 0.5114 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.5071 - accuracy: 0.6583 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.7014 - accuracy: 0.6463 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.3547 - accuracy: 0.6678 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.3741 - accuracy: 0.6665 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.7796 - accuracy: 0.6414 - val_loss: 7.6135 - val_accuracy: 0.5276\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026292ECF9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 7.613503456115723; accuracy of 52.76428461074829%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.35 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.2454 - accuracy: 0.5464 - val_loss: 0.1025 - val_accuracy: 0.9930\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0812 - accuracy: 0.9909 - val_loss: 0.0585 - val_accuracy: 0.9921\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0553 - accuracy: 0.9929 - val_loss: 0.0500 - val_accuracy: 0.9921\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0446 - accuracy: 0.9930 - val_loss: 0.0424 - val_accuracy: 0.9930\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0458 - accuracy: 0.9917 - val_loss: 0.0399 - val_accuracy: 0.9930\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0328 - accuracy: 0.9933 - val_loss: 0.0366 - val_accuracy: 0.9939\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0275 - accuracy: 0.9936 - val_loss: 0.0357 - val_accuracy: 0.9939\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.0349 - val_accuracy: 0.9937\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.0352 - val_accuracy: 0.9936\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0350 - val_accuracy: 0.9936\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0351 - val_accuracy: 0.9935\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0350 - val_accuracy: 0.9932\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0356 - val_accuracy: 0.9926\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262A63B8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 0.035555992275476456; accuracy of 99.26190376281738%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.2875 - accuracy: 0.4886 - val_loss: 0.0920 - val_accuracy: 0.9937\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0807 - accuracy: 0.9916 - val_loss: 0.0588 - val_accuracy: 0.9937\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0517 - accuracy: 0.9937 - val_loss: 0.0412 - val_accuracy: 0.9937\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0357 - accuracy: 0.9938 - val_loss: 0.0352 - val_accuracy: 0.9936\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0289 - accuracy: 0.9939 - val_loss: 0.0325 - val_accuracy: 0.9937\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.0295 - val_accuracy: 0.9937\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0289 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0280 - val_accuracy: 0.9938\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0283 - val_accuracy: 0.9939\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0268 - val_accuracy: 0.9943\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0268 - val_accuracy: 0.9943\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0266 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0266 - val_accuracy: 0.9941\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0271 - val_accuracy: 0.9944\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0270 - val_accuracy: 0.9946\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0269 - val_accuracy: 0.9947\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0275 - val_accuracy: 0.9946\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0280 - val_accuracy: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262AB4CB3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.02800128236413002; accuracy of 99.44999814033508%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.0073 - accuracy: 0.5690 - val_loss: 0.0769 - val_accuracy: 0.9903\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0723 - accuracy: 0.9924 - val_loss: 0.0559 - val_accuracy: 0.9931\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0576 - accuracy: 0.9926 - val_loss: 0.0448 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0439 - accuracy: 0.9939 - val_loss: 0.0386 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0367 - accuracy: 0.9940 - val_loss: 0.0327 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.0290 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0276 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0257 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0259 - val_accuracy: 0.9941\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0259 - val_accuracy: 0.9941\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0258 - val_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0256 - val_accuracy: 0.9944\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0258 - val_accuracy: 0.9944\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0259 - val_accuracy: 0.9945\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0280 - val_accuracy: 0.9934\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0256 - val_accuracy: 0.9945\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0279 - val_accuracy: 0.9936\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0280 - val_accuracy: 0.9936\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262B71FF670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.027519498020410538; accuracy of 99.39761757850647%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6531 - accuracy: 0.5544 - val_loss: 0.0621 - val_accuracy: 0.9904\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0675 - accuracy: 0.9918 - val_loss: 0.0636 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0595 - accuracy: 0.9940 - val_loss: 0.0441 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0415 - accuracy: 0.9940 - val_loss: 0.0359 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0322 - accuracy: 0.9939 - val_loss: 0.0313 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0820 - accuracy: 0.9846 - val_loss: 0.0348 - val_accuracy: 0.9941\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.0303 - val_accuracy: 0.9935\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0295 - val_accuracy: 0.9940\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0273 - val_accuracy: 0.9939\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0272 - val_accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0281 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0278 - val_accuracy: 0.9939\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0285 - val_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0293 - val_accuracy: 0.9944\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262C3FDA700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.029256707057356834; accuracy of 99.44285750389099%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.3420 - accuracy: 0.4833 - val_loss: 0.2179 - val_accuracy: 0.9920\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1928 - accuracy: 0.9880 - val_loss: 0.0823 - val_accuracy: 0.9890\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0754 - accuracy: 0.9901 - val_loss: 0.0634 - val_accuracy: 0.9920\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0614 - accuracy: 0.9924 - val_loss: 0.0518 - val_accuracy: 0.9930\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0505 - accuracy: 0.9931 - val_loss: 0.0455 - val_accuracy: 0.9930\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0456 - accuracy: 0.9933 - val_loss: 0.0424 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0418 - accuracy: 0.9937 - val_loss: 0.0409 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0386 - accuracy: 0.9932 - val_loss: 0.0376 - val_accuracy: 0.9939\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0324 - accuracy: 0.9938 - val_loss: 0.0342 - val_accuracy: 0.9939\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0320 - val_accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0301 - val_accuracy: 0.9936\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0298 - val_accuracy: 0.9939\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0286 - val_accuracy: 0.9939\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0286 - val_accuracy: 0.9938\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0286 - val_accuracy: 0.9940\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0290 - val_accuracy: 0.9940\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0286 - val_accuracy: 0.9940\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0284 - val_accuracy: 0.9941\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0281 - val_accuracy: 0.9943\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0289 - val_accuracy: 0.9943\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0287 - val_accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0301 - val_accuracy: 0.9944\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262D04BBB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.030118271708488464; accuracy of 99.43809509277344%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.01...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.8131 - accuracy: 0.5436 - val_loss: 0.0908 - val_accuracy: 0.9938\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0728 - accuracy: 0.9918 - val_loss: 0.0558 - val_accuracy: 0.9912\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0520 - accuracy: 0.9920 - val_loss: 0.0461 - val_accuracy: 0.9939\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0373 - accuracy: 0.9936 - val_loss: 0.0410 - val_accuracy: 0.9938\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 0.0434 - val_accuracy: 0.9936\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0293 - accuracy: 0.9938 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 0.0408 - val_accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.0405 - val_accuracy: 0.9930\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0401 - val_accuracy: 0.9931\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0528 - val_accuracy: 0.9909\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0538 - val_accuracy: 0.9906\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0545 - val_accuracy: 0.9905\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0552 - val_accuracy: 0.9905\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0545 - val_accuracy: 0.9906\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262D04BBDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.05449168384075165; accuracy of 99.05952215194702%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 22s 2s/step - loss: 1.2869 - accuracy: 0.6097 - val_loss: 0.0561 - val_accuracy: 0.9927\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0972 - accuracy: 0.9875 - val_loss: 0.0433 - val_accuracy: 0.9935\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0327 - accuracy: 0.9939 - val_loss: 0.0334 - val_accuracy: 0.9936\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0299 - val_accuracy: 0.9936\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0279 - val_accuracy: 0.9936\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0257 - val_accuracy: 0.9941\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0241 - val_accuracy: 0.9945\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0257 - val_accuracy: 0.9945\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0250 - val_accuracy: 0.9951\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0246 - val_accuracy: 0.9950\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0248 - val_accuracy: 0.9951\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0254 - val_accuracy: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262B0AC9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.02544783055782318; accuracy of 99.528568983078%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6651 - accuracy: 0.6398 - val_loss: 0.0620 - val_accuracy: 0.9912\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0551 - accuracy: 0.9924 - val_loss: 0.0413 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0394 - accuracy: 0.9940 - val_loss: 0.0325 - val_accuracy: 0.9941\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0296 - accuracy: 0.9938 - val_loss: 0.0295 - val_accuracy: 0.9936\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0266 - val_accuracy: 0.9941\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0250 - val_accuracy: 0.9946\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0238 - val_accuracy: 0.9949\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0225 - val_accuracy: 0.9951\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0217 - val_accuracy: 0.9956\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0213 - val_accuracy: 0.9955\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0211 - val_accuracy: 0.9954\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0216 - val_accuracy: 0.9954\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0221 - val_accuracy: 0.9956\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0224 - val_accuracy: 0.9957\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0219 - val_accuracy: 0.9956\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0231 - val_accuracy: 0.9952\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262F47C88B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.023088136687874794; accuracy of 99.52142834663391%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.5285 - accuracy: 0.6425 - val_loss: 0.0509 - val_accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0539 - accuracy: 0.9922 - val_loss: 0.0386 - val_accuracy: 0.9941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0376 - accuracy: 0.9938 - val_loss: 0.0312 - val_accuracy: 0.9940\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.0296 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.0268 - val_accuracy: 0.9942\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9947\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0248 - val_accuracy: 0.9947\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0285 - val_accuracy: 0.9948\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0295 - val_accuracy: 0.9950\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0295 - val_accuracy: 0.9950\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0320 - val_accuracy: 0.9949\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262FFCED700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.031535230576992035; accuracy of 99.50000047683716%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.5794 - accuracy: 0.5705 - val_loss: 0.0728 - val_accuracy: 0.9840\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0666 - accuracy: 0.9882 - val_loss: 0.0472 - val_accuracy: 0.9930\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0535 - accuracy: 0.9909 - val_loss: 0.0458 - val_accuracy: 0.9940\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0421 - accuracy: 0.9937 - val_loss: 0.0350 - val_accuracy: 0.9938\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0324 - accuracy: 0.9930 - val_loss: 0.0325 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0300 - accuracy: 0.9934 - val_loss: 0.0331 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0295 - val_accuracy: 0.9938\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0294 - val_accuracy: 0.9938\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0272 - val_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0256 - val_accuracy: 0.9943\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0248 - val_accuracy: 0.9942\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0251 - val_accuracy: 0.9941\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0262 - val_accuracy: 0.9944\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0264 - val_accuracy: 0.9945\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0280 - val_accuracy: 0.9946\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026311C52040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.02802489511668682; accuracy of 99.45714473724365%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.05...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 5.5870 - accuracy: 0.3489 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.2191 - accuracy: 0.6142 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 6.1369 - accuracy: 0.6193 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 14s 2s/step - loss: 6.2506 - accuracy: 0.6122 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 14s 2s/step - loss: 6.1811 - accuracy: 0.6165 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 14s 2s/step - loss: 6.5091 - accuracy: 0.5962 - val_loss: 4.2932 - val_accuracy: 0.7336\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002631CDE33A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 4.29316520690918; accuracy of 73.36428761482239%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: nan - accuracy: 0.2342 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3648 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3837 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3874 - val_loss: nan - val_accuracy: 0.3218\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3781 - val_loss: nan - val_accuracy: 0.3218\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000263283C18B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of nan; accuracy of 32.17619061470032%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: nan - accuracy: 0.4070 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3779 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3681 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3567 - val_loss: nan - val_accuracy: 0.3300\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 16s 2s/step - loss: nan - accuracy: 0.3605 - val_loss: nan - val_accuracy: 0.3300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026335668280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of nan; accuracy of 32.99523890018463%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 5.3783 - accuracy: 0.3793 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 14s 2s/step - loss: 5.7529 - accuracy: 0.6431 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 14s 2s/step - loss: 5.6207 - accuracy: 0.6513 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.7173 - accuracy: 0.6453 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.6666 - accuracy: 0.6484 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 5.4486 - accuracy: 0.6620 - val_loss: 6.6871 - val_accuracy: 0.5851\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026335668550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 6.687093257904053; accuracy of 58.51190686225891%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: nan - accuracy: 0.3765 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3273 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3259 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3391 - val_loss: nan - val_accuracy: 0.4663\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: nan - accuracy: 0.3283 - val_loss: nan - val_accuracy: 0.4663\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026336274E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of nan; accuracy of 46.6309517621994%\n",
      "------------------------------------------------------------------------\n",
      "Training fordropout 0.5 and 0.005...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.7423 - accuracy: 0.4780 - val_loss: 0.1178 - val_accuracy: 0.9929\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0854 - accuracy: 0.9911 - val_loss: 0.0745 - val_accuracy: 0.9894\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0730 - accuracy: 0.9902 - val_loss: 0.0589 - val_accuracy: 0.9921\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0554 - accuracy: 0.9928 - val_loss: 0.0468 - val_accuracy: 0.9930\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0449 - accuracy: 0.9929 - val_loss: 0.2851 - val_accuracy: 0.9628\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1299 - accuracy: 0.9806 - val_loss: 0.0762 - val_accuracy: 0.9680\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0563 - accuracy: 0.9863 - val_loss: 0.0424 - val_accuracy: 0.9938\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0329 - accuracy: 0.9935 - val_loss: 0.0394 - val_accuracy: 0.9925\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 17s 2s/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0383 - val_accuracy: 0.9931\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0376 - val_accuracy: 0.9930\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0373 - val_accuracy: 0.9931\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0376 - val_accuracy: 0.9931\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0380 - val_accuracy: 0.9929\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0374 - val_accuracy: 0.9925\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0387 - val_accuracy: 0.9930\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0384 - val_accuracy: 0.9928\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000263589EE4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 1: loss of 0.03838678449392319; accuracy of 99.27856922149658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.5420 - accuracy: 0.5708 - val_loss: 0.0570 - val_accuracy: 0.9927\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0590 - accuracy: 0.9915 - val_loss: 0.0521 - val_accuracy: 0.9917\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0489 - accuracy: 0.9928 - val_loss: 0.0427 - val_accuracy: 0.9937\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0405 - accuracy: 0.9940 - val_loss: 0.0372 - val_accuracy: 0.9937\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0317 - accuracy: 0.9940 - val_loss: 0.0322 - val_accuracy: 0.9936\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0380 - accuracy: 0.9923 - val_loss: 0.0331 - val_accuracy: 0.9937\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0328 - val_accuracy: 0.9932\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0298 - val_accuracy: 0.9936\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0289 - val_accuracy: 0.9932\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0295 - val_accuracy: 0.9934\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0296 - val_accuracy: 0.9930\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0298 - val_accuracy: 0.9929\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0298 - val_accuracy: 0.9929\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0306 - val_accuracy: 0.9925\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000263636C6AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 2: loss of 0.030569979920983315; accuracy of 99.24761652946472%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 1.6097 - accuracy: 0.5363 - val_loss: 0.0941 - val_accuracy: 0.9941\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1314 - accuracy: 0.9864 - val_loss: 0.0664 - val_accuracy: 0.9912\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0680 - accuracy: 0.9914 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0490 - accuracy: 0.9928 - val_loss: 0.0395 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0374 - accuracy: 0.9937 - val_loss: 0.0325 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0281 - accuracy: 0.9940 - val_loss: 0.0300 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0853 - val_accuracy: 0.9825\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0819 - val_accuracy: 0.9825\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.0800 - val_accuracy: 0.9825\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0657 - val_accuracy: 0.9827\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0279 - val_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0272 - val_accuracy: 0.9939\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0276 - val_accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0276 - val_accuracy: 0.9942\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0281 - val_accuracy: 0.9943\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0283 - val_accuracy: 0.9945\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0288 - val_accuracy: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002636C1CA0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 3: loss of 0.028793390840291977; accuracy of 99.45476055145264%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.3918 - accuracy: 0.5339 - val_loss: 0.0673 - val_accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0816 - accuracy: 0.9891 - val_loss: 0.0595 - val_accuracy: 0.9922\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0550 - accuracy: 0.9929 - val_loss: 0.0426 - val_accuracy: 0.9931\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0385 - accuracy: 0.9929 - val_loss: 0.0343 - val_accuracy: 0.9941\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.0303 - val_accuracy: 0.9941\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0288 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0282 - val_accuracy: 0.9942\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0287 - val_accuracy: 0.9941\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0276 - val_accuracy: 0.9941\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0292 - val_accuracy: 0.9942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0283 - val_accuracy: 0.9941\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0295 - val_accuracy: 0.9942\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0286 - val_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002637F2D7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.02831348404288292; accuracy of 99.42619204521179%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 2.2564 - accuracy: 0.5306 - val_loss: 0.0824 - val_accuracy: 0.9880\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0841 - accuracy: 0.9868 - val_loss: 0.0557 - val_accuracy: 0.9940\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0556 - accuracy: 0.9937 - val_loss: 0.0470 - val_accuracy: 0.9940\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0489 - accuracy: 0.9938 - val_loss: 0.0432 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0435 - accuracy: 0.9940 - val_loss: 0.0411 - val_accuracy: 0.9940\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0391 - accuracy: 0.9936 - val_loss: 0.0366 - val_accuracy: 0.9940\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0324 - accuracy: 0.9937 - val_loss: 0.0327 - val_accuracy: 0.9939\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 0.0294 - val_accuracy: 0.9939\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.0278 - val_accuracy: 0.9938\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0278 - val_accuracy: 0.9939\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0281 - val_accuracy: 0.9940\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0275 - val_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0276 - val_accuracy: 0.9941\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0300 - val_accuracy: 0.9941\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0279 - val_accuracy: 0.9943\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0275 - val_accuracy: 0.9943\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0290 - val_accuracy: 0.9943\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002638D2018B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.02902275323867798; accuracy of 99.42619204521179%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_acc_per_fold2 =[]\n",
    "full_loss_per_fold2=[]\n",
    "full_preds = []\n",
    "full_y_test =[]\n",
    "full_histories = []\n",
    "k = 5\n",
    "for i in range(len(dropout_search)):\n",
    "    avg_acc_per_fold =[]\n",
    "    avg_loss_per_fold=[]\n",
    "    preds = []\n",
    "    y_test = []\n",
    "    histories = []\n",
    "    for j in range(len(learning_search)):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training fordropout {dropout_search[i]} and {learning_search[j]}...')\n",
    "        results = kfolds_bidir_weights(k,dropout_search[i],learning_search[j],50, 5) #40 epochs, 1 stop tolerance\n",
    "        avg_acc_per_fold.append(sum(results[0])/k)\n",
    "        avg_loss_per_fold.append(sum(results[1])/k)\n",
    "        preds.append(results[2])\n",
    "        y_test.append(results[3])\n",
    "        histories.append(results[4])\n",
    "    full_acc_per_fold2.append(avg_acc_per_fold)\n",
    "    full_loss_per_fold2.append(avg_loss_per_fold)\n",
    "    full_preds.append(preds)\n",
    "    full_y_test.append(y_test)\n",
    "    full_histories.append(histories)\n",
    "\n",
    "\n",
    "# create the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'full_acc_per_fold2' (list)\n",
      "Stored 'full_loss_per_fold2' (list)\n",
      "Stored 'full_preds' (list)\n",
      "Stored 'full_y_test' (list)\n"
     ]
    }
   ],
   "source": [
    "%store full_acc_per_fold2\n",
    "%store full_loss_per_fold2\n",
    "%store full_preds\n",
    "%store full_y_test\n",
    "#%store histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r full_acc_per_fold2\n",
    "%store -r full_loss_per_fold2\n",
    "%store -r full_preds\n",
    "%store -r full_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.03179241381585598, nan, 0.02990000620484352],\n",
       " [0.03012264147400856, nan, 0.030090350285172464],\n",
       " [0.0325175553560257, nan, 0.031017278507351875]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_loss_per_fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_acc_per_fold2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_rep[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 with dropout 0.25 and learning 0.01 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-cd32ef6b4019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         classification_rep = classification_report(\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             np.argmax(preds,\n\u001b[0;32m     10\u001b[0m                       axis=2).ravel(), \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "for i in range(len(dropout_search)):\n",
    "    for j in range(len(learning_search)):\n",
    "        print(f'Run {i} with dropout {dropout_search[i]} and learning {learning_search[j]} ',)\n",
    "#              f' accuracy {full_acc_per_fold2[i][j]} loss {full_loss_per_fold2[i][j]}' )\n",
    "        y_test = full_y_test[i][j]\n",
    "        preds = full_preds[i][j]\n",
    "        classification_rep = classification_report(\n",
    "            y_test.ravel(), \n",
    "            np.argmax(preds,\n",
    "                      axis=2).ravel(), \n",
    "            digits=3,\n",
    "                    )\n",
    "        \n",
    "        print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Model for Usage in other Code\n",
    "f = open('full_acc_per_fold2', 'wb')\n",
    "pickle.dump(full_acc_per_fold2, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('full_loss_per_fold2', 'wb')\n",
    "pickle.dump(full_loss_per_fold2, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('full_preds', 'wb')\n",
    "pickle.dump(full_preds, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('full_y_test', 'wb')\n",
    "pickle.dump(full_y_test, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_acc_per_fold2 = pickle.load(open('full_acc_per_fold2', 'rb'))\n",
    "full_loss_per_fold2 = pickle.load(open('full_loss_per_fold2', 'rb'))\n",
    "full_preds = pickle.load(open('full_preds', 'rb'))\n",
    "full_y_test = pickle.load(open('full_y_test', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 , 0.01 , 99.38714265823364\n",
      "0.25 , 0.05 , 56.913334131240845\n",
      "0.25 , 0.005 , 99.41523790359497\n",
      "0.35 , 0.01 , 99.37809586524963\n",
      "0.35 , 0.05 , 49.94619071483612\n",
      "0.35 , 0.005 , 99.39809441566467\n",
      "0.5 , 0.01 , 99.41333293914795\n",
      "0.5 , 0.05 , 48.73571515083313\n",
      "0.5 , 0.005 , 99.3666660785675\n"
     ]
    }
   ],
   "source": [
    "#dropout_search = [0.25,0.35,0.5]\n",
    "#learning_search = [0.01,0.05,0.005]\n",
    "\n",
    "drops = []\n",
    "learns = []\n",
    "acc = []\n",
    "\n",
    "for i,dropout in enumerate(dropout_search):\n",
    "    for j, learning in enumerate(learning_search):\n",
    "        drops.append(dropout)\n",
    "        learns.append(learning)\n",
    "        acc.append(full_acc_per_fold2[i][j])\n",
    "        print(dropout,',',learning,',',full_acc_per_fold2[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Parameter performance to pick best overall performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x250375c7d90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#drops\n",
    "#learns\n",
    "#acc\n",
    "plt.scatter(drops, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2503a248730>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(learns, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = []\n",
    "learns = []\n",
    "acc = []\n",
    "\n",
    "for i,dropout in enumerate(dropout_search):\n",
    "    for j, learning in enumerate(learning_search):\n",
    "        if learning <= 0.01:\n",
    "            drops.append(dropout)\n",
    "            learns.append(learning)\n",
    "            acc.append(full_acc_per_fold2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2503a2b4070>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(drops, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2503a3162e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(learns, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate of 0.01 and a dropout of .35 appears to be the most performant, this function probably can be used to refactor the above with different parameters, but for quick coding, it's just a copy with new parameter of `pat` which is the patience of our Neural Network's Early stopping. Upping this value will allow us to keep trying for better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds_bidir_weights_model(n,dropout,learning,n_epochs,pat ):\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    acc_per_fold =[]\n",
    "    loss_per_fold=[]\n",
    "    preds_per_fold = []\n",
    "    y_test_per_fold = []\n",
    "    models =[]\n",
    "    histories=[]\n",
    "    #classificat_reports=[]\n",
    "    \n",
    "    safety = EarlyStopping(monitor='val_loss', patience=pat, restore_best_weights=True)\n",
    "    \n",
    "    inv_map = {v: k for k, v in tag_map.items()}\n",
    "    label_class_weight = {}\n",
    "    for i in range(len(word_map)):\n",
    "        if i < 8:\n",
    "            if inv_map[i]=='O' or inv_map[i]==0: # freuqent class of 'O' or '0'\n",
    "                label_class_weight[i] = 1.0\n",
    "            else:\n",
    "                label_class_weight[i] = 2000.0 # tags we actually care about (ratio for # of 0 tags to true labels)\n",
    "        else: \n",
    "            label_class_weight[i] = 1.0\n",
    "\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X, y):\n",
    "\n",
    "      # Define the model architecture\n",
    "        model1 = Sequential()\n",
    "        model1.add(Embedding(len(word_map), 300, input_length=max_len))\n",
    "        model1.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "        model1.add(Dropout(dropout)) #play with this value \n",
    "        model1.add(TimeDistributed(Dense(len(tag_map),activation='softmax')))\n",
    "\n",
    "        opt =Adam(learning_rate=learning)\n",
    "        \n",
    "      # Compile the model\n",
    "        #change the learning rate\n",
    "        model1.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "      # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "      # Fit data to model\n",
    "        history = model1.fit(X[train], y[train], epochs=n_epochs, validation_data=(X[test], y[test]), batch_size=20, \n",
    "                             callbacks = [safety], class_weight = label_class_weight) #add weights param\n",
    "        histories.append(history)\n",
    "      # Generate generalization metrics\n",
    "        scores = model1.evaluate(X[test], y[test], verbose=0)\n",
    "        \n",
    "        preds = model1.predict(X[test])\n",
    "        preds_per_fold.append(preds)\n",
    "        y_test = y[test]\n",
    "        y_test_per_fold.append(y_test)\n",
    "        print(f'Score for fold {fold_no}: {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        models.append(model1)\n",
    "\n",
    "      # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "    return (acc_per_fold, loss_per_fold,preds_per_fold,y_test_per_fold,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_per_fold.append(y_test)\n",
    "preds_per_fold.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Run of LSTM with Weights and Higher Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 2.3348 - accuracy: 0.4532 - val_loss: 0.0999 - val_accuracy: 0.9931\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.1289 - accuracy: 0.9868 - val_loss: 0.0514 - val_accuracy: 0.9940\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0523 - accuracy: 0.9940 - val_loss: 0.0419 - val_accuracy: 0.9940\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0423 - accuracy: 0.9940 - val_loss: 0.0377 - val_accuracy: 0.9940\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0343 - accuracy: 0.9939 - val_loss: 0.0345 - val_accuracy: 0.9940\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0264 - accuracy: 0.9940 - val_loss: 0.0315 - val_accuracy: 0.9940\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0308 - val_accuracy: 0.9941\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0306 - val_accuracy: 0.9941\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0316 - val_accuracy: 0.9942\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9940\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0326 - val_accuracy: 0.9941\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0332 - val_accuracy: 0.9942\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9944\n",
      "Score for fold 1: loss of 0.03064516745507717; accuracy of 99.41071271896362%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 2.6994 - accuracy: 0.4442 - val_loss: 0.2826 - val_accuracy: 0.9849\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.1732 - accuracy: 0.9352 - val_loss: 0.0426 - val_accuracy: 0.9941\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0431 - accuracy: 0.9939 - val_loss: 0.0377 - val_accuracy: 0.9941\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0331 - accuracy: 0.9939 - val_loss: 0.0337 - val_accuracy: 0.9941\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.0306 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0295 - val_accuracy: 0.9941\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0291 - val_accuracy: 0.9939\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0300 - val_accuracy: 0.9936\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0293 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.0301 - val_accuracy: 0.9939\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0303 - val_accuracy: 0.9936\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0327 - val_accuracy: 0.9930\n",
      "Score for fold 2: loss of 0.029059479013085365; accuracy of 99.38928484916687%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.8840 - accuracy: 0.4634 - val_loss: 0.3737 - val_accuracy: 0.8744\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.1764 - accuracy: 0.9410 - val_loss: 0.0576 - val_accuracy: 0.9937\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0521 - accuracy: 0.9940 - val_loss: 0.0481 - val_accuracy: 0.9937\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0433 - accuracy: 0.9940 - val_loss: 0.0408 - val_accuracy: 0.9937\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0314 - accuracy: 0.9942 - val_loss: 0.0392 - val_accuracy: 0.9922\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.0336 - val_accuracy: 0.9932\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0313 - val_accuracy: 0.9932\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0286 - val_accuracy: 0.9933\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0277 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0286 - val_accuracy: 0.9935\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0303 - val_accuracy: 0.9930\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0298 - val_accuracy: 0.9934\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0297 - val_accuracy: 0.9940\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0301 - val_accuracy: 0.9937\n",
      "Score for fold 3: loss of 0.027727410197257996; accuracy of 99.37857389450073%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.4579 - accuracy: 0.6247 - val_loss: 0.0912 - val_accuracy: 0.9819\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0746 - accuracy: 0.9868 - val_loss: 0.0458 - val_accuracy: 0.9939\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0404 - accuracy: 0.9938 - val_loss: 0.0411 - val_accuracy: 0.9939\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0328 - accuracy: 0.9935 - val_loss: 0.0337 - val_accuracy: 0.9939\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 0.0316 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.0312 - val_accuracy: 0.9936\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0312 - val_accuracy: 0.9936\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0304 - val_accuracy: 0.9937\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0298 - val_accuracy: 0.9939\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0298 - val_accuracy: 0.9941\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0296 - val_accuracy: 0.9946\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0289 - val_accuracy: 0.9948\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0285 - val_accuracy: 0.9951\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0275 - val_accuracy: 0.9956\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0278 - val_accuracy: 0.9956\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9955\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0307 - val_accuracy: 0.9955\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0286 - val_accuracy: 0.9955\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0312 - val_accuracy: 0.9956\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F9F36793A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.027532104402780533; accuracy of 99.56071376800537%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 15s 2s/step - loss: 1.9682 - accuracy: 0.5673 - val_loss: 0.0808 - val_accuracy: 0.9914\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0783 - accuracy: 0.9901 - val_loss: 0.0518 - val_accuracy: 0.9924\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0540 - accuracy: 0.9925 - val_loss: 0.0438 - val_accuracy: 0.9943\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0454 - accuracy: 0.9936 - val_loss: 0.0384 - val_accuracy: 0.9943\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0375 - accuracy: 0.9940 - val_loss: 0.0340 - val_accuracy: 0.9943\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0302 - accuracy: 0.9939 - val_loss: 0.0306 - val_accuracy: 0.9943\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0293 - val_accuracy: 0.9941\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 15s 3s/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0274 - val_accuracy: 0.9941\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0270 - val_accuracy: 0.9941\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0271 - val_accuracy: 0.9941\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0269 - val_accuracy: 0.9941\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9942\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0262 - val_accuracy: 0.9945\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0262 - val_accuracy: 0.9949\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0261 - val_accuracy: 0.9950\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0262 - val_accuracy: 0.9947\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0262 - val_accuracy: 0.9948\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0262 - val_accuracy: 0.9950\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0264 - val_accuracy: 0.9950\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FA00109AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.026096850633621216; accuracy of 99.50000047683716%\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "results = kfolds_bidir_weights_model(k,.35,0.01,100, 5) #100 epochs, 5 stop tolerance\n",
    "k_avg_acc_per_fold=sum(results[0])/k\n",
    "k_avg_loss_per_fold=sum(results[1])/k\n",
    "k_preds=results[2]\n",
    "k_y_test =results[3]\n",
    "k_models = results[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_avg_acc_per_fold=sum(results[0])/k\n",
    "k_avg_loss_per_fold=sum(results[1])/k\n",
    "k_preds=results[2]\n",
    "k_y_test =results[3]\n",
    "k_models = results[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Model for Usage in other Code\n",
    "f = open('k_avg_acc_per_fold', 'wb')\n",
    "pickle.dump(k_avg_acc_per_fold, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('k_avg_loss_per_fold', 'wb')\n",
    "pickle.dump(k_avg_loss_per_fold, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('k_preds', 'wb')\n",
    "pickle.dump(k_preds, f)\n",
    "f.close()\n",
    "# Pickle Model for Usage in other Code\n",
    "f = open('k_y_test', 'wb')\n",
    "pickle.dump(k_y_test, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x1f9d0447d30>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1f99384a7c0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1f9d8eb2490>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1f9e992e8e0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1f9f36a7910>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "for i,model in enumerate(k_models):\n",
    "    model.save(f'my_model_{i}.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "    #del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53740577/does-any-one-got-attributeerror-str-object-has-no-attribute-decode-whi\n",
    "from keras.models import load_model\n",
    "fname = 'my_model_'+str(1)+'.h5'\n",
    "model = load_model(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_avg_acc_per_fold = pickle.load(open('k_avg_acc_per_fold', 'rb'))\n",
    "k_avg_loss_per_fold = pickle.load(open('k_avg_loss_per_fold', 'rb'))\n",
    "k_preds = pickle.load(open('k_preds', 'rb'))\n",
    "k_y_test = pickle.load(open('k_y_test', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 1000, 300)         4752900   \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 1000, 512)         1140736   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1000, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 1000, 8)           4104      \n",
      "=================================================================\n",
      "Total params: 5,897,740\n",
      "Trainable params: 5,897,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0th model\n",
      "Loaded 1th model\n",
      "Loaded 2th model\n",
      "Loaded 3th model\n",
      "Loaded 4th model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x26183840280>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x2618e94f040>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x26184f36310>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x2618d2d5a90>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x2618fd5ffa0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "k_models_2=[]\n",
    "for i in range(5):\n",
    "    fname = 'my_model_'+str(i)+'.h5'\n",
    "    model = load_model(fname)\n",
    "    print(f'Loaded {str(i)}th model')\n",
    "    k_models_2.append(model)\n",
    "k_models_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "B-Defendant lawyer      0.000     0.000     0.000         0\n",
      "I-Defendant lawyer      0.000     0.000     0.000         0\n",
      "           B-Judge      0.000     0.000     0.000         0\n",
      "           I-Judge      0.000     0.000     0.000         0\n",
      "       B-State Rep      0.000     0.000     0.000         0\n",
      "       I-State Rep      0.000     0.000     0.000         0\n",
      "\n",
      "         micro avg      0.000     0.000     0.000         0\n",
      "         macro avg      0.000     0.000     0.000         0\n",
      "      weighted avg      0.000     0.000     0.000         0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(\n",
    "            k_y_test.ravel(), \n",
    "            np.argmax(k_preds,\n",
    "                      axis=2).ravel(), \n",
    "            digits=3#, labels=sorted_labels,\n",
    "    #labels change everything to 0\n",
    "                    )\n",
    "        \n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Model  0 ----------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000026183840280>\n",
      "---------------- Model  1 ----------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002618E94F040>\n",
      "---------------- Model  2 ----------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000026184F36310>\n",
      "---------------- Model  3 ----------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002618D2D5A90>\n",
      "---------------- Model  4 ----------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002618FD5FFA0>\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(k_models_2):\n",
    "    print('----------------','Model ',i,'----------------')\n",
    "    print(model)\n",
    "#    print(dropout,',',learning,',',full_acc_per_fold2[i][j])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "k_models_2[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_models_2[4].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
